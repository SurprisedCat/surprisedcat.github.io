<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>线性代数与矩阵 on SurprisedCat</title><link>https://surprisedcat.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5/</link><description>Recent content in 线性代数与矩阵 on SurprisedCat</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2020–2021, SurprisedCat; all rights reserved.</copyright><lastBuildDate>Fri, 20 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://surprisedcat.github.io/tags/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5/index.xml" rel="self" type="application/rss+xml"/><item><title>线性代数与矩阵之矩阵的正定性，二次型与合同矩阵</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%9F%A9%E9%98%B5%E7%9A%84%E6%AD%A3%E5%AE%9A%E6%80%A7%E4%BA%8C%E6%AC%A1%E5%9E%8B%E4%B8%8E%E5%90%88%E5%90%8C%E7%9F%A9%E9%98%B5/</link><pubDate>Fri, 20 May 2022 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%9F%A9%E9%98%B5%E7%9A%84%E6%AD%A3%E5%AE%9A%E6%80%A7%E4%BA%8C%E6%AC%A1%E5%9E%8B%E4%B8%8E%E5%90%88%E5%90%8C%E7%9F%A9%E9%98%B5/</guid><description>
&lt;h2 id="线性代数与矩阵之矩阵的正定性二次型与合同矩阵">线性代数与矩阵之矩阵的正定性，二次型与合同矩阵&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#对称埃米特矩阵与正定性">对称（埃米特）矩阵与正定性&lt;/a>&lt;/li>
&lt;li>&lt;a href="#正定矩阵性质">正定矩阵性质&lt;/a>&lt;/li>
&lt;li>&lt;a href="#二次型与最小值">二次型与最小值&lt;/a>&lt;/li>
&lt;li>&lt;a href="#合同矩阵了解">合同矩阵（了解）&lt;/a>&lt;/li>
&lt;li>&lt;a href="#合同性质">合同性质&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>我们在对称矩阵的基础上定义了正定、半正定、负定、半负定的概念，并引入二次型，其与最大最小值相关。最后我们简介了矩阵的合同。&lt;/p>
&lt;h2 id="对称埃米特矩阵与正定性">对称（埃米特）矩阵与正定性&lt;/h2>
&lt;p>对称（埃米特）矩阵与矩阵的正定性，通常&lt;strong>正定性是定义在对称矩阵（或埃米特矩阵）上&lt;/strong>的，如果一个矩阵不是对称（埃米特）矩阵，就不具备讨论正定性的前提条件。&lt;/p>
&lt;blockquote>
&lt;p>一个&lt;span class="math">\(n×n\)&lt;/span>的实对称矩阵&lt;span class="math">\(A\)&lt;/span>是&lt;strong>正定的&lt;/strong>，当且仅当对于所有的非零实系数向量&lt;span class="math">\(x\)&lt;/span>，都有&lt;span class="math">\(x^TAx&amp;gt;0\)&lt;/span>，其中&lt;span class="math">\(x^T\)&lt;/span>表示x的转置。&lt;/p>
&lt;p>类似的，如果&lt;span class="math">\(x^TAx\geq 0\)&lt;/span>，则&lt;span class="math">\(A\)&lt;/span>称为&lt;strong>半正定矩阵&lt;/strong>；如果&lt;span class="math">\(x^TAx&amp;lt;0\)&lt;/span>，则&lt;span class="math">\(A\)&lt;/span>称为&lt;strong>负定矩阵&lt;/strong>；如果&lt;span class="math">\(x^TAx\leq 0\)&lt;/span>，则&lt;span class="math">\(A\)&lt;/span>称为&lt;strong>半负定矩阵&lt;/strong>。&lt;/p>
&lt;/blockquote>
&lt;p>注：如果是复数域的埃米特矩阵，那么上面一定中的转置都有替换成共轭转置。&lt;/p>
&lt;p>正定性还有这几个等价命题：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有特征值为正。对于正定矩阵的特征向量&lt;span class="math">\(y\)&lt;/span>，有&lt;span class="math">\(y^TAy&amp;gt;0\Rightarrow y^T\lambda y=\lambda |y|^2&amp;gt;0\Rightarrow \lambda&amp;gt;0\)&lt;/span>。&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有主元为正。证明思路：主元与二次型展开的平方项系数一致。&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的顺序主子式为正。&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>与单位阵&lt;span class="math">\(I\)&lt;/span>合同，即存在可逆矩阵&lt;span class="math">\(C\)&lt;/span>，使得&lt;span class="math">\(A=C^TIC\)&lt;/span>。&lt;/li>
&lt;/ol>
&lt;p>类似的，半正定矩阵有以下等价命题：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有特征值为非负。&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有主元为非负。&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的顺序主子式为非负。&lt;/li>
&lt;/ol>
&lt;p>我们可以通过例子说明，非对称矩阵可以在满足上述1，2，3的前提下不满足正定矩阵的定义&lt;span class="math">\(x^TAx&amp;gt;0\)&lt;/span>。如下例 &lt;span class="math">\[
\begin{bmatrix}
1&amp;amp;-100\\0&amp;amp;1
\end{bmatrix}
\]&lt;/span> 显然，其主元、特征值都是1，顺序主子式也都大于0，但是对于&lt;span class="math">\(x^TAx\)&lt;/span>，我们随便找一个向量&lt;span class="math">\(x=[1,1]^T\)&lt;/span>，则 &lt;span class="math">\[
[1\quad 1]\begin{bmatrix}1&amp;amp;-100\\0&amp;amp;1\end{bmatrix}\begin{bmatrix}1\\1\end{bmatrix}=-98&amp;lt;0
\]&lt;/span> 这并不满足&lt;span class="math">\(x^TAX&amp;gt;0\)&lt;/span>。这说明，&lt;strong>正定性必须建立在对称矩阵上&lt;/strong>。&lt;/p>
&lt;h3 id="正定矩阵性质">正定矩阵性质&lt;/h3>
&lt;ol style="list-style-type: decimal">
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>是正定矩阵，它的逆矩阵&lt;span class="math">\(A^{-1}\)&lt;/span>也是正定矩阵。因为逆矩阵的特征值是原矩阵的倒数&lt;span class="math">\(1\over \lambda\)&lt;/span>，因此也都是正数。&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A,B\)&lt;/span>是正定矩阵，那么&lt;span class="math">\(A+B\)&lt;/span>也是正定矩阵。证明：&lt;span class="math">\(x^T(A+B)x=x^TAx+x^TBx&amp;gt;0\)&lt;/span>&lt;/li>
&lt;li>如果&lt;span class="math">\(A\)&lt;/span>是一个&lt;span class="math">\(m×n\)&lt;/span>长方形矩阵，则&lt;span class="math">\(A^TA\)&lt;/span>是对称方阵，且一定半正定。证明：&lt;span class="math">\(x^TA^TAx=(Ax)^TAx=|Ax|^2\geq 0\)&lt;/span>。当&lt;span class="math">\(A\)&lt;/span>的秩为&lt;span class="math">\(n\)&lt;/span>时，&lt;span class="math">\(A^TA\)&lt;/span>为秩为&lt;span class="math">\(n\)&lt;/span>的&lt;span class="math">\(n\)&lt;/span>阶方阵，此时&lt;span class="math">\(A^TA\)&lt;/span>的零空间为零维空间，此时&lt;span class="math">\(A^TA\)&lt;/span>为正定矩阵。&lt;/li>
&lt;/ol>
&lt;h2 id="二次型与最小值">二次型与最小值&lt;/h2>
&lt;p>有了对称矩阵和定义在对称矩阵上的正定矩阵，我们由&lt;span class="math">\(x^TAx\)&lt;/span>引出二次型的概念。所谓“二次型”就是多元二次函数的矩阵表示形态，但是这个多元二次函数只包含二次项不包含一次项和常数项。这是因为在高阶多项式中，主要性质大多由最高阶项决定。&lt;/p>
&lt;blockquote>
&lt;p>二次型：对&lt;span class="math">\(n\)&lt;/span>维实向量&lt;span class="math">\(x∈R^n\)&lt;/span>&lt;span class="math">\(n\)&lt;/span>阶实对称阵&lt;span class="math">\(A\)&lt;/span>，&lt;span class="math">\(f(\vec x)=\vec x^TA\vec x\)&lt;/span>称为二次型。复数域上变为共轭转置即可。&lt;/p>
&lt;/blockquote>
&lt;p>由二项式展开式： &lt;span class="math">\[
\begin{aligned}
f(x_1,x_2,\dotsb,x_n)&amp;amp;=c_{11}x_1^2+c_{22}x_2^2+\dotsb+c_{nn}x_n^2\\
&amp;amp;+c_{12}x_1x_2+c_{13}x_1x_3+\dotsb+c_{1n}x_1x_n\\
&amp;amp;+\dotsb+c_{n-1,n}x_{n-1}x_n
\end{aligned}
\]&lt;/span> 与二次型&lt;span class="math">\(f(\vec x)=\vec x^TA\vec x\)&lt;/span>关系可知，其系数矩阵&lt;span class="math">\(A\)&lt;/span>与二项式系数关系为： &lt;span class="math">\[
A=\begin{bmatrix}
c_{11}&amp;amp;0.5c_{12}&amp;amp;0.5c_{13}&amp;amp;\dotsb&amp;amp;0.5c_{1,n}\\
c_{21}&amp;amp;c_{22}&amp;amp;0.5c_{23}&amp;amp;\dotsb&amp;amp;0.5c_{2,n}\\
\vdots&amp;amp;\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\vdots&amp;amp;\\
0.15c_{1,n}&amp;amp;0.5c_{2,n}&amp;amp;0.5c_{3,n}&amp;amp;\dotsb&amp;amp;c_{n,n}\\
\end{bmatrix}
\]&lt;/span> 显然，矩阵&lt;span class="math">\(A\)&lt;/span>是对称矩阵。当&lt;span class="math">\(A\)&lt;/span>是（半）正定矩阵时，二次型有最小值；当&lt;span class="math">\(A\)&lt;/span>是（半）负定矩阵时二次型有最大值。&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/正定负定不定半正定.png" alt="正定负定不定半正定.png" />&lt;p class="caption">正定负定不定半正定.png&lt;/p>
&lt;/div>
&lt;h2 id="合同矩阵了解">合同矩阵（了解）&lt;/h2>
&lt;p>合同矩阵，在线性代数，特别是二次型理论中，常常用到矩阵间的合同关系。&lt;/p>
&lt;blockquote>
&lt;p>合同矩阵：设&lt;span class="math">\(A,B\)&lt;/span>是两个&lt;span class="math">\(n\)&lt;/span>阶方阵，若存在可逆矩阵&lt;span class="math">\(C\)&lt;/span>，使得： &lt;span class="math">\[B=C^TAC\]&lt;/span> 则称方阵&lt;span class="math">\(A\)&lt;/span>与&lt;span class="math">\(B\)&lt;/span>合同，记作&lt;span class="math">\(A≃B\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;h3 id="合同性质">合同性质&lt;/h3>
&lt;p>合同关系是一个&lt;strong>等价关系&lt;/strong>，也就是说满足：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>反身性：任意矩阵都与其自身合同；&lt;/li>
&lt;li>对称性：&lt;span class="math">\(A\)&lt;/span>合同于&lt;span class="math">\(B\)&lt;/span>，则可以推出&lt;span class="math">\(B\)&lt;/span>合同于&lt;span class="math">\(A\)&lt;/span>；&lt;/li>
&lt;li>传递性：&lt;span class="math">\(A\)&lt;/span>合同于&lt;span class="math">\(B\)&lt;/span>，&lt;span class="math">\(B\)&lt;/span>合同于&lt;span class="math">\(C\)&lt;/span>，则可以推出&lt;span class="math">\(A\)&lt;/span>合同于&lt;span class="math">\(C\)&lt;/span>；&lt;/li>
&lt;li>此外，由于&lt;span class="math">\(B=C^TAC\)&lt;/span>中，要求&lt;span class="math">\(C\)&lt;/span>可逆，所以合同矩阵的秩相同。&lt;/li>
&lt;/ol>
&lt;p>两个实对称矩阵合同的充要条件是&lt;strong>它们的正负惯性指数相同&lt;/strong>。&lt;/p>
&lt;p>其中，提到了正负惯性指数，是指：&lt;/p>
&lt;blockquote>
&lt;p>正惯性指数，简称正惯数，是线性代数里矩阵的&lt;strong>正的特征值个数&lt;/strong>，也即是规范型里的系数&amp;quot;1&amp;quot;的个数。&lt;/p>
&lt;/blockquote>
&lt;p>实二次型的标准形中，系数为正的平方项的个数等于二次型的正惯性指数。&lt;/p>
&lt;p>此外，合同变化与二次型的化简有关。&lt;/p></description></item><item><title>线性代数与矩阵之特征值与特征向量</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/</link><pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%89%B9%E5%BE%81%E5%80%BC%E4%B8%8E%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F/</guid><description>
&lt;h2 id="线性代数与矩阵之特征值与特征向量">线性代数与矩阵之特征值与特征向量&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#传统的特征值与特征向量介绍方法">传统的特征值与特征向量介绍方法&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征向量特殊在哪里">特征向量特殊在哪里&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征基">特征基&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征基的存在性与特征子空间">特征基的存在性与特征（子）空间&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#特征值都不相同">特征值都不相同&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征值重根与特征向量个数">特征值重根与特征向量个数&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征子空间">特征（子）空间&lt;/a>&lt;/li>
&lt;/ul>&lt;/li>
&lt;li>&lt;a href="#特征值的一些性质">特征值的一些性质&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征值分解与矩阵的幂">特征值分解与矩阵的幂&lt;/a>&lt;/li>
&lt;li>&lt;a href="#矩阵幂的快捷计算">矩阵幂的快捷计算&lt;/a>&lt;/li>
&lt;li>&lt;a href="#投影矩阵的特征值与特征向量">投影矩阵的特征值与特征向量&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>特征值与特征向量是线性代数与矩阵中非常重要且深刻的两个概念，然而我当年在学习的时候基本上只学会了如何计算特征值和特征向量，对他们的意义、由来、用法不求甚解，很长一段时间都不知为什么会引入这两个奇怪的东西。当再次看到这二者时，我觉得还是记录下一些想法，必备后用。&lt;/p>
&lt;p>注意，我们默认只在&lt;strong>方阵&lt;/strong>中讨论特征值和特征向量。&lt;/p>
&lt;h2 id="传统的特征值与特征向量介绍方法">传统的特征值与特征向量介绍方法&lt;/h2>
&lt;p>国内一些典型的大学线代教科书，例如用的非常广泛但也被称为教科书中的耻辱柱的《线性代数》（同济版）。对特征值与特征向量的介绍很直接，上来就会给你下个定义：&lt;/p>
&lt;blockquote>
&lt;p>设&lt;span class="math">\(A\)&lt;/span>是&lt;span class="math">\(n\)&lt;/span>阶方阵，如果数&lt;span class="math">\(\lambda\)&lt;/span>和&lt;span class="math">\(n\)&lt;/span>维非零列向量&lt;span class="math">\(x\)&lt;/span>使关系是 &lt;span class="math">\[Ax=\lambda x\tag{1}\]&lt;/span> 成立，那么，这样的数&lt;span class="math">\(\lambda\)&lt;/span>称为矩阵&lt;span class="math">\(A\)&lt;/span>的&lt;strong>特征值&lt;/strong>，非零向量&lt;span class="math">\(x\)&lt;/span>称为&lt;span class="math">\(A\)&lt;/span>的对应与特征值&lt;span class="math">\(\lambda\)&lt;/span>的&lt;strong>特征向量&lt;/strong>。&lt;/p>
&lt;p>（1）式也可写成 &lt;span class="math">\[(A-\lambda I)x=0\]&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>以上是同济版线性代数教材对特征值和特征向量的第一印象介绍。&lt;/p>
&lt;p>接下来，大多数教科书就会介绍如何根据行列式&lt;span class="math">\(\det(A-\lambda I)=0\)&lt;/span>求出特征值，再将求出的各个特征值代入式（1）求出特征向量，接下来就开始举例子做题了。&lt;/p>
&lt;p>最后，大家经过艰苦的刷题和复习，线性代数考了高分，过了段时间，就将这个有些奇怪的特征值和特征向量抛掷脑后。反正，当时我是这么过来的，^_^。&lt;/p>
&lt;h2 id="特征向量特殊在哪里">特征向量特殊在哪里&lt;/h2>
&lt;p>很多人并没想过，这个特征向量，为什么特殊，它又是怎么被称为“特征”的。刚接触这个定义会觉得有些微妙，似乎是个很巧妙的东西，又说不出个因为所以，有点懵，怎么就是“特征”值，“特征”向量了呢？我们从特征向量入手。&lt;/p>
&lt;p>我们知道，矩阵是线性变化的一种表示方法。空间中的向量与矩阵的乘积本质上是对该向量长度和方向的变换。大多数向量在经过矩阵的变换后，长度和方向都会发生变化。如下图：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/矩阵乘法线性变换.gif" alt="矩阵乘法线性变换.gif" />&lt;p class="caption">矩阵乘法线性变换.gif&lt;/p>
&lt;/div>
&lt;p>图中向量&lt;span class="math">\(v\)&lt;/span>原来所在的方向的直线可以称之为向量&lt;span class="math">\(v\)&lt;/span>张成的空间，对这个概念有疑惑的话，可以参考笔记&lt;a href="线性代数与矩阵之理解向量、线性变换与矩阵乘法.md">线性代数与矩阵之理解向量、线性变换与矩阵乘法&lt;/a>，线性变换之后，向量&lt;span class="math">\(v\)&lt;/span>大概率会离开原来所在的一维子空间到。这种离开原来子空间的向量并没有什么特殊的。基本上随便找一个空间中的向量，都会发生这种改变。那么，有没有一些特殊的向量，经过矩阵&lt;span class="math">\(A\)&lt;/span>的变换之后不会离开原来的一维子空间呢？&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/特征向量.gif" alt="特征向量.gif" />&lt;p class="caption">特征向量.gif&lt;/p>
&lt;/div>
&lt;p>还真有。如上所示，对于矩阵&lt;span class="math">\(\begin{bmatrix}3&amp;amp;1\\0&amp;amp;2\end{bmatrix}\)&lt;/span>而言，向量&lt;span class="math">\((1,-1)^T\)&lt;/span>在经过矩阵变换之后变成了&lt;span class="math">\((2,-2)^T\)&lt;/span>，仍旧位于原来的子空间中，只是长度变长了。同时，不难发现所有在向量&lt;span class="math">\((1,-1)^T\)&lt;/span>同一条直线上的向量都满足这种方向不变性。那么这些方向不变的向量相对于大多数方向会改变的向量是特殊的存在，此时我们再回看传统特征向量的定义： &lt;span class="math">\[
Ax=\lambda x\tag{1}
\]&lt;/span> 不正是说的是向量&lt;span class="math">\(x\)&lt;/span>在经过矩阵&lt;span class="math">\(A\)&lt;/span>的变换后，方向没有变化，和原向量是共线的&lt;span class="math">\(\lambda x\)&lt;/span>，只是长度发生了改变。对于特征向量而言，矩阵变化只是长度的伸缩，而长度伸缩的大小，正是特征值&lt;span class="math">\(\lambda\)&lt;/span>。&lt;/p>
&lt;p>我们再看特征这个词的解释：特别的征象、标志；特点。我们说一个事物的特征，比如昆虫的特征是一对触角，两对翅（忽略极少数特例），三对足。特征体现了一种&lt;strong>不变性&lt;/strong>，不管其他方面怎么变，比如颜色、大小、生活地点，只要它的三个特性“一对触角，两对翅（忽略极少数特例），三对足”没变，那么它就是昆虫。如果它的特征，如足数目变了，比如蜘蛛、蜈蚣，那么它就不是昆虫（是不是很多人不知道蜘蛛不是昆虫，哈哈）。而&lt;strong>特征向量也是不变性的体现，它的方向在矩阵变换中总是不变的&lt;/strong>。&lt;/p>
&lt;p>现在，我们可以承认，特征向量（以及附带的特征值）确实具有特殊性，那么这种特殊性有什么好处呢？我们需要回到向量在空间中表示的角度来考虑。&lt;/p>
&lt;h2 id="特征基">特征基&lt;/h2>
&lt;p>正常情况下，向量都是用标准正交基表示的，用矩阵表示就是单位向量&lt;span class="math">\(I\)&lt;/span>。例如，向量&lt;span class="math">\(v=(3,2)^T\)&lt;/span>就是说在基&lt;span class="math">\(e_1=(1,0)^T,e_2=(0,1)^T\)&lt;/span>两个单位向量下，由3份&lt;span class="math">\(e_1\)&lt;/span>和2份&lt;span class="math">\(e_2\)&lt;/span>合成的向量，即&lt;span class="math">\(v=3e_1+2e_2\)&lt;/span>。在经过某个矩阵&lt;span class="math">\(A\)&lt;/span>的线性变换后，比如还是上面的例子&lt;span class="math">\(\begin{bmatrix}3&amp;amp;1\\0&amp;amp;2\end{bmatrix}\)&lt;/span>，其结果&lt;span class="math">\((11,4)^T\)&lt;/span>很难和原向量&lt;span class="math">\((3,2)^T\)&lt;/span>看出直接的联系。&lt;/p>
&lt;p>如果我们换一种思路，用另一组基去表示向量&lt;span class="math">\(v\)&lt;/span>，能不能让矩阵代表的线性变换看起来更直观，更容易呢？比方说，借助特征向量的方向不变性？&lt;/p>
&lt;p>我们可以尝试下。以&lt;span class="math">\(v=(3,2)^T,A=\begin{bmatrix}3&amp;amp;1\\0&amp;amp;2\end{bmatrix}\)&lt;/span>为例。我们根据特征向量的求法，可得两个特征向量分别为&lt;span class="math">\(t_1=(1,0)^T,t_2=(1,-1)^T\)&lt;/span>，对应特征值分别为&lt;span class="math">\(\lambda_1=3,\lambda_2=2\)&lt;/span>。&lt;/p>
&lt;p>那么&lt;span class="math">\(v\)&lt;/span>用&lt;span class="math">\(t_1,t_2\)&lt;/span>可表示为&lt;span class="math">\(v=5t_1-2t_2\)&lt;/span>，即在基&lt;span class="math">\(t_1=(1,0)^T,t_2=(1,-1)^T\)&lt;/span>表示下应为&lt;span class="math">\((5,-2)^T\)&lt;/span>，那么 &lt;span class="math">\[Av=A(5t_1-2t_2)=5At_1-2At_2=5\lambda_1t_1-2\lambda_2t_2=15t_1-4t_2\]&lt;/span> 在基&lt;span class="math">\(t_1,t_2\)&lt;/span>下，结果为&lt;span class="math">\((15,-4)\)&lt;/span>正好分别将第一、二个分量扩大了&lt;span class="math">\(\lambda_1,\lambda_2\)&lt;/span>倍！过程非常直观，计算非常方便！那些原来没有规律的变换，在特征向量组成的基表示下，&lt;strong>只是在各个分量方向不变是的伸缩变化&lt;/strong>。而其在标准正交基&lt;span class="math">\(e_1,e_2\)&lt;/span>下的结果正是&lt;span class="math">\(15t_1-4t_2=(11,4)^T\)&lt;/span>。结果没有任何区别！&lt;/p>
&lt;p>因此，为了线性变换的便利，我们引入该线性变换（矩阵）对应特征基来表示一个向量：&lt;/p>
&lt;blockquote>
&lt;p>线性变换的特征基：空间的一组基，使得某线性变换在这组基下只是坐标轴方向上的伸缩变换(乘以一个标量&lt;span class="math">\(\lambda\)&lt;/span>)，不同轴上的伸缩比例不同。若&lt;span class="math">\(T=(t_1,t_2,\dotsb,t_n)\)&lt;/span>是矩阵&lt;span class="math">\(A\)&lt;/span>的一组特征基，向量&lt;span class="math">\(x\)&lt;/span>在特征基&lt;span class="math">\(T\)&lt;/span>的表示下为&lt;span class="math">\(x=(x_1,x_2,\dotsb,x_n)\)&lt;/span>，那么&lt;span class="math">\(Ax\)&lt;/span>的结果在&lt;span class="math">\(T\)&lt;/span>的表示下是： &lt;span class="math">\[Ax=(\lambda_1x_1,\lambda_2x_2,\dotsb,\lambda_nx_n)\]&lt;/span> 其中，&lt;span class="math">\(\lambda_1,\lambda_2,\dotsb,\lambda_n\)&lt;/span>分别是特征向量&lt;span class="math">\(t_1,t_2,\dotsb,t_n\)&lt;/span>对应的特征值。&lt;/p>
&lt;/blockquote>
&lt;p>注意，这里的&lt;span class="math">\(x=(x_1,x_2,\dotsb,x_n)\)&lt;/span>是在特征基下的表示结果，即&lt;span class="math">\(x=x_1t_1+x_2t_2+\dotsb+x_nt_n\)&lt;/span>，而不是标准正交基下的表示结果。&lt;/p>
&lt;p>矩阵&lt;span class="math">\(A=\begin{bmatrix}3&amp;amp;1\\0&amp;amp;2\end{bmatrix}\)&lt;/span>的特征基的变换过程如下&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/特征基.gif" alt="特征基" />&lt;p class="caption">特征基&lt;/p>
&lt;/div>
&lt;p>所以使用特征向量组成的特征基来应对相应的线性变换，可以大大降低计算复杂度，这在求矩阵的幕、图像压缩、解微分方程等领域得到了大量应用，后面我们会举几个例子。&lt;/p>
&lt;p>现在有一个问题，既然特征基那么好用，那么特征基总是存在嘛？换句话说，我们总是能够找到足够多的线性无关的特征向量组成特征基嘛？&lt;/p>
&lt;h3 id="特征基的存在性与特征子空间">特征基的存在性与特征（子）空间&lt;/h3>
&lt;p>一般我们求特征向量的步骤是先根据&lt;span class="math">\(\det(A-\lambda I)=0\)&lt;/span>解特征值的一元高次方程，然后在代入&lt;span class="math">\(Ax=\lambda x\)&lt;/span>求特征向量。那么 &lt;span class="math">\[\det(A-\lambda I)=0\tag{2}\]&lt;/span> 这个式子的解，就决定了特征向量的存在性。我们知道，在复数域下，n次方程必然有n个根，&lt;strong>而有没有重根，将是决定特征基是否存在的关键&lt;/strong>。&lt;/p>
&lt;h4 id="特征值都不相同">特征值都不相同&lt;/h4>
&lt;p>对于方程组 &lt;span class="math">\[(A-\lambda I)x=0\]&lt;/span> 由于式（2）&lt;span class="math">\(\det(A-\lambda I)=0\)&lt;/span>，即&lt;span class="math">\(A-\lambda I\)&lt;/span>并不是满秩的（奇异矩阵），由此其必存在至少一维零空间，此时&lt;span class="math">\(x\)&lt;/span>是属于零空间的任意向量。&lt;/p>
&lt;p>对于存在&lt;span class="math">\(n\)&lt;/span>个不同特征值的场景，&lt;span class="math">\(A-\lambda I\)&lt;/span>的维数为&lt;span class="math">\(n-1\)&lt;/span>，由于&lt;span class="math">\(rank(Col(A-\lambda I))+rank(N(A-\lambda I))=n\)&lt;/span>，则我们可以得到&lt;span class="math">\(n\)&lt;/span>个特征向量&lt;span class="math">\((x_1,x_2\dotsb,x_n)\)&lt;/span>处在&lt;span class="math">\(n\)&lt;/span>个一维的零空间中。现在需要证明的是，这&lt;span class="math">\(n\)&lt;/span>个特征向量是线性无关的。&lt;/p>
&lt;blockquote>
&lt;p>我们使用反证法来证明。先假设这&lt;span class="math">\(n\)&lt;/span>个特征向量线性相关，则存在&lt;span class="math">\(n\)&lt;/span>个不全为零的常数&lt;span class="math">\((c^{(1)}_i)\)&lt;/span>使得如下式子成立： &lt;span class="math">\[c^{(1)}_1 x_1+c^{(1)}_2 x_2+\dotsb+c^{(1)}_n x_n=0\tag{3}\]&lt;/span> 用矩阵&lt;span class="math">\(A\)&lt;/span>左乘式(3)，根据&lt;span class="math">\(Ax_i =\lambda_ix_i\)&lt;/span>有： &lt;span class="math">\[c^{(1)}_1\lambda_1 x_1+c^{(1)}_2\lambda_2 x_2+\dotsb+c^{(1)}_n\lambda_n x_n=0\tag{4}\]&lt;/span> 现使用&lt;span class="math">\(式(4)-\lambda_n×式(3)\)&lt;/span>有: &lt;span class="math">\[c^{(1)}_1(\lambda_1-\lambda_n) x_1+c^{(1)}_2(\lambda_2-\lambda_n) x_2+\dotsb+c^{(1)}_{n-1}(\lambda_{n-1}-\lambda_n) x_{n-1}=0\tag{5}\]&lt;/span> 由于所有的&lt;span class="math">\(\lambda_i\)&lt;/span>都不相等，所以&lt;span class="math">\(\lambda_i-\lambda_n\neq 0(i\neq n)\)&lt;/span>。 我们令&lt;span class="math">\(c^{(2)}_i=c^{(1)}_i(\lambda_i-\lambda_n)\)&lt;/span> &lt;span class="math">\[c^{(2)}_1 x_1+c^{(2)}_2 x_2+\dotsb+c^{(2)}_{n-1} x_{n-1}=0\tag{6}\]&lt;/span> 式(6)与式(3)形式一样，但是少一个&lt;span class="math">\(x_n\)&lt;/span>，我们仿照之前的步骤，同样对&lt;span class="math">\(A×式(6)-\lambda_{n-1}×式(6)\)&lt;/span>得到: &lt;span class="math">\[c^{(2)}_1(\lambda_1-\lambda_{n-1}) x_1+c^{(2)}_2(\lambda_2-\lambda_{n-1}) x_2+\dotsb+c^{(2)}_{n-2}(\lambda_{n-2}-\lambda_{n-1}) x_{n-2}=0\tag{7}\]&lt;/span> 这次我们把&lt;span class="math">\(x_{n-1}\)&lt;/span>消掉了。 按照前面的乘以矩阵&lt;span class="math">\(A\)&lt;/span>再减去&lt;span class="math">\(\lambda\)&lt;/span>的步骤重复进行&lt;span class="math">\(n−2\)&lt;/span>次（每次都用一个不同的单个字符代替&lt;span class="math">\(x_i\)&lt;/span>前面的系数）后，可得： &lt;span class="math">\[c^{n-2}_1 (\lambda_1-\lambda_3)x_1+c^{n-2}_2(\lambda_2-\lambda_3)x_2=0\tag{8}\]&lt;/span> 同样的，令&lt;span class="math">\(c^{n-2}_1 (\lambda_1-\lambda_3)=c^{n-1}_1,c^{n-2}_2(\lambda_2-\lambda_3)=c^{(n-1)}_2\)&lt;/span>即可得到: &lt;span class="math">\[c^{(n-1)}_1x_1 +c^{(n-1)}_2x_2=0\tag{9}\]&lt;/span> 最后，我们使用&lt;span class="math">\(式(9)-\lambda_2×式(9)\)&lt;/span>有: &lt;span class="math">\[c^{(n-1)}_1Ax_1 +c^{(n-1)}_2Ax_2-c^{(n-1)}_1\lambda_2x_1-c^{(n-1)}_2\lambda_2x_2\\=c^{(n-1)}_1(\lambda_1-\lambda_2)x_1=0\tag{10}\]&lt;/span> 我们最后令&lt;span class="math">\(c^{(n)}_1=c^{(n-1)}_1(\lambda_1-\lambda_2)\)&lt;/span>。由于特征向量不为零，所以只能是&lt;span class="math">\(c^{(n)}_1\)&lt;/span>。&lt;/p>
&lt;p>而&lt;span class="math">\(c^{(n)}_1=c^{(n-1)}_1(\lambda_1-\lambda_2)=c^{(n-2)}_1(\lambda_1-\lambda_3)(\lambda_1-\lambda_2)=\dotsb=c^{1}_1(\lambda_1-\lambda_2)(\lambda_1-\lambda_3)\dotsb(\lambda_1-\lambda_n)\)&lt;/span>，又因为各特征值都不相等，所以只能是&lt;span class="math">\(c^{(1)}_1=0\)&lt;/span>。将其代回式（9）可得：&lt;span class="math">\(c_2^{(n-1)}=0\)&lt;/span>&lt;/p>
&lt;p>而&lt;span class="math">\(c_2^{(n-1)}=c^{(1)}_2(\lambda_2-\lambda_3)(\lambda_2-\lambda_4)\dotsb(\lambda_2-\lambda_n)\)&lt;/span>，而各特征值都不相等，所以只能是&lt;span class="math">\(c^{(1)}_2=0\)&lt;/span>。我们逐步从后往前反推，即可得到 &lt;span class="math">\[c^{(1)}_i=0,\forall i=\{1,2,\dotsb,n\}\]&lt;/span> 则说明前面的假设：存在&lt;span class="math">\(n\)&lt;/span>个不全为零的常数&lt;span class="math">\((c^{(1)}_i)\)&lt;/span>使式（3）为0不成立，因此&lt;strong>矩阵不同特征值对应的特征向量线性无关&lt;/strong>得证。&lt;/p>
&lt;/blockquote>
&lt;p>需要指出，我们所说的&lt;span class="math">\(n\)&lt;/span>个不同特征值，不一定非要都是实数，也可以是复数。复数特征值和特征向量同样满足&lt;span class="math">\(Ax=\lambda x\)&lt;/span>的一系列特性。我们以逆时针旋转&lt;span class="math">\(\frac{\pi}{2}\)&lt;/span>的旋转矩阵&lt;span class="math">\(R=\begin{bmatrix}0&amp;amp;-1\\1&amp;amp;0\end{bmatrix}\)&lt;/span>为例： &lt;img src="../../images/旋转矩阵.gif" alt="旋转矩阵.gif" />&lt;/p>
&lt;p>显然，经过逆时针90°旋转，空间中所有的非零向量方向都发生了改变。我们计算特征值：&lt;span class="math">\(\det(R-\lambda I)=\lambda^2+1=0\Rightarrow \lambda_1=i,\lambda_2=-i\)&lt;/span>。代入算出对应的特征向量分别为&lt;span class="math">\(x_1=(1,-i)^T,x_2=(-i,1)^T\)&lt;/span>。可见，在此场景下的特征向量无法用实数域向量表示，但是用&lt;span class="math">\(x_1,x_2\)&lt;/span>组成特征基，其矩阵计算与实数域结果依然一致。&lt;/p>
&lt;h4 id="特征值重根与特征向量个数">特征值重根与特征向量个数&lt;/h4>
&lt;p>前一节已经说明不同的特征值必然带来线性不相关的特征向量，那么当特征值有&lt;span class="math">\(r\)&lt;/span>重根时，线性无关特征向量是不是也会有&lt;span class="math">\(r\)&lt;/span>个呢？&lt;/p>
&lt;p>答案是不一定。而且&lt;span class="math">\(r\)&lt;/span>重根的特征向量可能从1~r个不等。&lt;/p>
&lt;p>典型的&lt;span class="math">\(r\)&lt;/span>重特征值有&lt;span class="math">\(r\)&lt;/span>个线性无关特征向量的矩阵是单位阵&lt;span class="math">\(I_{n×n}\)&lt;/span>，特征值&lt;span class="math">\(\det(I-\lambda I)=0\)&lt;/span>，所有的特征值都是1，同时空间中所有的向量都可以作为特征向量（&lt;span class="math">\(Ix=1×x\)&lt;/span>），所以可以从空间中取出&lt;span class="math">\(n\)&lt;/span>个线性无关特征向量。&lt;/p>
&lt;p>典型的线性无关特征向量个数小于特征根重数的矩阵是主对角元素有相等时的三角矩阵。具体例子如 &lt;span class="math">\[
\begin{bmatrix}
1&amp;amp;2\\0&amp;amp;1
\end{bmatrix},
\begin{bmatrix}
1&amp;amp;2&amp;amp;3\\0&amp;amp;1&amp;amp;1\\0&amp;amp;0&amp;amp;1
\end{bmatrix}
\]&lt;/span> 这两个矩阵都只有一个线性无关的特征向量。&lt;/p>
&lt;h4 id="特征子空间">特征（子）空间&lt;/h4>
&lt;p>我们将所有有着&lt;strong>相同特征值的特征向量组成的空间，还包括零向量&lt;/strong>（但要注意零向量本身不是特征向量），叫做一个特征（子）空间。也可以说是相同特征值所对应的特征向量张成的（子）空间。矩阵&lt;span class="math">\(A\)&lt;/span>有多少个不同特征值，就有多少个特征子空间。&lt;/p>
&lt;p>由于特征子空间具有&lt;strong>几何特性&lt;/strong>，我们将特征子空间的维度成为&lt;strong>几何重数&lt;/strong>，而特征值的重数是&lt;strong>方程解出来的，具有代数特征&lt;/strong>，我们称特征值的重数为&lt;strong>代数重数&lt;/strong>。&lt;/p>
&lt;p>我们知道行列式&lt;span class="math">\(\det(A-\lambda I)=0\)&lt;/span>，特征子空间作为&lt;span class="math">\((A-\lambda I)x=0\)&lt;/span>的零空间必然有解，因此特征空间的维度必然是大于等于1。如果特征值重数是1，那么特征空间的维度必然等于1。而对于特征值根的重数大于1（即代数重数大于1），特征空间的维度取决于&lt;span class="math">\((A-\lambda I)x=0\)&lt;/span>的零空间的维度，此维度小于代数重数，即有&lt;span class="math">\(1\leq 几何充数 \leq 代数重数\)&lt;/span>。&lt;/p>
&lt;p>如果矩阵&lt;span class="math">\(A\)&lt;/span>各特征子空间的直和等于原完整空间&lt;span class="math">\(V^n\)&lt;/span>，那么&lt;span class="math">\(A\)&lt;/span>就有了&lt;span class="math">\(n\)&lt;/span>个线性无关的特征向量，此时这些特征向量可以构成一组特征基。&lt;/p>
&lt;h2 id="特征值的一些性质">特征值的一些性质&lt;/h2>
&lt;p>说了那么久的特征向量，我们再来看看特征值。特征值算是特征向量的副产品，虽然说我们在求解的时候通常是先求特征值，再求特征向量。&lt;/p>
&lt;p>特征值几个常见的性质如下：&lt;/p>
&lt;blockquote>
&lt;p>性质1：矩阵&lt;span class="math">\(A\)&lt;/span>的特征值和等于矩阵的迹：&lt;span class="math">\(\sum\limits_i \lambda_i=tr(A)\)&lt;/span>&lt;/p>
&lt;p>性质2：矩阵&lt;span class="math">\(A\)&lt;/span>的特征值积等于其行列式：&lt;span class="math">\(\prod\limits_i \lambda_i=\det(A)\)&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>这两个性质的证明可借助矩阵的特征多项式。我们可以将&lt;span class="math">\(\det(A-\lambda I)\)&lt;/span>写成零点式形式： &lt;span class="math">\[
f(\lambda)=(\lambda_1-\lambda)(\lambda_2-\lambda)\dotsb(\lambda_n-\lambda)
\]&lt;/span> 其中，&lt;span class="math">\(\lambda_i\)&lt;/span>都是特征值，且有可能相等也有可能是复数。显然，根据展开式系数有&lt;span class="math">\(\lambda^0=\prod\limits_i \lambda_i,\lambda^1=(-1)^{n-1}\sum\limits_i \lambda_i\)&lt;/span>。我们再根据行列式&lt;span class="math">\(\det(A-\lambda I)\)&lt;/span>的展开项对应可得&lt;span class="math">\(\lambda^0=\det(A),\lambda^1=(-1)^{n-1}\sum\limits_i a_{ii}\)&lt;/span>。&lt;/p>
&lt;blockquote>
&lt;p>性质3：若&lt;span class="math">\(λ\)&lt;/span>是可逆阵&lt;span class="math">\(A\)&lt;/span>的一个特征根，&lt;span class="math">\(x\)&lt;/span>为对应的特征向量，则&lt;span class="math">\(1/λ\)&lt;/span>是&lt;span class="math">\(A\)&lt;/span>的逆的一个特征根，&lt;span class="math">\(x\)&lt;/span>仍为对应的特征向量。&lt;/p>
&lt;/blockquote>
&lt;p>证明：若&lt;span class="math">\(x\)&lt;/span>为&lt;span class="math">\(A\)&lt;/span>对应的一个特征向量，&lt;span class="math">\(Ax=\lambda x\Rightarrow A^{-1}Ax=A^{-1}\lambda x\Rightarrow Ix=\lambda A^{-1}x\Rightarrow 1/\lambda x=A^{-1}x\)&lt;/span>。得证。&lt;/p>
&lt;p>另外，如果某个特征值为0，说明矩阵&lt;span class="math">\(A\)&lt;/span>是奇异矩阵，特征向量&lt;span class="math">\(x\)&lt;/span>为了满足&lt;span class="math">\(Ax=0\)&lt;/span>必须位于&lt;span class="math">\(A\)&lt;/span>的零空间内。在不可逆矩阵中，特征值就不能套用上面的性质。&lt;/p>
&lt;blockquote>
&lt;p>性质4：若&lt;span class="math">\(λ\)&lt;/span>是方阵A的一个特征根，&lt;span class="math">\(x\)&lt;/span>为对应的特征向量，则&lt;span class="math">\(λ\)&lt;/span>的&lt;span class="math">\(m\)&lt;/span>次方是&lt;span class="math">\(A\)&lt;/span>的&lt;span class="math">\(m\)&lt;/span>次方的一个特征根，&lt;span class="math">\(x\)&lt;/span>仍为对应的特征向量。&lt;/p>
&lt;/blockquote>
&lt;p>证明：若&lt;span class="math">\(x\)&lt;/span>为&lt;span class="math">\(A\)&lt;/span>对应的一个特征向量，&lt;span class="math">\(A^mx=A^{m-1}(Ax)=A^{m-1}\lambda x=\lambda A^{m-2}(Ax)=\dotsb=\lambda^m x\)&lt;/span>，即&lt;span class="math">\(A^mx=\lambda^m x\)&lt;/span>。得证。&lt;/p>
&lt;blockquote>
&lt;p>性质5：矩阵&lt;span class="math">\(A\)&lt;/span>与&lt;span class="math">\(A^T\)&lt;/span>拥有相同的特征值。&lt;/p>
&lt;/blockquote>
&lt;p>证明：我们通过行列式&lt;span class="math">\(\det(A-\lambda I)\)&lt;/span>计算得到矩阵&lt;span class="math">\(A\)&lt;/span>的特征值，根据行列式转置不变的性质，我们有&lt;span class="math">\(\det(A-\lambda I)=\det(A-\lambda I)^T=\det(A^T-\lambda I^T)=\det(A^T-\lambda I)\)&lt;/span>，即为&lt;span class="math">\(A^T\)&lt;/span>计算特征值的行列式。因此，矩阵&lt;span class="math">\(A\)&lt;/span>与&lt;span class="math">\(A^T\)&lt;/span>拥有相同的特征值。&lt;/p>
&lt;blockquote>
&lt;p>性质6：对于任何实数矩阵，如果其特征值为实数，那么特征向量是实向量。&lt;/p>
&lt;/blockquote>
&lt;p>证明：我们从矩阵的空间来理解比较容易。对于&lt;span class="math">\(n\)&lt;/span>阶实数矩阵而言，它是代表&lt;span class="math">\(\R^n\)&lt;/span>空间中的线性变换，这意味着任意&lt;span class="math">\(\R^n\)&lt;/span>中的向量，经过矩阵变换之后必然仍然在&lt;span class="math">\(\R^n\)&lt;/span>空间中。对于矩阵&lt;span class="math">\(A\)&lt;/span>，其求特征值所用的行列式所代表的矩阵&lt;span class="math">\(A-\lambda I\)&lt;/span>，如果也是实数矩阵，那么也是&lt;span class="math">\(\R^n\)&lt;/span>空间中的线性变换，同样也要满足&lt;span class="math">\(\R^n\)&lt;/span>线性空间中的变换的封闭性。而当特征值&lt;span class="math">\(\lambda\)&lt;/span>为实数时，&lt;span class="math">\(A-\lambda I\)&lt;/span>显然也是实数矩阵，那么特征向量&lt;span class="math">\(x\)&lt;/span>使得&lt;span class="math">\((A-\lambda I)x=0\)&lt;/span>就位于&lt;span class="math">\(A-\lambda I\)&lt;/span>的零空间中。矩阵的零空间&lt;span class="math">\(N(A)\)&lt;/span>和矩阵的行空间&lt;span class="math">\(Raw(A)\)&lt;/span>是&lt;span class="math">\(\R^n\)&lt;/span>中互补的两个子空间，因此&lt;span class="math">\(N(A),Raw(A)\)&lt;/span>都是实数向量的空间，因此位于零空间&lt;span class="math">\(N(A)\)&lt;/span>中的特征向量必然也是实数向量。&lt;/p>
&lt;h2 id="特征值分解与矩阵的幂">特征值分解与矩阵的幂&lt;/h2>
&lt;p>如果我们有了&lt;span class="math">\(n\)&lt;/span>个线性无关的特征向量，那么我们能够做一些新的改变，我们将矩阵&lt;span class="math">\(A\)&lt;/span>的具有&lt;span class="math">\(n\)&lt;/span>个线性无关的特征向量&lt;span class="math">\(q_i\)&lt;/span>作为列向量，组成一个可逆方阵&lt;span class="math">\(Q\)&lt;/span>： &lt;span class="math">\[
Q=[q_1,q_2,\dotsb,q_n]
\]&lt;/span> 将其与原矩阵&lt;span class="math">\(A\)&lt;/span>相乘可得： &lt;span class="math">\[
AQ=A[q_1,q_2,\dotsb,q_n]=[\lambda_1 q_1,\lambda_2 q_2,\dotsb,\lambda_n q_n]\\
=Q\begin{bmatrix}
\lambda_1&amp;amp;0&amp;amp;\dotsb&amp;amp;0\\
0&amp;amp;\lambda_2&amp;amp;\dotsb&amp;amp;0\\
\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\vdots\\
0&amp;amp;0&amp;amp;\dotsb&amp;amp;\lambda_1\\
\end{bmatrix}=Q\Lambda
\]&lt;/span> 这里的矩阵&lt;span class="math">\(\Lambda\)&lt;/span>为对角阵，它的非零元素就是矩阵&lt;span class="math">\(A\)&lt;/span>的特征值。因为矩阵&lt;span class="math">\(Q\)&lt;/span>中的列向量线性无关，因此逆矩阵&lt;span class="math">\(Q^{-1}\)&lt;/span>存在。在等式两侧左乘逆矩阵&lt;span class="math">\(Q^{-1}\)&lt;/span>，得到&lt;span class="math">\(\Lambda=Q^{-1}AQ\)&lt;/span>。相应地，&lt;span class="math">\(A=Q\Lambda Q^{-1}\)&lt;/span>。我们称之为矩阵的&lt;strong>特征分解&lt;/strong>，特征分解的过程也称为&lt;strong>相似对角化&lt;/strong>。&lt;/p>
&lt;blockquote>
&lt;p>特征分解（Eigendecomposition），又称谱分解（Spectral decomposition）是将矩阵分解为由其特征值和特征向量表示的矩阵之积的方法。 &lt;span class="math">\(A\)&lt;/span>可以被分解为&lt;span class="math">\(A=Q\Lambda {Q}^{-1}\)&lt;/span>，其中&lt;span class="math">\(Q\)&lt;/span>是&lt;span class="math">\(N×N\)&lt;/span>方阵，且其第&lt;span class="math">\(i\)&lt;/span>列为&lt;span class="math">\(A\)&lt;/span>的特征向量&lt;span class="math">\(q_i\)&lt;/span>。&lt;span class="math">\(Λ\)&lt;/span>是对角矩阵，其对角线上的元素为对应的特征值，也即&lt;span class="math">\(\Lambda_{ii}=\lambda_i\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>由于&lt;span class="math">\(Q\)&lt;/span>是由特征向量组成的矩阵，并且可逆，因此&lt;span class="math">\(Q\)&lt;/span>的必然是非奇异矩阵，它的列向量组必然是线性无关的。这也推出了矩阵可特征值分解的一个充要条件：&lt;/p>
&lt;blockquote>
&lt;p>定理：矩阵&lt;span class="math">\(A\)&lt;/span>有&lt;span class="math">\(n\)&lt;/span>个线性无关的特征向量&lt;span class="math">\(\Leftrightarrow\)&lt;/span>矩阵&lt;span class="math">\(A\)&lt;/span>可特征值分解。&lt;/p>
&lt;/blockquote>
&lt;p>在联合之前特征基、特征子空间、代数重数、几何重数的概念，我们将上述定理做出推广：&lt;/p>
&lt;blockquote>
&lt;p>推论：矩阵&lt;span class="math">\(A\)&lt;/span>有&lt;span class="math">\(n\)&lt;/span>个线性无关的特征向量&lt;span class="math">\(\Leftrightarrow\)&lt;/span>矩阵&lt;span class="math">\(A\)&lt;/span>存在一组特征基&lt;span class="math">\(\Leftrightarrow\)&lt;/span>矩阵&lt;span class="math">\(A\)&lt;/span>所有的特征值的几何重数等于代数重数&lt;span class="math">\(\Leftrightarrow\)&lt;/span>矩阵&lt;span class="math">\(A\)&lt;/span>所以特征子空间的直和为完整空间&lt;span class="math">\(\Leftrightarrow\)&lt;/span>矩阵&lt;span class="math">\(A\)&lt;/span>可特征值分解&lt;/p>
&lt;/blockquote>
&lt;p>需要注意的是，&lt;strong>可特征值分解和矩阵&lt;span class="math">\(A\)&lt;/span>本身是不是非奇异无关，只和&lt;span class="math">\(A\)&lt;/span>的特征值数量有关&lt;/strong>，奇异矩阵也可能有特征值分解，如下例： &lt;span class="math">\[
A=\begin{bmatrix}
1&amp;amp;1\\0&amp;amp;0
\end{bmatrix}=\begin{bmatrix}
1&amp;amp;-1\\0&amp;amp;1
\end{bmatrix}\begin{bmatrix}
1&amp;amp;0\\0&amp;amp;0
\end{bmatrix}\begin{bmatrix}
1&amp;amp;1\\0&amp;amp;1
\end{bmatrix}
\]&lt;/span> 而非奇异矩阵也有可能没有特征值分解，例如&lt;span class="math">\(\begin{bmatrix}1&amp;amp;2\\0&amp;amp;1\end{bmatrix}\)&lt;/span>。&lt;/p>
&lt;h3 id="矩阵幂的快捷计算">矩阵幂的快捷计算&lt;/h3>
&lt;p>特征值分解的一个重要应用是计算矩阵的幂。根据特征分解公式&lt;span class="math">\(\mathbf{A}=\mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^{-1}\)&lt;/span>，有 &lt;span class="math">\[
A^m=(Q\Lambda Q^{-1})^m=Q\Lambda Q^{-1}Q\Lambda Q^{-1}\dotsb Q\Lambda Q^{-1}=Q\Lambda^m Q^{-1}
\]&lt;/span> 这大大方便了矩阵的幂计算。&lt;/p>
&lt;p>同时，我们观察&lt;span class="math">\(A^m\)&lt;/span>分解后的结果&lt;span class="math">\(Q\Lambda^m Q^{-1}\)&lt;/span>，如果当&lt;span class="math">\(m\rightarrow ∞\)&lt;/span>时，&lt;span class="math">\(A^m\rightarrow 0\)&lt;/span>，我们称矩阵&lt;span class="math">\(A\)&lt;/span>是&lt;strong>稳定的&lt;/strong>。那么根据&lt;span class="math">\(A^m=Q\Lambda^m Q^{-1}\)&lt;/span>，只有当&lt;span class="math">\(\Lambda^m\rightarrow 0\)&lt;/span>时，&lt;span class="math">\(A\)&lt;/span>才是稳定的。这就要求&lt;span class="math">\(A\)&lt;/span>的最大特征值的模要小于1，即&lt;span class="math">\(|\max \lambda_i|&amp;lt;1\)&lt;/span>。&lt;/p>
&lt;p>此外，当&lt;span class="math">\(m\)&lt;/span>很大时，我们也发现最大的特征值&lt;span class="math">\(\max \lambda_i\)&lt;/span>对矩阵的幂产生的作用最大，因此我们也可用矩阵的最大特征值估计一些结果。&lt;/p>
&lt;h2 id="投影矩阵的特征值与特征向量">投影矩阵的特征值与特征向量&lt;/h2>
&lt;p>假设投影矩阵&lt;span class="math">\(P\)&lt;/span>是一个&lt;span class="math">\(n×n\)&lt;/span>维矩阵。由于&lt;span class="math">\(P\)&lt;/span>是幂等的，即&lt;span class="math">\(P^2=P\)&lt;/span>，因此对于特征向量&lt;span class="math">\(x\)&lt;/span>有 &lt;span class="math">\[
\left .
\begin{aligned}
P^2x=\lambda^2 x\\
Px=\lambda x\\
P^2=P
\end{aligned}
\right \}\Rightarrow \lambda^2 x = \lambda x
\]&lt;/span> 由于特征向量不为0，因此有 &lt;span class="math">\[
\lambda^2=\lambda\Rightarrow \lambda=0,1
\]&lt;/span> 即投影矩阵的特征值只能是0或1。&lt;/p>
&lt;p>若该投影矩阵的列空间&lt;span class="math">\(Col(P)\)&lt;/span>的秩为&lt;span class="math">\(r\)&lt;/span>，那么任意列空间的元素都是特征向量，因为满足&lt;span class="math">\(Px=1×x\)&lt;/span>，所以我们可以从列空间中挑选出&lt;span class="math">\(r\)&lt;/span>个线性无关的特征向量。同时，对于投影矩阵的零空间&lt;span class="math">\(N(P)\)&lt;/span>，其是&lt;span class="math">\(n-r\)&lt;/span>维的，其中所有的向量皆满足&lt;span class="math">\(Px=0=0×x\)&lt;/span>，因此所有零空间中的向量也是&lt;span class="math">\(P\)&lt;/span>的特征向量，从而我们也能从零空间中找出&lt;span class="math">\(n-r\)&lt;/span>个线性无关的特征向量。&lt;/p>
&lt;p>我们还知道投影矩阵是对称矩阵，即&lt;span class="math">\(P^T=P\)&lt;/span>，因此其列空间和行空间是一样的。根据矩阵四类空间的性质（参考笔记&lt;a href="线性代数与矩阵之四类空间.md">线性代数与矩阵之四类空间&lt;/a>），零矩阵和行矩阵垂直，因此零矩阵中元素皆垂直于行空间元素，列空间等于行空间的&lt;span class="math">\(r\)&lt;/span>个特征向量必然也垂直与零空间中的&lt;span class="math">\(n-r\)&lt;/span>个特征向量。这样我们就找到了&lt;span class="math">\(n\)&lt;/span>个线性无关的特征向量，即投影矩阵&lt;span class="math">\(P\)&lt;/span>必然可特征分解。（所有的对称矩阵都满足这个条件，因此所有的对称矩阵都是可特征分解的。）&lt;/p>
&lt;p>总结：投影矩阵必然可特征分解，且其特征值只有0和1。&lt;/p></description></item><item><title>线性代数与矩阵之正交（酉）矩阵与正交化</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E6%AD%A3%E4%BA%A4%E9%85%89%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E4%BA%A4%E5%8C%96/</link><pubDate>Wed, 11 May 2022 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E6%AD%A3%E4%BA%A4%E9%85%89%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%AD%A3%E4%BA%A4%E5%8C%96/</guid><description>
&lt;h2 id="线性代数与矩阵之正交酉矩阵与正交化">线性代数与矩阵之正交（酉）矩阵与正交化&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#正交向量组">正交向量组&lt;/a>&lt;/li>
&lt;li>&lt;a href="#正交矩阵">正交矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#酉矩阵">酉矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#施密特正交化">施密特正交化&lt;/a>&lt;/li>
&lt;li>&lt;a href="#qr分解">QR分解&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>本笔记将系统的介绍矩阵中正交的相关概念，包括正交向量（组），正交矩阵以及酉矩阵、施密特正交化以及矩阵的QR分解等。&lt;/p>
&lt;h2 id="正交向量组">正交向量组&lt;/h2>
&lt;blockquote>
&lt;p>正交向量组：一组非零的两两正交(即内积为0)的向量构成的向量组，用数学语言可写为：有一组向量&lt;span class="math">\((q_1,q_2,\dotsb,q_n)\)&lt;/span>，向量之间两两满足 &lt;span class="math">\[q_i^Tq_j=&amp;lt;q_i,q_j&amp;gt;=\begin{cases}
0,i\neq j\\
a&amp;gt;0,i=j
\end{cases}\]&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>如果我们要求当&lt;span class="math">\(i=j\)&lt;/span>时的内积&lt;span class="math">\(a=1\)&lt;/span>，则称&lt;span class="math">\((q_1,q_2,\dotsb,q_n)\)&lt;/span>为标准正交向量组，所为“标准”就是其每个向量模长为单位长度1，相应的将向量长度化为1的过程就叫做&lt;strong>标准化（Normalization）&lt;/strong>。（此外，如果这个标准正交向量组的个数等于空间的维度&lt;span class="math">\(n\)&lt;/span>，那么这一组标准正交向量可以作为空间的标准正交基。因为非零正交的向量必然线性无关）&lt;/p>
&lt;h2 id="正交矩阵">正交矩阵&lt;/h2>
&lt;p>在矩阵论中，正交矩阵（英语：orthogonal matrix）是一个方阵&lt;span class="math">\(Q\)&lt;/span>，其&lt;strong>元素为实数&lt;/strong>，而且&lt;strong>行向量与列向量皆为正交的单位向量&lt;/strong>，使得该矩阵的&lt;strong>转置矩阵&lt;/strong>有如下特性： &lt;span class="math">\[Q^{T}Q=QQ^{T}=I\]&lt;/span> 显而易见，&lt;span class="math">\(Q^{T}=Q^{-1}\)&lt;/span>即&lt;strong>正交矩阵的转置为其逆矩阵&lt;/strong>。这算是正交矩阵最重要的性质。这也说明，矩阵&lt;span class="math">\(Q\)&lt;/span>的列向量组&lt;span class="math">\((Cq_1,Cq_2,\dotsb,Cq_n)\)&lt;/span>是一组标准正交向量。典型的正交矩阵有单位阵&lt;span class="math">\(I\)&lt;/span>，置换矩阵，标准化的Hadamard等。&lt;/p>
&lt;h3 id="酉矩阵">酉矩阵&lt;/h3>
&lt;p>酉矩阵是正交矩阵在复数空间&lt;span class="math">\(\mathbb{C}^n\)&lt;/span>的推广。酉矩阵（又译作幺正矩阵，英语：unitary matrix）是一个&lt;span class="math">\(n×n\)&lt;/span>复数方块矩阵&lt;span class="math">\(U\)&lt;/span>，其满足以下性质： &lt;span class="math">\[U^\ast U=UU^{\ast}=I_{n}\]&lt;/span> 其中&lt;span class="math">\(U\ast\)&lt;/span>是&lt;span class="math">\(U\)&lt;/span>的共轭转置，&lt;span class="math">\(I_n\)&lt;/span>是&lt;span class="math">\(n×n\)&lt;/span>单位矩阵。同样的，酉矩阵的逆矩阵就是共轭转置： &lt;span class="math">\[
U^{-1}=U^{*}
\]&lt;/span> 显然，&lt;span class="math">\(U\)&lt;/span>的列（行）向量组是在&lt;span class="math">\(\mathbb{C}^n\)&lt;/span>上的一组标准正交基。&lt;/p>
&lt;h2 id="施密特正交化">施密特正交化&lt;/h2>
&lt;p>请看网页资料&lt;a href="../../网页资料/线性代数与矩阵之Gram-Schmidt正交化.html">线性代数与矩阵之Gram-Schmidt正交化.html&lt;/a>&lt;/p>
&lt;p>原文地址&lt;a href="https://ccjou.wordpress.com/2010/04/22/gram-schmidt-正交化與-qr-分解/">https://ccjou.wordpress.com/2010/04/22/gram-schmidt-正交化與-qr-分解/&lt;/a>&lt;/p>
&lt;h2 id="qr分解">QR分解&lt;/h2>
&lt;p>某种程度上来说，矩阵的QR分解就是施密特正交化的矩阵化表示。对矩阵&lt;span class="math">\(A\)&lt;/span>进行施密特正交化得到&lt;span class="math">\(Q\)&lt;/span>，而求取&lt;span class="math">\(R\)&lt;/span>的过程是使用已经求取的标准正交基反推原来的列向量。&lt;/p></description></item><item><title>线性代数与矩阵之投影与子空间</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E6%8A%95%E5%BD%B1%E4%B8%8E%E5%AD%90%E7%A9%BA%E9%97%B4/</link><pubDate>Tue, 10 May 2022 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E6%8A%95%E5%BD%B1%E4%B8%8E%E5%AD%90%E7%A9%BA%E9%97%B4/</guid><description>
&lt;h2 id="线性代数与矩阵之投影与子空间">线性代数与矩阵之投影与子空间&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#引子">引子&lt;/a>&lt;/li>
&lt;li>&lt;a href="#投影从向量到子空间投影">投影——从向量到子空间投影&lt;/a>&lt;/li>
&lt;li>&lt;a href="#投影的最小误差要求">投影的最小误差要求&lt;/a>&lt;/li>
&lt;li>&lt;a href="#向量到向量的投影">向量到向量的投影&lt;/a>&lt;/li>
&lt;li>&lt;a href="#向量的投影矩阵">向量的投影矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#子空间投影">子空间投影&lt;/a>&lt;/li>
&lt;li>&lt;a href="#投影矩阵与子空间关系">投影矩阵与子空间关系&lt;/a>&lt;/li>
&lt;li>&lt;a href="#再谈投影和误差">再谈投影和误差&lt;/a>&lt;/li>
&lt;li>&lt;a href="#最小二乘法与子空间投影">最小二乘法与（子）空间投影&lt;/a>&lt;/li>
&lt;li>&lt;a href="#最小二乘法">最小二乘法&lt;/a>&lt;/li>
&lt;li>&lt;a href="#ata不可逆时的处理">&lt;span class="math">\(A^TA\)&lt;/span>不可逆时的处理&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="引子">引子&lt;/h2>
&lt;p>注：本文中默认矩阵&lt;span class="math">\(A\)&lt;/span>的形式为：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/bordermatrix.png" alt="bordermatrix" />&lt;p class="caption">bordermatrix&lt;/p>
&lt;/div>
&lt;p>在&lt;a href="线性代数与矩阵之四类空间.md">《线性代数与矩阵之四类空间》&lt;/a>笔记中，我们提到了四个空间与方程的可解性，讨论的都是解存在以及解系的情况。那如果&lt;span class="math">\(Ax=b\)&lt;/span>这个线性方程组中，解不存在怎么办？比如我们需要知道一个人的平面位置，但是我们经过多次间接测量&lt;span class="math">\((x_i,y_i)\)&lt;/span>（假设间接测量和实际位置存在某种线性关系），得到了很多组结果： &lt;span class="math">\[
\begin{bmatrix}
x_1&amp;amp;y_1\\x_2&amp;amp;y_2\\x_3&amp;amp;y_3\\\vdots&amp;amp;\vdots\\x_m&amp;amp;y_m\\
\end{bmatrix}\begin{bmatrix}\theta_1\\\theta_2\end{bmatrix}=\begin{bmatrix}b_1\\b_2\end{bmatrix}
\]&lt;/span> 显然，通常这个方程组时不可解的，那么有没有一种方法，能得出尽量精确的解呢？&lt;/p>
&lt;p>答案是有的，尽量近似的解获得方式如下（暂时不考虑&lt;span class="math">\(A^TA\)&lt;/span>不可逆）： &lt;span class="math">\[
A^TA\Theta=A^Tb\Rightarrow \hat{\Theta}=(A^TA)^{-1}A^Tb
\]&lt;/span> 注意，这里的矩阵&lt;span class="math">\(A\)&lt;/span>&lt;strong>并不是方阵&lt;/strong>，因此&lt;span class="math">\((A^TA)^{-1}\neq A^{-1}(A^T)^{-1}\)&lt;/span>，&lt;span class="math">\(A,A^T\)&lt;/span>的逆不存在的。&lt;/p>
&lt;p>其中，&lt;span class="math">\(A^Tb\)&lt;/span>和衍生出来的投影矩阵&lt;span class="math">\(A(A^TA)^{-1}A^Tb\)&lt;/span>的由来就是这篇笔记的重点。&lt;/p>
&lt;h2 id="投影从向量到子空间投影">投影——从向量到子空间投影&lt;/h2>
&lt;p>想象我们站在冬日的阳光下，阳光照在我们身上。在给我们带来温暖与惬意的同时，也在平地上留下了一个影子，这就是投影在生活中最常见的情形。而此时的影子是三维世界的我们在二维平面成的像，当然阳光的角度，地面是不是斜坡都会影响影子的最终形态。&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/投影影子.jpeg" alt="投影影子" />&lt;p class="caption">投影影子&lt;/p>
&lt;/div>
&lt;p>线性代数与矩阵中也存在类似的过程——&lt;strong>投影&lt;/strong>。投影是一种高维事物（如向量）往低维子空间投射影子的过程，而这个低维子空间中的影子应该是子空间中&lt;strong>与原来事物相似&lt;/strong>的存在。如果用严格的数学语言描述：&lt;/p>
&lt;blockquote>
&lt;p>投影：有一属于向量空间&lt;span class="math">\(V\)&lt;/span>的子空间&lt;span class="math">\(W\)&lt;/span>，该子空间的一个投影&lt;span class="math">\(P\)&lt;/span>需使得&lt;span class="math">\(\forall u\in V,P(u)\in W\)&lt;/span>，并且&lt;span class="math">\(\forall u\in W\)&lt;/span>，有&lt;span class="math">\(P(u)=u\)&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>上面这句话可解释为，&lt;span class="math">\(P\)&lt;/span>是向量空间&lt;span class="math">\(V\)&lt;/span>到子空间&lt;span class="math">\(W\)&lt;/span>投影，那么&lt;span class="math">\(P\)&lt;/span>将所有&lt;span class="math">\(V\)&lt;/span>中的元素都映射到&lt;span class="math">\(W\)&lt;/span>中，而且&lt;span class="math">\(P\)&lt;/span>在&lt;span class="math">\(W\)&lt;/span>上是恒等变换。虽然这个定义没有问题，但是满足这个定义的投影&lt;span class="math">\(P\)&lt;/span>显然不是唯一的，如下图所示，各个&lt;span class="math">\(p _i\)&lt;/span>都可以算作投影的影子。&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/投影结果.drawio.svg" alt="投影结果.drawio.svg" />&lt;p class="caption">投影结果.drawio.svg&lt;/p>
&lt;/div>
&lt;p>在这些影子中，总得有好有坏吧。我们可以设立一个指标：&lt;strong>影子向量和原来向量的差别或误差&lt;/strong>。差别（误差）越小，也就是越近似，那么这个影子就保留了原向量尽可能多的信息，因此最好的投影会让二者具有“最近似性”关系。&lt;/p>
&lt;p>其实，这种追求最小误差的投影，叫做&lt;strong>正交投影&lt;/strong>，正交投影是我们用得最多的投影方式，一个子空间的正交投影是唯一的。&lt;strong>斜投影&lt;/strong>有时用来提及非正交投影，斜投影常常会扭曲向量的尺寸，因此用的不多。我们这里先提一下这些概念，本文其实说的投影都是正交投影。&lt;/p>
&lt;h3 id="投影的最小误差要求">投影的最小误差要求&lt;/h3>
&lt;p>那么，如果体现投影的“最近似”特性呢？由于从高维空间到子空间的投影是不唯一的，就像阳光可以顺着不同的方向照射，同一个地面产生的影子也是不一样的。如果原来的向量&lt;span class="math">\(\vec{b}\)&lt;/span>产生的投影向量是&lt;span class="math">\(\vec{p}\)&lt;/span>，那么它们之间的误差就是&lt;span class="math">\(\vec{e}=\vec{b}-\vec{p}\)&lt;/span>。“最近似”特性就是希望误差&lt;span class="math">\(\vec{e}\)&lt;/span>最小。根据点与空间的关系可知，&lt;strong>最小化&lt;span class="math">\(\vec{e}\)&lt;/span>相当于让其成为向量到空间的距离&lt;/strong>。&lt;/p>
&lt;p>那么这个空间&lt;span class="math">\(V\)&lt;/span>到子空间&lt;span class="math">\(W\)&lt;/span>的投影&lt;span class="math">\(P\)&lt;/span>到底怎么求？以及如何在低维子空间中找到任意&lt;span class="math">\(V\)&lt;/span>中向量的影子呢？就是这一章节的阐述重点。&lt;/p>
&lt;h3 id="向量到向量的投影">向量到向量的投影&lt;/h3>
&lt;p>空间中，最简单的子空间就是一维子空间（除了零向量），直接来说就是一个向量所在的过原点的直线，且该一维子空间由这个向量确定。一维子空间的投影是最基本的场景，也是其他更复杂场景的基础。一个向量往另一向量确定的一维子空间投影应该是什么呢？根据我们之前的要求，投影的影子应该是和原来向量差距最小的的。基本场景如下图所示：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/向量投影.drawio.svg" alt="向量投影" />&lt;p class="caption">向量投影&lt;/p>
&lt;/div>
&lt;p>在上面这个图中，&lt;span class="math">\(\vec{b}\)&lt;/span>为原向量，&lt;span class="math">\(\vec{p}\)&lt;/span>为其在向量&lt;span class="math">\(\vec{a}\)&lt;/span>所在的一维子空间的投影向量。根据向量的减法关系可知：&lt;span class="math">\(\vec{b}-\vec{p}=\vec{e}\)&lt;/span>，其中&lt;span class="math">\(\vec{e}\)&lt;/span>是&lt;span class="math">\(\vec{b},\;\vec{p}\)&lt;/span>的误差。用小学的知识也能知道，&lt;strong>当&lt;span class="math">\(\vec{e}\)&lt;/span>垂直于一维子空间所在直线&lt;/strong>的时候，误差最小。所以投影应该满足： &lt;span class="math">\[
\vec{e}\perp\vec{a}\\
\Leftrightarrow \vec{a}^T\vec{e}=0或\vec{a}\cdot \vec{e}=0
\]&lt;/span> 我们将&lt;span class="math">\(\vec{e}=\vec{b}-\vec{p}\)&lt;/span>代入，可得 &lt;span class="math">\[
\vec{a}^T(\vec{b}-\vec{p})=0\Leftrightarrow \vec{a}^T\vec{b}=\vec{a}^T\vec{p}
\]&lt;/span> 并且，&lt;span class="math">\(\vec{p}\)&lt;/span>与&lt;span class="math">\(\vec{a}\)&lt;/span>都是一维子空间的向量，二者共线，必然有&lt;span class="math">\(\vec{p}=x\vec{a}\)&lt;/span>，其中&lt;span class="math">\(x\)&lt;/span>是一个标量。代入上式可得： &lt;span class="math">\[
\vec{a}^T\vec{b}=\vec{a}^T(x\vec{a})\Leftrightarrow x=(\vec{a}^T\vec{a})^{-1}\vec{a}^T\vec{b}
\]&lt;/span> &lt;span class="math">\(x\)&lt;/span>是&lt;span class="math">\(\vec{p}\)&lt;/span>与&lt;span class="math">\(\vec{a}\)&lt;/span>的倍数关系，由&lt;span class="math">\(\vec{p}=x\vec{a}\)&lt;/span>可得： &lt;span class="math">\[
\vec{p}=\vec{a}(\vec{a}^T\vec{a})^{-1}\vec{a}^T\vec{b}
\]&lt;/span> 那么，对于任意的&lt;span class="math">\(\vec{b}\in \R^n\)&lt;/span>，为了追求误差最小化，其投影到&lt;span class="math">\(\vec{a}\)&lt;/span>所属的一维子空间投影矩阵为： &lt;span class="math">\[
P_a=\vec{a}(\vec{a}^T\vec{a})^{-1}\vec{a}^T
\]&lt;/span> 其中，&lt;span class="math">\(P_a\)&lt;/span>表示投影到向量&lt;span class="math">\(\vec{a}\)&lt;/span>所在子空间的投影矩阵。由于从&lt;span class="math">\(\vec{e}\perp\vec{a}\)&lt;/span>到投影矩阵&lt;span class="math">\(P_a\)&lt;/span>的推导过程都是充要关系，因此这种最小化误差的投影与投影矩阵&lt;span class="math">\(P\)&lt;/span>是一一对应的。&lt;/p>
&lt;h3 id="向量的投影矩阵">向量的投影矩阵&lt;/h3>
&lt;p>上一小节，我们得到了某向量所在的一维子空间的投影矩阵&lt;span class="math">\(P_a=\vec{a}(\vec{a}^T\vec{a})^{-1}\vec{a}^T\)&lt;/span>。我们现在来研究一些&lt;span class="math">\(P\)&lt;/span>有哪些特性与性质。&lt;/p>
&lt;p>首先，&lt;span class="math">\(P_a\)&lt;/span>与&lt;span class="math">\(\vec{a}\)&lt;/span>的关系非常密切，由&lt;span class="math">\(P_a=kaa^T,k=(\vec{a}^T\vec{a})^{-1}\)&lt;/span>可知，&lt;span class="math">\(P_a\)&lt;/span>中的每个列向量都是&lt;span class="math">\(\vec{a}\)&lt;/span>的倍数，即列向量之间都是线性相关的。这意味着&lt;span class="math">\(P_a\)&lt;/span>的列空间（值域）等于&lt;span class="math">\(\vec{a}\)&lt;/span>所在的一维子空间，&lt;span class="math">\(Col(P_a)=\R^1_a\)&lt;/span>。这满足了投影定义中，将所有&lt;span class="math">\(V\)&lt;/span>中的元素都映射到子空间&lt;span class="math">\(W\)&lt;/span>中的要求。&lt;/p>
&lt;p>同时，&lt;span class="math">\(P_a\)&lt;/span>的列向量的最大线性无关组为1，即&lt;span class="math">\(P_a\)&lt;/span>是个秩1矩阵。投影所保留的维度正好对应了一维子空间的维度，这也体现了&lt;span class="math">\(P_a\)&lt;/span>与一维子空间的映射关系。&lt;/p>
&lt;p>我们之前，在定义投影的时候也提过，&lt;span class="math">\(\forall u\in W\)&lt;/span>，有&lt;span class="math">\(P(u)=u\)&lt;/span>，也就是子空间中向量的投影是其本身。如果对一个已经经过投影的向量再做一次投影操作（因为第一次投影操作以及让影子属于子空间了），应该不再有变化，这从几何观点很容易理解。不难发现，&lt;span class="math">\(P_aP_a=\vec{a}(\vec{a}^T\vec{a})^{-1}[\vec{a}^T\vec{a}(\vec{a}^T\vec{a})^{-1}]_{=1}\vec{a}^T=\vec{a}(\vec{a}^T\vec{a})^{-1}\vec{a}^T=P_a\)&lt;/span>，即&lt;span class="math">\(P_a^2=P_a\)&lt;/span>。我们称这个性质为&lt;strong>幂等性&lt;/strong>，满足这个性质的矩阵为幂等矩阵。投影矩阵的幂等性还可以从信息的角度理解，投影矩阵的作用是将与子空间无关的其他维度剥离，只留下子空间维度的信息。因此经过投影的向量已经没有了其他维度信息，在投影（剥离）一次不改变结果。&lt;/p>
&lt;p>此外，我们还发现，投影矩阵是一个对称矩阵，即&lt;span class="math">\(P_a^T=P_a\)&lt;/span>。投影矩阵的对称性涉及到自伴随算子与空间的映射关系，是一个深刻且值得探讨的结论，但是需要的数学知识较深，这里不再讨论。&lt;/p>
&lt;p>总结，向量到一维子空间的投影矩阵有如下性质：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>投影矩阵&lt;span class="math">\(P_a\)&lt;/span>可有一维子空间所在向量&lt;span class="math">\(\vec{a}\)&lt;/span>构成，因此其列空间为该子空间。&lt;/li>
&lt;li>&lt;span class="math">\(P_a\)&lt;/span>的秩等于子空间维度。&lt;/li>
&lt;li>&lt;span class="math">\(P_a\)&lt;/span>是幂等矩阵；&lt;/li>
&lt;li>&lt;span class="math">\(P_a\)&lt;/span>是对称矩阵。&lt;/li>
&lt;/ol>
&lt;h3 id="子空间投影">子空间投影&lt;/h3>
&lt;p>我们已经讨论了向量到向量所在的一维子空间的投影，那么当子空间维数不仅仅是一维的，而是高维的子空间，那么其投影该怎么求呢？&lt;/p>
&lt;p>方法和一维子空间类似。假设我们要求矩阵&lt;span class="math">\(A\)&lt;/span>确定的投影矩阵&lt;span class="math">\(P_A\)&lt;/span>，由于子空间等于由矩阵&lt;span class="math">\(A\)&lt;/span>的列空间，整体空间中有一任意非零向量&lt;span class="math">\(\vec{b}\)&lt;/span>，其在子空间的投影为&lt;span class="math">\(\vec{p}\)&lt;/span>，因为&lt;span class="math">\(\vec{p}\)&lt;/span>位于&lt;span class="math">\(A\)&lt;/span>的列空间，所以可以用&lt;span class="math">\(A\)&lt;/span>的列向量的线性组合&lt;span class="math">\(\hat{x}_1\vec{c}_1+\hat{x}_2\vec{c}_2+\dotsb+\hat{x}_n\vec{c}_n\)&lt;/span>表示，其中&lt;span class="math">\(\vec{c}_i\)&lt;/span>是&lt;span class="math">\(A\)&lt;/span>的一个&lt;span class="math">\(m×1\)&lt;/span>的列向量，将其写成矩阵形式为：&lt;span class="math">\(\vec{p}=A\hat{x}\)&lt;/span>。&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/3dim_projection.png" alt="3dim_projection.png" />&lt;p class="caption">3dim_projection.png&lt;/p>
&lt;/div>
&lt;p>同样的，我们希望误差&lt;span class="math">\(\vec{e}=\vec{b}-\vec{p}\)&lt;/span>最小，那么根据高中立体几何知识可知：&lt;strong>只有当误差&lt;span class="math">\(\vec{e}\)&lt;/span>垂直与子空间时，&lt;span class="math">\(e\)&lt;/span>的长度最短&lt;/strong>。此时，&lt;span class="math">\(\vec{e}\)&lt;/span>应垂直于子空间中所有向量，包括&lt;span class="math">\(A\)&lt;/span>的所有列向量，即 &lt;span class="math">\[
\vec{e}\perp Col(A)\\
\Leftrightarrow A^T\vec{e}=\vec{0}或 c_i\cdot \vec{e}=0\;\forall i\in\{1,\dotsb,n\}
\]&lt;/span> 其中，&lt;span class="math">\(Col(A)\)&lt;/span>表示矩阵&lt;span class="math">\(A\)&lt;/span>的列空间，&lt;span class="math">\(c_i\)&lt;/span>是矩阵&lt;span class="math">\(A\)&lt;/span>的一列。将&lt;span class="math">\(\vec{e}=\vec{b}-\vec{p},\;\vec{p}=A\hat{x}\)&lt;/span>代入上式可得： &lt;span class="math">\[
A^T(\vec{b}-\vec{p})=0\Leftrightarrow A^T\vec{b}=A^T\vec{p}\Leftrightarrow A^T\vec{b}=A^TA\hat{x}
\]&lt;/span> 我们先只考虑&lt;span class="math">\(A^TA\)&lt;/span>是可逆的情形，可得： &lt;span class="math">\[
\hat{x}=(A^TA)^{-1}A^T\vec{b}
\]&lt;/span> 而&lt;span class="math">\(\hat{x}\)&lt;/span>又是&lt;span class="math">\(\vec{p}\)&lt;/span>用矩阵&lt;span class="math">\(A\)&lt;/span>列向量线性表示的系数，即&lt;span class="math">\(\vec{p}=A\hat{x}\)&lt;/span>。综上可得，对于空间中任意向量&lt;span class="math">\(\vec{b}\in \R^m\)&lt;/span>，在误差&lt;span class="math">\(\vec{e}\)&lt;/span>最小化的正交投影要求下，其投影到子空间&lt;span class="math">\(Col(A)\)&lt;/span>的结果为： &lt;span class="math">\[
\vec{p}=A(A^TA)^{-1}A^T\vec{b}
\]&lt;/span> 相应的，由&lt;span class="math">\(A\)&lt;/span>所确定的投影矩阵可定义为： &lt;span class="math">\[
P_A=A(A^TA)^{-1}A^T
\]&lt;/span>&lt;/p>
&lt;h3 id="投影矩阵与子空间关系">投影矩阵与子空间关系&lt;/h3>
&lt;p>上一小节已经求出了投影矩阵&lt;span class="math">\(P_A=A(A^TA)^{-1}A^T\)&lt;/span>，其中&lt;span class="math">\(A_{m×n}\)&lt;/span>为&lt;span class="math">\(m×n\)&lt;/span>矩阵，那么投影矩阵与&lt;span class="math">\(A\)&lt;/span>所构成的子空间是什么关系呢？&lt;/p>
&lt;p>我们首先研究&lt;span class="math">\(P_A\)&lt;/span>的列空间的秩。由于我们先假设&lt;span class="math">\(A^TA\)&lt;/span>是可逆的，因此其为一个&lt;span class="math">\(n×n\)&lt;/span>维可逆矩阵，因此有&lt;span class="math">\(Rank(A^TA)=n\)&lt;/span>。同时由于两个秩为&lt;span class="math">\(r\)&lt;/span>的矩阵乘积秩必然也不大于&lt;span class="math">\(r\)&lt;/span>（这是因为矩阵右乘或左乘分别是到其行空间或列空间的映射，因此矩阵乘法不可能升维），所以&lt;span class="math">\(Rank(A)=Rank(A^T)\geq Rank(A^TA)=n\)&lt;/span>。而又因为矩阵的秩小于等于行数和列数，即&lt;span class="math">\(Rank(A)=Rank(A^T)\leq \min\{m,n\}\)&lt;/span>，所以有&lt;span class="math">\(Rank(A)=Rank(A^T)=n\leq m\)&lt;/span>。&lt;/p>
&lt;p>有了矩阵秩的信息，我们再来看看投影矩阵&lt;span class="math">\(P_A\)&lt;/span>的秩，我们发现&lt;span class="math">\(P_A\)&lt;/span>的秩并不好求，因此我们这里用一个夹逼的技巧，看看矩阵&lt;span class="math">\(P_AA\)&lt;/span>的秩，易得 &lt;span class="math">\[
P_AA=A\underbrace{(A^TA)^{-1}A^TA}_{=I}=A
\]&lt;/span> 根据&lt;strong>两个矩阵乘积的秩必然不大于任一个矩阵的秩&lt;/strong>这一特性，有： &lt;span class="math">\[
\left .
\begin{aligned}
rank(P_A)≥rank(P_AA)=rank(A)=n\\
rank(P_A)=rank(A(A^TA)^{-1}A^T)≤rank(A)=n
\end{aligned}
\right \}
\Rightarrow rank(P_A)=n
\]&lt;/span> 即投影矩阵&lt;span class="math">\(P_A\)&lt;/span>的秩为&lt;span class="math">\(n\)&lt;/span>，等于子空间的维度。&lt;/p>
&lt;p>有了&lt;span class="math">\(P_A\)&lt;/span>的秩，我们再由矩阵乘法的积的列空间特性进行进一步推导。对于矩阵乘法&lt;span class="math">\(S=AX\)&lt;/span>，如果我们将&lt;span class="math">\(X\)&lt;/span>写成列向量组的形式&lt;span class="math">\(X=(x_1,x_2,\dotsb,x_k)\)&lt;/span>，则&lt;span class="math">\(S=AX\)&lt;/span>的乘积为&lt;span class="math">\((Ax_1,Ax_2,\dotsb,Ax_k)\)&lt;/span>。显然，矩阵&lt;span class="math">\(S\)&lt;/span>的每一列&lt;span class="math">\(s_i=Ax_i ∈ Col(A)\)&lt;/span>，因而&lt;span class="math">\(S\)&lt;/span>列向量组的线性组合也在&lt;span class="math">\(Col(A)\)&lt;/span>中，即&lt;span class="math">\(Col(S)\subseteq Col(A)\)&lt;/span>。依据此结论，我们可推断&lt;span class="math">\(Col(P_A)\subseteq Col(A)\)&lt;/span>。再综合&lt;span class="math">\(P_A\)&lt;/span>的秩为&lt;span class="math">\(n\)&lt;/span>等于&lt;span class="math">\(rank(A)\)&lt;/span>，我们能够断定&lt;span class="math">\(Col(P_A)=Col(A)\)&lt;/span>，即&lt;span class="math">\(A\)&lt;/span>所构成的子空间等于投影矩阵&lt;span class="math">\(P_A\)&lt;/span>的列空间。&lt;/p>
&lt;p>最后我们来看看投影矩阵还有哪些性质。根据一维子空间中的投影研究应该具有幂等性和对称性。不难验证：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>幂等性：&lt;span class="math">\(P_AP_A=A(A^TA)^{-1}\underbrace{A^TA(A^TA)^{-1}}_{=I}A^T=A(A^TA)^{-1}A^T=P_A\)&lt;/span>&lt;/li>
&lt;li>幂等矩阵的迹等于幂等矩阵的秩，即&lt;span class="math">\(tr(A)=rank(A)\)&lt;/span>（通过特征值证明）&lt;/li>
&lt;li>对称性：&lt;span class="math">\(P_A^T=(A(A^TA)^{-1}A^T)^T=(A^T)^T((A^TA)^{-1})^TA^T=A(A^TA)^{-1}A^T=P_A\)&lt;/span>&lt;/li>
&lt;/ol>
&lt;h3 id="再谈投影和误差">再谈投影和误差&lt;/h3>
&lt;p>通过投影，我们把空间中任一向量&lt;span class="math">\(\vec{b}\)&lt;/span>分成了投影子空间的部分&lt;span class="math">\(\vec{p}\)&lt;/span>和误差部分&lt;span class="math">\(\vec{e}\)&lt;/span>。从信息的角度，投影矩阵的作用就是保留子空间中的信息分量&lt;span class="math">\(\vec{p}\)&lt;/span>，去掉非子空间中的分量&lt;span class="math">\(\vec{e}\)&lt;/span>。之前，我们已经分析出，投影子空间等于矩阵&lt;span class="math">\(A\)&lt;/span>的列空间&lt;span class="math">\(Col(A)\)&lt;/span>。那么误差&lt;span class="math">\(\vec{e}\)&lt;/span>所在的空间有没有什么特殊之处呢？&lt;/p>
&lt;p>从之前的推导过程中，我们指出对于任意误差&lt;span class="math">\(\vec{e}\)&lt;/span>，为了使其最小化，应让其垂直与列空间&lt;span class="math">\(Col(A)\)&lt;/span>，即 &lt;span class="math">\[
\forall \vec{e},有\vec{e}\perp Col(A)
\]&lt;/span> 哈，这里很直观的告诉我们，所有&lt;span class="math">\(\vec{e}\)&lt;/span>所组成的子空间，应该垂直于列空间。而根据笔记&lt;a href="线性代数与矩阵之四类空间.md">线性代数与矩阵之四类空间&lt;/a>的内容，&lt;strong>垂直于列空间的空间正是左零空间&lt;/strong>！&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/投影分割空间.png" alt="投影分割空间.png" />&lt;p class="caption">投影分割空间.png&lt;/p>
&lt;/div>
&lt;p>这也就是说，我们永远可以把一个&lt;span class="math">\(\R^m\)&lt;/span>中的向量，通过投影拆分成两个分量：一个在&lt;span class="math">\(A\)&lt;/span>的列空间中，另一个分量垂直于&lt;span class="math">\(A\)&lt;/span>的列空间，即在&lt;span class="math">\(A\)&lt;/span>的左零空间中。同时这两个空间的直和，正好等于完整的空间&lt;span class="math">\(\R^m\)&lt;/span>！&lt;/p>
&lt;blockquote>
&lt;p>直和：设&lt;span class="math">\(V_1,V_2\)&lt;/span>是线性空间&lt;span class="math">\(V\)&lt;/span>的子空间，如果&lt;span class="math">\(V_1+V_2\)&lt;/span>中的每个向量分解式&lt;span class="math">\(\vec{\alpha}=\vec{\alpha}_1+\vec{\alpha}_2\)&lt;/span>唯一，其中&lt;span class="math">\(\vec{\alpha}_1∈V_1,\vec{\alpha}_2∈V_2\)&lt;/span>。那么称这个和为直和(direct sum)，记为&lt;span class="math">\(V_1⊕V_2\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;h2 id="最小二乘法与子空间投影">最小二乘法与（子）空间投影&lt;/h2>
&lt;p>我们说了这么长时间的投影，再回头看&lt;a href="#引子">引子&lt;/a>中的那个问题，是不是有点理解投影的作用了？&lt;/p>
&lt;p>对于一个方程数大于变量数的线性方程组而言（&lt;span class="math">\(m&amp;gt;n\)&lt;/span>），一般是没有解的。而投影就是让这个线性方程组有一个最近似的解&lt;span class="math">\(\vec{\hat{x}}\)&lt;/span>，使误差&lt;span class="math">\(\vec{e}=\vec{b}-A\vec{\hat{x}}\)&lt;/span>最小。这个方法在拟合方程如最小二乘法中得到了广泛应用。&lt;/p>
&lt;h3 id="最小二乘法">最小二乘法&lt;/h3>
&lt;p>“最小平方法”是对线性方程组，即方程个数比未知数更多的方程组，以回归分析求得近似解的标准方法，其核心是将&lt;strong>残差总和最小化&lt;/strong>，残差即观测值与模型提供的拟合值之间的差距，对应到矩阵化处理，就是使投影的误差最小。&lt;/p>
&lt;p>下面我们用一个例子来说明最小二乘法的矩阵化处理方法。&lt;/p>
&lt;p>假设在平面直角坐标系中有三个点&lt;span class="math">\(p_1,p_2,p_3\)&lt;/span>，分别为&lt;span class="math">\(\{(1,1), (2,2), (3,2)\}\)&lt;/span>需要求一条直线尽可能的经过这三个点，虽然不可能有直线完全经过三点，但可以要求直线与这三个点的误差尽量小。我们假设这条直线可写成&lt;span class="math">\(b=C+Dt\)&lt;/span>的形式，将数据代入写成方程组： &lt;span class="math">\[
\begin{cases}
C+D=1\\
C+2D=2\\
C+3D=2
\end{cases}\Leftrightarrow
\underbrace{\begin{bmatrix}
1&amp;amp;1\\1&amp;amp;2\\1&amp;amp;3\\
\end{bmatrix}}_A
\underbrace{\begin{bmatrix}
C\\D\\
\end{bmatrix}}_{\vec{x}}=
\underbrace{\begin{bmatrix}
1\\2\\2\\
\end{bmatrix}}_{\vec{b}}
\]&lt;/span>&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/最小二乘法.png" alt="最小二乘法.png" />&lt;p class="caption">最小二乘法.png&lt;/p>
&lt;/div>
&lt;p>显然，这个的方程&lt;span class="math">\(A\vec{x}=\vec{b}\)&lt;/span>是无解的，我们根据之前向量投影思路，解决办法就是求其最优解，最优解的含义即为误差最小： &lt;span class="math">\[
\min\|\vec{e}\|^2=\|A\vec{\hat{x}}-\vec{b}\|^2
\]&lt;/span> 我们需要的就是寻找具有&lt;strong>最小误差平方和&lt;/strong>的解&lt;span class="math">\(\vec{\hat{x}}\)&lt;/span>，这也是“最小二乘”这一名称的由来。&lt;/p>
&lt;p>前面投影章节已经指出，正交投影矩阵&lt;span class="math">\(P_A\)&lt;/span>能够最小化误差，所以&lt;span class="math">\(\vec{\hat{x}}\)&lt;/span>的值应该等于&lt;span class="math">\(\vec{b}\)&lt;/span>在&lt;span class="math">\(A\)&lt;/span>所在子空间的正交投影，即： &lt;span class="math">\[
\hat{x}=(A^TA)^{-1}A^T\vec{b}
\]&lt;/span> 根据上式解&lt;span class="math">\(A\vec{\hat{x}}=\vec{b}\)&lt;/span>可得： &lt;span class="math">\[
\hat{x}=\begin{bmatrix}
\hat{C}\\\hat{D}\\
\end{bmatrix}=\left (\begin{bmatrix}
1&amp;amp;1&amp;amp;1\\1&amp;amp;2&amp;amp;3\\
\end{bmatrix}\begin{bmatrix}
1&amp;amp;1\\1&amp;amp;2\\1&amp;amp;3\\
\end{bmatrix}\right)^{-1}\begin{bmatrix}
1&amp;amp;1&amp;amp;1\\1&amp;amp;2&amp;amp;3\\
\end{bmatrix}\begin{bmatrix}
1\\2\\2\\
\end{bmatrix}=\begin{bmatrix}
\frac{2}{3}\\\\\frac{1}{2}\\
\end{bmatrix}
\]&lt;/span> 即为方程误差最小的最优解。我们也可以验证，误差&lt;span class="math">\(\vec{e}=\vec{b}-A\vec{\hat{x}}=[1/6\; -1/3\; 1/6]^T\)&lt;/span>，&lt;span class="math">\(A^T\vec{e}=\vec{0}\Rightarrow Col(A)\perp\vec{e}\)&lt;/span>，投影向量&lt;span class="math">\(\vec{p}=A\vec{\hat{x}}\)&lt;/span>与&lt;span class="math">\(\vec{e}\)&lt;/span>正交，并且&lt;span class="math">\(\vec{e}\)&lt;/span>与矩阵&lt;span class="math">\(A\)&lt;/span>的列空间&lt;span class="math">\(Col(A)\)&lt;/span>正交。&lt;/p>
&lt;p>最小二乘法是投影矩阵的典型应用，再补充一个小点，在实数空间&lt;span class="math">\(\R^n\)&lt;/span>中，投影矩阵&lt;span class="math">\(P_A=A(A^TA)^{-1}A^T\)&lt;/span>；而在复数空间&lt;span class="math">\(\mathbb{C}^n\)&lt;/span>中，需要使用共轭转置代替，即&lt;span class="math">\(P_A=A(A^HA)^{-1}A^H\)&lt;/span>。&lt;/p>
&lt;h3 id="ata不可逆时的处理">&lt;span class="math">\(A^TA\)&lt;/span>不可逆时的处理&lt;/h3>
&lt;p>之前，我们一直假设&lt;span class="math">\(A^TA\)&lt;/span>是可逆的。然而，确实存在其不可逆的场景，比如一些未知量&lt;span class="math">\(x_i,x_j\)&lt;/span>存在线性关系。&lt;/p>
&lt;p>最简单的方法当时是从中挑出一些列，筛选出线性无关的特征，不保留相同的特征，保证不存在线性相关的特征，从而组成一个更小的矩阵&lt;span class="math">\(\tilde{A}\)&lt;/span>，使&lt;span class="math">\(\tilde{A}^T\tilde{A}\)&lt;/span>可逆。&lt;/p>
&lt;p>其次，我们可以增加样本量，即多增加几个方程，看看能不能破坏未知量&lt;span class="math">\(x_i,x_j\)&lt;/span>存在线性关系。&lt;/p>
&lt;p>最后，还可以采用正则化方法，对于正则化的方法，常见的是L1正则项和L2正则项。这超出了本文的阐述范围，有兴趣的读者可以找相关资料了解。&lt;/p></description></item><item><title>线性代数与矩阵之四类空间</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%9B%9B%E7%B1%BB%E7%A9%BA%E9%97%B4/</link><pubDate>Mon, 09 May 2022 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%9B%9B%E7%B1%BB%E7%A9%BA%E9%97%B4/</guid><description>
&lt;h2 id="线性代数与矩阵之四类空间">线性代数与矩阵之四类空间&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#矩阵的列空间与行空间">矩阵的列空间与行空间&lt;/a>&lt;/li>
&lt;li>&lt;a href="#列空间与线性方程组的解">列空间与线性方程组的解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#矩阵的零空间与左零空间">矩阵的零空间与左零空间&lt;/a>&lt;/li>
&lt;li>&lt;a href="#零空间与线性方程组的通解">零空间与线性方程组的通解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#各空间关系">各空间关系&lt;/a>&lt;/li>
&lt;li>&lt;a href="#秩的关系">秩的关系&lt;/a>&lt;/li>
&lt;li>&lt;a href="#正交关系">正交关系&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#子空间互补">子空间互补&lt;/a>&lt;/li>
&lt;/ul>&lt;/li>
&lt;li>&lt;a href="#四类空间与线性方程组的可解性">四类空间与线性方程组的可解性&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>对于一个&lt;span class="math">\(m×n\)&lt;/span>的矩阵&lt;span class="math">\(A\)&lt;/span>， &lt;span class="math">\[
A=\begin{bmatrix}
a_{11}&amp;amp;a_{12}&amp;amp;a_{13}&amp;amp;\dotsb&amp;amp;a_{1n}\\
a_{21}&amp;amp;a_{22}&amp;amp;a_{23}&amp;amp;\dotsb&amp;amp;a_{2n}\\
a_{31}&amp;amp;a_{32}&amp;amp;a_{33}&amp;amp;\dotsb&amp;amp;a_{3n}\\
\vdots&amp;amp;\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\vdots\\
a_{n1}&amp;amp;a_{n2}&amp;amp;a_{n3}&amp;amp;\dotsb&amp;amp;a_{nn}\\
\end{bmatrix}
\]&lt;/span> 皆有四类空间，即矩阵的&lt;strong>列向量组成的列空间（Column Space）&lt;/strong>、矩阵&lt;strong>行向量组成的行空间（Row Space）&lt;/strong>、零空间（Null Space）以及左零空间（Left Null Space）。&lt;/p>
&lt;p>注：&lt;strong>本文在没有特殊说明的时候，矩阵&lt;span class="math">\(A\)&lt;/span>都是此&lt;span class="math">\(m\times n\)&lt;/span>矩阵&lt;/strong>。&lt;/p>
&lt;h2 id="矩阵的列空间与行空间">矩阵的列空间与行空间&lt;/h2>
&lt;p>矩阵&lt;span class="math">\(A_{m\times n}\)&lt;/span>根据横向和纵向，我们可以将其分成列向量组或行向量组&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/bordermatrix.png" alt="bordermatrix" />&lt;p class="caption">bordermatrix&lt;/p>
&lt;/div>
&lt;p>其中，列向量组表示&lt;span class="math">\(A=(c_1,c_2\dotsb,c_n)\)&lt;/span>，行向量组表示&lt;span class="math">\(A=(r_1,r_2,\dotsb,r_m)^T\)&lt;/span>。&lt;/p>
&lt;blockquote>
&lt;p>列（行）空间：用&lt;span class="math">\(A\)&lt;/span>的所有列向量所张成的空间，称为列空间，记作&lt;span class="math">\(C(A)或Col(A)\)&lt;/span>；用&lt;span class="math">\(A\)&lt;/span>的所有行向量所张成的空间，称为行空间，记作&lt;span class="math">\(R(A)或Raw(A)\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>向量组张成空间的概念参见笔记&lt;a href="线性代数与矩阵之理解向量、线性变换与矩阵乘法.md">线性代数与矩阵之理解向量、线性变换与矩阵乘法&lt;/a>。每一个&lt;span class="math">\(c_i\)&lt;/span>是&lt;span class="math">\(m\times 1\)&lt;/span>向量，因此列空间必是&lt;span class="math">\(R^m\)&lt;/span>空间的子空间，同理行空间是&lt;span class="math">\(R^n\)&lt;/span>空间的子空间。&lt;/p>
&lt;p>如果从矩阵乘以向量&lt;span class="math">\(Ax=y\)&lt;/span>的角度来看列空间，我们可以发现，&lt;span class="math">\(Ax\)&lt;/span>的结果是列向量组&lt;span class="math">\((c_1,c_2\dotsb,c_n)\)&lt;/span>的线性组合，即&lt;span class="math">\(y\)&lt;/span>必然是列空间的向量。这表明列空间等同于该矩阵左乘向量的值域空间。同理，行空间是&lt;span class="math">\(x^TA=y^T\)&lt;/span>的值域空间。&lt;/p>
&lt;h3 id="列空间与线性方程组的解">列空间与线性方程组的解&lt;/h3>
&lt;p>如果将线性方程组写成矩阵的形式&lt;span class="math">\(Ax=b\)&lt;/span>，如果要求此方程有解，那么向量&lt;span class="math">\(b\)&lt;/span>必须要在矩阵&lt;span class="math">\(A\)&lt;/span>的列空间中。&lt;/p>
&lt;h2 id="矩阵的零空间与左零空间">矩阵的零空间与左零空间&lt;/h2>
&lt;blockquote>
&lt;p>零空间：所有满足&lt;span class="math">\(Ax=0\)&lt;/span>的向量&lt;span class="math">\(x\)&lt;/span>的集合就称之为矩阵&lt;span class="math">\(A\)&lt;/span>的零空间，记为&lt;span class="math">\(N(A)或Null(A)\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>如果矩阵A的各列线性无关，则&lt;span class="math">\(x\)&lt;/span>就只有零向量这个唯一解，如果&lt;span class="math">\(A\)&lt;/span>的各列线性相关(意味着降维了，进一步是行列式值为零)，那么&lt;span class="math">\(x\)&lt;/span>就有非零解。由于解&lt;span class="math">\(x\)&lt;/span>是&lt;span class="math">\(n\times 1\)&lt;/span>向量，因此零空间是&lt;span class="math">\(R^n\)&lt;/span>空间的子空间(通常小于&lt;span class="math">\(n\)&lt;/span>)。&lt;/p>
&lt;blockquote>
&lt;p>左零空间：所有满足&lt;span class="math">\(y^TA=A^Ty=0\)&lt;/span>的向量&lt;span class="math">\(y^T或y\)&lt;/span>的集合就称之为矩阵&lt;span class="math">\(A\)&lt;/span>的左零空间，记为&lt;span class="math">\(N(A^T)或Null(A^T)\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>显然，左零空间就是因为&lt;span class="math">\(y^T\)&lt;/span>向量在矩阵左侧。由于解&lt;span class="math">\(y\)&lt;/span>是&lt;span class="math">\(m\times 1\)&lt;/span>向量，因此左零空间是&lt;span class="math">\(R^m\)&lt;/span>空间的子空间(通常小于&lt;span class="math">\(m\)&lt;/span>)。&lt;/p>
&lt;h3 id="零空间与线性方程组的通解">零空间与线性方程组的通解&lt;/h3>
&lt;p>无论是零空间还是左零空间都是&lt;strong>解&lt;/strong>的特性。利用零空间和方程的一个特解，我们可以构造方程的通解。 &lt;span class="math">\[
Ax=b\Rightarrow Ax^\ast+Ax&amp;#39;=b
\]&lt;/span> 其中，&lt;span class="math">\(Ax^\ast=0\)&lt;/span>，&lt;span class="math">\(x^\ast\)&lt;/span>是零空间的仍一元素，而&lt;span class="math">\(x&amp;#39;\)&lt;/span>是方程组的任一个特解。&lt;span class="math">\(x^\ast\)&lt;/span>可以用零空间的一组基来表示，即 &lt;span class="math">\[
x^\ast=(z_1,z_2,\dotsb,z_r)\begin{bmatrix}
x_1\\x_2\\\dotsb\\z_r
\end{bmatrix}
\]&lt;/span> 其中，&lt;span class="math">\((z_1,z_2,\dotsb,z_r)\)&lt;/span>表示零空间的一组基，&lt;span class="math">\(z_i\)&lt;/span>为&lt;span class="math">\(n\times 1\)&lt;/span>维向量，下标&lt;span class="math">\(r\)&lt;/span>为零空间的维度。&lt;/p>
&lt;p>对于&lt;span class="math">\(Ax=0\)&lt;/span>的通解，还可以使用简化列阶梯形矩阵来求解，Matlab正是用此方法进行求解的。&lt;/p>
&lt;blockquote>
&lt;p>简化列阶梯形矩阵：简化列阶梯形矩阵或简约行梯形式矩阵（reduced row echelon form），也称作行规范形矩阵（row canonical form），如果满足额外的条件：每个首项系数是1，且是其所在列的唯一的非零元素。&lt;/p>
&lt;/blockquote>
&lt;p>例如： &lt;span class="math">\[{\displaystyle \left[{\begin{array}{ccccc}1&amp;amp;0&amp;amp;a_{1}&amp;amp;0&amp;amp;b_{1}\\0&amp;amp;1&amp;amp;a_{2}&amp;amp;0&amp;amp;b_{2}\\0&amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;b_{3}\end{array}}\right]}\]&lt;/span>&lt;/p>
&lt;p>简化列阶梯形矩阵与线性方程组的通解有关系，如果我们将所有基本列放到一起，如上例中是一个&lt;span class="math">\(I_{3\times 3}\)&lt;/span>，剩下的自由列为&lt;span class="math">\(F=\begin{bmatrix}a_1&amp;amp;b_1\\a_2&amp;amp;b_2\\0&amp;amp;b_3\end{bmatrix}\)&lt;/span>。在求解&lt;span class="math">\(Ax=0\)&lt;/span>时，我们分别把自由列（第3，5）列取（1，0）和（0，1）可得，零空间的一组基为： &lt;span class="math">\[
k_1\begin{bmatrix}-a_1\\-a_2\\1\\0\\0\end{bmatrix}+k_2\begin{bmatrix}
-b_1\\-b_2\\0\\-b_3\\1\end{bmatrix}
\]&lt;/span>&lt;/p>
&lt;h2 id="各空间关系">各空间关系&lt;/h2>
&lt;p>对于一个矩阵&lt;span class="math">\(A_{m\times n}\)&lt;/span>，其四个空间为&lt;/p>
&lt;ul>
&lt;li>列空间&lt;span class="math">\(C(A)\)&lt;/span>，是空间&lt;span class="math">\(R^m\)&lt;/span>的子空间，秩&lt;span class="math">\(r\)&lt;/span>为&lt;span class="math">\(A\)&lt;/span>的基本列个数，或&lt;span class="math">\(C(A)\)&lt;/span>的维度。&lt;/li>
&lt;li>零空间&lt;span class="math">\(N(A)\)&lt;/span>，是空间&lt;span class="math">\(R^n\)&lt;/span>的子空间，秩&lt;span class="math">\(n-r\)&lt;/span>为&lt;span class="math">\(A\)&lt;/span>的自由列个数，或&lt;span class="math">\(N(A)\)&lt;/span>的维度。&lt;/li>
&lt;li>行空间&lt;span class="math">\(C(A^T)=R(A)\)&lt;/span>，是空间&lt;span class="math">\(R^n\)&lt;/span>的子空间，秩&lt;span class="math">\(r\)&lt;/span>为&lt;span class="math">\(A^T\)&lt;/span>的基本列个数，或&lt;span class="math">\(R(A)\)&lt;/span>的维度。&lt;/li>
&lt;li>左零空间&lt;span class="math">\(N(A^T)\)&lt;/span>，是空间&lt;span class="math">\(R^m\)&lt;/span>的子空间，秩&lt;span class="math">\(m-r\)&lt;/span>为&lt;span class="math">\(A^T\)&lt;/span>的自由列个数，或&lt;span class="math">\(C(A^T)\)&lt;/span>的维度。&lt;/li>
&lt;/ul>
&lt;p>各空间的关系总结如下图：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/four-linear-subspaces.png" alt="four-linear-subspaces.png" />&lt;p class="caption">four-linear-subspaces.png&lt;/p>
&lt;/div>
&lt;h3 id="秩的关系">秩的关系&lt;/h3>
&lt;p>一个基本的秩的结论是列空间维度等于行空间维度，即&lt;span class="math">\(Rank(A)=Rank(A^T)\)&lt;/span>。这个结论太过显然，很多时候我们都未自习思考过。&lt;/p>
&lt;p>我们再来看列空间和零空间之间秩的关系。在&lt;span class="math">\(A_{m\times n}\)&lt;/span>中，列向量组中向量个数有&lt;span class="math">\(n\)&lt;/span>个，其中有&lt;span class="math">\(r_c\)&lt;/span>个线性无关的向量，那么根据线性无关向量个数和子空间维度的关系，我们可以知道列空间&lt;span class="math">\(C(A)\)&lt;/span>的秩为&lt;span class="math">\(r_c\)&lt;/span>。（算是矩阵值域的特性）&lt;/p>
&lt;p>而当我们在看方程组&lt;span class="math">\(Ax=0\)&lt;/span>时，当通过高斯消元法，可以得到一个上三角矩阵，但是主对角线元素不一定都是非0的，我们将主对角线非0的列叫基本列，主对角线等于0的自由列。根据三角矩阵秩与主对角元素的关系可知，基本列个数为&lt;span class="math">\(r_c\)&lt;/span>，那么自由列个数就是&lt;span class="math">\(n-c_r\)&lt;/span>。&lt;/p>
&lt;p>在解方程&lt;span class="math">\(x\)&lt;/span>过程中，我们给自由列任一的系数，而基本变量用自由变量来表示；也就是说，自由变量确定了一个值，基本变量也就随之确定了一个值。上面这个解集形式也被称为方程组的“通解”，因为它给出了方程组所有解的显示表示。自由列的个数解决了自由变量的个数，也就决定了零空间的维度，因此零空间维度是&lt;span class="math">\(n-r_c\)&lt;/span>。&lt;/p>
&lt;p>综上所述：&lt;span class="math">\(Rank(C(A))+Rank(N(A))=n\)&lt;/span>。同理，有&lt;span class="math">\(Rank(R(A))+Rank(N(A^T))=m\)&lt;/span>。这二者是从线性方程组与解的关系得来的。&lt;/p>
&lt;h3 id="正交关系">正交关系&lt;/h3>
&lt;p>先说结论：&lt;strong>列空间与左零空间是&lt;span class="math">\(R^m\)&lt;/span>的子空间，且二者正交；行空间与零空间是&lt;span class="math">\(R^n\)&lt;/span>的子空间，且二者正交&lt;/strong>。&lt;/p>
&lt;p>再看看其中的关键词：&lt;strong>正交&lt;/strong>，准确的说是&lt;strong>子空间正交&lt;/strong>。那么什么是子空间正交呢？&lt;/p>
&lt;blockquote>
&lt;p>子空间正交：子空间&lt;span class="math">\(S\)&lt;/span>与子空间&lt;span class="math">\(T\)&lt;/span>正交，则&lt;span class="math">\(S\)&lt;/span>中的&lt;strong>任意&lt;/strong>一个向量都和T中的&lt;strong>任意&lt;/strong>向量正交。&lt;/p>
&lt;/blockquote>
&lt;p>什么是向量正交，这个就太基本了，不再赘述。如果两个子空间正交，那么他们一定只能相交于零向量。因为，如果他们相较于某个非零向量&lt;span class="math">\(\vec{v}\)&lt;/span>，那么&lt;span class="math">\(\vec{v}\in S\cap T\)&lt;/span>，则要求&lt;span class="math">\(\vec{v}\)&lt;/span>必须和自己正交，而和自己正交的向量只有零向量，与假设矛盾。&lt;/p>
&lt;p>但是，按照如上定义如果我们要验证子空间的正交性，那么需要验证任意的向量，是很麻烦的。根据线性空间与基的关系，我们可以有如下推论：&lt;/p>
&lt;blockquote>
&lt;p>推论：如果向量和（子）空间的一组基正交，那么该向量和（子）空间正交。&lt;/p>
&lt;/blockquote>
&lt;p>根据此推论，我们再来看看式子&lt;span class="math">\(Ax=0\)&lt;/span>，显然&lt;span class="math">\(x_{n\times 1}\)&lt;/span>是零空间的任意向量。我们将矩阵&lt;span class="math">\(A\)&lt;/span>写成行向量组的形式，即 &lt;span class="math">\[
Ax=\begin{bmatrix}
r_1\\r_2\\ \vdots\\r_m
\end{bmatrix} x_{n\times 1}=\begin{bmatrix}
0\\0\\ \vdots\\0
\end{bmatrix}_{m\times 1}
\]&lt;/span> 注意，此处每一个&lt;span class="math">\(r_i\)&lt;/span>是一个&lt;span class="math">\(1\times n\)&lt;/span>的行向量。根据行空间的定义，它是由行向量组张成的空间，&lt;strong>因此这些行向量必然包含行空间的一组基&lt;/strong>。&lt;/p>
&lt;p>同时，由于&lt;span class="math">\(r_i x=0,i\in \{1,2,\cdots,m\}\)&lt;/span>，因此任一行向量与零空间的向量&lt;span class="math">\(x\)&lt;/span>都是正交的。又因为行向量必然包含行空间的一组基，那么零空间中的向量&lt;span class="math">\(x\)&lt;/span>正交于行空间的一组基，推得&lt;span class="math">\(x\)&lt;/span>正交于行空间。同时，&lt;span class="math">\(x\)&lt;/span>又是零空间中的任意向量，因此零空间是正交于行空间的。&lt;/p>
&lt;p>虽然有些啰嗦，但是我们再来阐述下列空间与左零空间的正交性。我们看式子&lt;span class="math">\(y^TA=0\)&lt;/span>，显然&lt;span class="math">\(y_{m\times 1}\)&lt;/span>是左零空间任意向量。我们将矩阵&lt;span class="math">\(A\)&lt;/span>写成列向量组的形式，即 &lt;span class="math">\[
y^TA=y^T\begin{bmatrix}
c_1&amp;amp;c_2&amp;amp;\cdots&amp;amp;c_n
\end{bmatrix}=\begin{bmatrix}
0&amp;amp;0&amp;amp; \cdots&amp;amp;0
\end{bmatrix}_{1\times n}
\]&lt;/span> 注意，此处每一个&lt;span class="math">\(c_j\)&lt;/span>是一个&lt;span class="math">\(m\times 1\)&lt;/span>的列向量。根据列空间的定义，它是由列向量组张成的空间，&lt;strong>因此这些列向量必然包含列空间的一组基&lt;/strong>。&lt;/p>
&lt;p>同时，由于&lt;span class="math">\(y^T c_j=0,j\in \{1,2,\cdots,n\}\)&lt;/span>，因此任一列向量与左零空间的向量&lt;span class="math">\(y^T\)&lt;/span>都是正交的。又因为列向量必然包含列空间的一组基，那么左零空间中的向量&lt;span class="math">\(y^T\)&lt;/span>正交于列空间的一组基，推得&lt;span class="math">\(y^T\)&lt;/span>正交于列空间。同时，&lt;span class="math">\(y^T\)&lt;/span>又是左零空间中的任意向量，因此左零空间是正交于列空间的。&lt;/p>
&lt;h4 id="子空间互补">子空间互补&lt;/h4>
&lt;blockquote>
&lt;p>补空间：在数学领域线性代数和泛函分析中，空间&lt;span class="math">\(V\)&lt;/span>的子空间&lt;span class="math">\(W\)&lt;/span>的正交补是正交于&lt;span class="math">\(W\)&lt;/span>中所有向量的所有&lt;span class="math">\(V\)&lt;/span>中向量的集合，其张成的空间成为&lt;span class="math">\(W^{\perp}\)&lt;/span>，即 &lt;span class="math">\[W^{\perp}=\{x\in V:\forall y\in W,&amp;lt;x,y&amp;gt;=0\}\]&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>我们再联系四个空间秩的关系，有&lt;/p>
&lt;ul>
&lt;li>&lt;span class="math">\(Rank(Raw(A))+Rank(N(A^T))=Rank(Col(A))+Rank(N(A^T))=m\)&lt;/span>可知，&lt;span class="math">\(R^m\)&lt;/span>被切割成&lt;span class="math">\(R^r\)&lt;/span>的列空间和&lt;span class="math">\(R^{m-r}\)&lt;/span>的左零空间。也可以说在&lt;span class="math">\(R^m\)&lt;/span>中列空间和左零空间&lt;strong>互补&lt;/strong>。&lt;/li>
&lt;li>&lt;span class="math">\(Rank(Col(A))+Rank(N(A))=Rank(Raw(A))+Rank(N(A))=n\)&lt;/span>可知，&lt;span class="math">\(R^n\)&lt;/span>被切割成&lt;span class="math">\(R^r\)&lt;/span>的行空间和&lt;span class="math">\(R^{n-r}\)&lt;/span>的零空间。也可以说在&lt;span class="math">\(R^n\)&lt;/span>中行空间和零空间&lt;strong>互补&lt;/strong>。&lt;/li>
&lt;/ul>
&lt;p>互补的子空间组合在一起就是完整的空间，这种组合到一起的操作又称直和。&lt;/p>
&lt;h2 id="四类空间与线性方程组的可解性">四类空间与线性方程组的可解性&lt;/h2>
&lt;p>MIT著名的线性代数课程是从线性方程组的解的角度引出四类空间的。会看最初的定义&lt;/p>
&lt;p>矩阵&lt;span class="math">\(A_{m\times n}\)&lt;/span>根据横向和纵向，我们可以将其分成列向量组或行向量组&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/bordermatrix.png" alt="bordermatrix" />&lt;p class="caption">bordermatrix&lt;/p>
&lt;/div>
&lt;p>其中，列向量组表示&lt;span class="math">\(A=(c_1,c_2\dotsb,c_n)\)&lt;/span>，行向量组表示&lt;span class="math">\(A=(r_1,r_2,\dotsb,r_m)^T\)&lt;/span>。&lt;/p>
&lt;p>在矩阵&lt;span class="math">\(A\)&lt;/span>与向量&lt;span class="math">\(x\)&lt;/span>的乘积&lt;span class="math">\(Ax=(c_1,c_2\dotsb,c_n)x=b\)&lt;/span>中，&lt;span class="math">\(b\)&lt;/span>是值，体现的是列向量的线性组合，所有可能的&lt;span class="math">\(b\)&lt;/span>组成了列空间即为值域，也就是说只有&lt;span class="math">\(b\)&lt;/span>是列空间的元素，方程才有解。同理，&lt;span class="math">\(y^TA=b^T\)&lt;/span>也只有当&lt;span class="math">\(b^T\)&lt;/span>是行空间的元素时，&lt;span class="math">\(y^T\)&lt;/span>才有解。&lt;/p>
&lt;p>当矩阵为列满秩，即&lt;span class="math">\(Rank(A)=n\leq m\)&lt;/span>时，方程只可能有0个或1个解。&lt;span class="math">\(b\)&lt;/span>在列空间中，只有一个解；不在时没有解。&lt;/p>
&lt;p>线性方程组&lt;span class="math">\(Ax=0\)&lt;/span>是特殊的值0，所有让此方程组成立的&lt;span class="math">\(x\)&lt;/span>组成了&lt;span class="math">\(A\)&lt;/span>的零空间。在此方程中，零向量总是方程的解。当&lt;span class="math">\(Rank(A)=n\leq m\)&lt;/span>时，有且只有一个解：零向量。只有当&lt;span class="math">\(Rank(A)&amp;lt;n\)&lt;/span>时，才存在非零解，非零解一旦存在，就不是一个，而是一个解空间，即零空间，且零空间与列空间维度和为&lt;span class="math">\(n\)&lt;/span>。&lt;/p>
&lt;p>如果对于方程&lt;span class="math">\(Ax=b\)&lt;/span>有解，且&lt;span class="math">\(Ax=0\)&lt;/span>存在非零向量解&lt;span class="math">\(x_n\)&lt;/span>，那么&lt;span class="math">\(Ax=b\)&lt;/span>的解就是一个解系，其组成为任一个特解&lt;span class="math">\(x_p\)&lt;/span>与零空间中向量的任意线性组合，即&lt;span class="math">\(x=x_p+任意一组N(A)中的向量和\)&lt;/span>。因为&lt;span class="math">\(A(x_p+x_n)=Ax_p+Ax_n=b+0=b,\; x_n=k_1x_{n1}+k_2x_{n2}+\cdots,\;x_{ni}\in N(A)\)&lt;/span>。&lt;/p>
&lt;p>这里都只讨论&lt;span class="math">\(Ax=b\)&lt;/span>有解的情形，四个空间也有可解性密切相关。当&lt;span class="math">\(Ax=b\)&lt;/span>不可解，即&lt;span class="math">\(b\)&lt;/span>不在列空间中，我们是否可以求出&lt;span class="math">\(x\)&lt;/span>的最优或最近似解呢？这就会涉及到向量与矩阵的投影。&lt;/p></description></item><item><title>线性代数与矩阵之逆矩阵</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E9%80%86%E7%9F%A9%E9%98%B5/</link><pubDate>Sun, 08 May 2022 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E9%80%86%E7%9F%A9%E9%98%B5/</guid><description>
&lt;ul>
&lt;li>&lt;a href="#逆矩阵">逆矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#补充了解广义逆">补充了解：广义逆&lt;/a>&lt;/li>
&lt;li>&lt;a href="#逆矩阵存在条件">逆矩阵存在条件&lt;/a>&lt;/li>
&lt;li>&lt;a href="#逆矩阵的求法">逆矩阵的求法&lt;/a>&lt;/li>
&lt;li>&lt;a href="#初等变换法">初等变换法&lt;/a>&lt;/li>
&lt;li>&lt;a href="#伴随矩阵求逆矩阵">伴随矩阵求逆矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#矩阵分解法">矩阵分解法&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特殊矩阵的逆">特殊矩阵的逆&lt;/a>&lt;/li>
&lt;li>&lt;a href="#对角矩阵的逆">对角矩阵的逆&lt;/a>&lt;/li>
&lt;li>&lt;a href="#正交矩阵的逆">正交矩阵的逆&lt;/a>&lt;/li>
&lt;li>&lt;a href="#分块矩阵的逆">分块矩阵的逆&lt;/a>&lt;/li>
&lt;li>&lt;a href="#逆矩阵的性质">逆矩阵的性质&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="线性代数与矩阵之逆矩阵">线性代数与矩阵之逆矩阵&lt;!-- omit in toc -->&lt;/h2>
&lt;p>逆矩阵，是线性代数和矩阵分析中非常常见也是非常关键的一个问题。本笔记将根据自己常遇到的逆矩阵相关问题，整理有关逆矩阵定义、常用求法、存在条件以及常用性质等相关内容，并对广义逆做简单介绍。&lt;/p>
&lt;h2 id="逆矩阵">逆矩阵&lt;/h2>
&lt;blockquote>
&lt;p>逆矩阵（inverse matrix），又称乘法反方阵、反矩阵。在线性代数中，给定一个&lt;span class="math">\(n\)&lt;/span>阶方阵&lt;span class="math">\(\mathbf {A}\)&lt;/span>，若存在一&lt;span class="math">\(n\)&lt;/span>阶方阵&lt;span class="math">\(\mathbf{B}\)&lt;/span>，使得&lt;span class="math">\(\mathbf{AB}=\mathbf{BA}=\mathbf{I}_n\)&lt;/span>，其中&lt;span class="math">\(\mathbf{I}_n\)&lt;/span>为&lt;span class="math">\(n\)&lt;/span>阶单位矩阵，则称&lt;span class="math">\(\mathbf{A}\)&lt;/span>是可逆的，且&lt;span class="math">\(\mathbf{B}\)&lt;/span>是&lt;span class="math">\(\mathbf{A}\)&lt;/span>的&lt;strong>逆矩阵&lt;/strong>，记作&lt;span class="math">\(\mathbf {A} ^{-1}\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>注意：我们在谈论一般的逆矩阵时只针对&lt;strong>方阵&lt;/strong>，非方阵不存在逆矩阵，但是可以有广义逆矩阵。&lt;/p>
&lt;blockquote>
&lt;p>可逆矩阵：如果&lt;span class="math">\(A\)&lt;/span>有逆矩阵，我们称为可逆矩阵，或非奇异矩阵。不可逆的矩阵也叫做奇异矩阵。&lt;/p>
&lt;/blockquote>
&lt;h3 id="补充了解广义逆">补充了解：广义逆&lt;/h3>
&lt;blockquote>
&lt;p>广义逆（Generalized inverse），是线性代数中针对矩阵的一种运算。一个矩阵&lt;span class="math">\(A\)&lt;/span>的广义逆叫做&lt;span class="math">\(A\)&lt;/span>的广义逆阵，是指具有部分逆矩阵的特性，但是不一定具有逆矩阵的所有特性的另一矩阵。假设一矩阵&lt;span class="math">\(A\in \mathbb {R} ^{n\times m}\)&lt;/span>及另一矩阵&lt;span class="math">\(A^{\mathrm {g} }\in \mathbb {R} ^{m\times n}\)&lt;/span>，若&lt;span class="math">\(A^{\mathrm {g} }\)&lt;/span>满足&lt;span class="math">\(AA^{\mathrm {g} }A=A\)&lt;/span>，则&lt;span class="math">\(A^{\mathrm {g} }\)&lt;/span>即为&lt;span class="math">\(A\)&lt;/span>的广义逆阵。&lt;/p>
&lt;/blockquote>
&lt;p>广义逆也称为伪逆（pseudoinverse），有些时候，伪逆特指&lt;strong>摩尔－彭若斯广义逆&lt;/strong>。此外，还有针对非方阵的单边逆矩阵，如左逆矩阵、右逆矩阵等。&lt;/p>
&lt;h2 id="逆矩阵存在条件">逆矩阵存在条件&lt;/h2>
&lt;p>矩阵&lt;span class="math">\(A_{n\times n}\)&lt;/span>可逆的核心是&lt;strong>不能降维&lt;/strong>，即&lt;span class="math">\(A_{n\times n}\)&lt;/span>必须&lt;span class="math">\(n\)&lt;/span>维空间的一个表示。其等效表述有：&lt;/p>
&lt;ul>
&lt;li>&lt;span class="math">\(\det(A)\neq 0\)&lt;/span>。行列式不为0，表明&lt;span class="math">\(n\)&lt;/span>维体积不等于0，若有一个维度消失，那么其高维体积必是0。&lt;/li>
&lt;li>&lt;span class="math">\(\mathrm{Rank}(A)=n\)&lt;/span>。这个好理解，矩阵的秩就是可描述空间的维度。&lt;/li>
&lt;li>存在初等变换矩阵&lt;span class="math">\(P\)&lt;/span>，使得&lt;span class="math">\(PA=I\)&lt;/span>。我们知道初等变换不会增加维度，而单位矩阵&lt;span class="math">\(I\)&lt;/span>的维度是&lt;span class="math">\(n\)&lt;/span>，这也意味着矩阵&lt;span class="math">\(A，I\)&lt;/span>秩相等。&lt;/li>
&lt;li>&lt;span class="math">\(A\)&lt;/span>的所有特征值都不为0。特征值等效于该矩阵&lt;span class="math">\(n\)&lt;/span>维特征基的尺度变换，如果其中某个特征值为0，必然使得该特征向量所在维度坍缩，从而降维。&lt;/li>
&lt;li>齐次线性方程组&lt;span class="math">\(Ax=0\)&lt;/span>仅有零解或非齐次线性方程组&lt;span class="math">\(Ax=b\)&lt;/span>有唯一解。零空间维0维，等效于列空间为&lt;span class="math">\(n\)&lt;/span>维。&lt;/li>
&lt;li>&lt;span class="math">\(A\)&lt;/span>的行（列）向量组线性无关。最大线性无关组中的向量个数即为空间维数。&lt;/li>
&lt;li>任一&lt;span class="math">\(n\)&lt;/span>维向量可由&lt;span class="math">\(A\)&lt;/span>的行（列）向量组线性表示。这表明&lt;span class="math">\(A\)&lt;/span>的最大线性无关组至少为&lt;span class="math">\(n\)&lt;/span>。&lt;/li>
&lt;li>&lt;span class="math">\(A\)&lt;/span>可表示成有限个初等矩阵的乘积。&lt;/li>
&lt;/ul>
&lt;p>我们在这一小结，开头说了可逆的核心是&lt;strong>不能降维&lt;/strong>，这又是什么理由呢？从变换的角度可逆矩阵是将&lt;span class="math">\(n\)&lt;/span>维空间中点从一个位置，&lt;strong>一一对应的变换到另一个位置&lt;/strong>。其中不能有多个点变换到同一个点上（通常是降维），也不能有一个点变换到多个点情况（这个一般不会）。当多个点变换到同一个点上时，我们无法从变换后的点（像）精确、唯一的找到到底原来时哪一个点（原）变过来的，也就意味着无法找到一个变换方法把像点变回去，这就是不可逆的变换，即为不可逆矩阵。&lt;/p>
&lt;h2 id="逆矩阵的求法">逆矩阵的求法&lt;/h2>
&lt;p>除了使用定义求矩阵的逆外，常见的逆矩阵的直接求法包含&lt;strong>初等变换法&lt;/strong>和&lt;strong>伴随矩阵法&lt;/strong>。此外，&lt;strong>矩阵分解&lt;/strong>对矩阵求逆也有很大的帮助。&lt;/p>
&lt;p>求逆矩阵一直是矩阵研究中的一个重点问题，也是计算量非常大的一个问题。因此，也有很多逆矩阵的技巧，例如分块矩阵求逆，利用性质求逆等等，我们在本文中不再详述。&lt;/p>
&lt;h3 id="初等变换法">初等变换法&lt;/h3>
&lt;p>求逆矩阵最基本的方法是初等变换法。如果要求方阵&lt;span class="math">\(A\)&lt;/span>的逆矩阵，用初等变换法是：&lt;/p>
&lt;blockquote>
&lt;p>将矩阵&lt;span class="math">\(A\)&lt;/span>与单位矩阵&lt;span class="math">\(I\)&lt;/span>排成一个新的矩阵&lt;span class="math">\((A \quad I)\)&lt;/span>，称为增广矩阵，将此增广矩阵&lt;span class="math">\((A\quad I)\)&lt;/span>做初等行变换，将它化成&lt;span class="math">\((I\quad B)\)&lt;/span>的形式，则 &lt;span class="math">\[B=A^{-1}\]&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>举个例子。&lt;/p>
&lt;p>例1：求矩阵&lt;span class="math">\(A\)&lt;/span>的逆矩阵。 &lt;span class="math">\[A= \begin{bmatrix} 1&amp;amp;0&amp;amp;-2\\ -3&amp;amp;1&amp;amp;4\\ 2&amp;amp;-3&amp;amp;4\end{bmatrix} \]&lt;/span> 这是一个三阶的矩阵，最简便有效的方法是初等变换法。我们将矩阵与单位矩阵排在一起，然后做初等变换。 &lt;span class="math">\[\begin{aligned}(A\quad I)&amp;amp;=\begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;\vdots&amp;amp;1&amp;amp;0&amp;amp;0\\ -3&amp;amp;1&amp;amp;4 &amp;amp;\vdots&amp;amp; 0&amp;amp;1&amp;amp;0\\ 2&amp;amp;-3&amp;amp;4 &amp;amp;\vdots&amp;amp; 0&amp;amp;0&amp;amp;1\end{bmatrix}\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;\vdots&amp;amp;1&amp;amp;0&amp;amp;0\\ 0&amp;amp;1&amp;amp;-2 &amp;amp;\vdots&amp;amp; 3&amp;amp;1&amp;amp;0\\ 0&amp;amp;-3&amp;amp;8 &amp;amp;\vdots&amp;amp; -2&amp;amp;0&amp;amp;1\end{bmatrix}\\ &amp;amp;\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;\vdots&amp;amp;1&amp;amp;0&amp;amp;0\\ 0&amp;amp;1&amp;amp;-2 &amp;amp;\vdots&amp;amp; 3&amp;amp;1&amp;amp;0\\ 0&amp;amp;0&amp;amp;2 &amp;amp;\vdots&amp;amp; 7&amp;amp;3&amp;amp;1\end{bmatrix}\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;0&amp;amp;\vdots&amp;amp;8&amp;amp;3&amp;amp;1\\ 0&amp;amp;1&amp;amp;0 &amp;amp;\vdots&amp;amp; 10&amp;amp;4&amp;amp;1\\ 0&amp;amp;0&amp;amp;2 &amp;amp;\vdots&amp;amp; 7&amp;amp;3&amp;amp;1\end{bmatrix}\\&amp;amp;\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;0&amp;amp;\vdots&amp;amp;8&amp;amp;3&amp;amp;1\\ 0&amp;amp;1&amp;amp;0 &amp;amp;\vdots&amp;amp; 10&amp;amp;4&amp;amp;1\\ 0&amp;amp;0&amp;amp;1 &amp;amp;\vdots&amp;amp; \frac{7}{2}&amp;amp;\frac{3}{2}&amp;amp;\frac{1}{2}\end{bmatrix} \end{aligned}\]&lt;/span>&lt;/p>
&lt;p>所以我们得到&lt;/p>
&lt;p>&lt;span class="math">\[A^{-1}= \begin{bmatrix} 8&amp;amp;3&amp;amp;1\\ 10&amp;amp;4&amp;amp;1\\\frac{7}{2}&amp;amp;\frac{3}{2}&amp;amp;\frac{1}{2}\end{bmatrix} \]&lt;/span>&lt;/p>
&lt;p>我们再来看一个四阶矩阵的逆矩阵。&lt;/p>
&lt;p>例2：求矩阵&lt;span class="math">\(A\)&lt;/span>的逆矩阵。 &lt;span class="math">\[A=\begin{bmatrix}1&amp;amp;2&amp;amp;3&amp;amp;4\\ 2&amp;amp;3&amp;amp;1&amp;amp;2\\ 1&amp;amp;1&amp;amp;1&amp;amp;-1\\ 1&amp;amp;0&amp;amp;-2&amp;amp;-6\end{bmatrix}\]&lt;/span> 我们将下述矩阵做初等变换&lt;/p>
&lt;p>&lt;span class="math">\[ \begin{aligned} (A\quad I)&amp;amp;= \begin{bmatrix}1&amp;amp;2&amp;amp;3&amp;amp;4 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0\\ 2&amp;amp;3&amp;amp;1&amp;amp;2 &amp;amp;\vdots &amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\ 1&amp;amp;1&amp;amp;1&amp;amp;-1 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\ 1&amp;amp;0&amp;amp;-2&amp;amp;-6 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\end{bmatrix}\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;-6 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\ 2&amp;amp;3&amp;amp;1&amp;amp;2 &amp;amp;\vdots &amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;0\\ 1&amp;amp;1&amp;amp;1&amp;amp;-1 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;0\\ 1&amp;amp;2&amp;amp;3&amp;amp;4 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;0 \end{bmatrix} \\&amp;amp; \sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;-6 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\ 0&amp;amp;3&amp;amp;5&amp;amp;14 &amp;amp;\vdots &amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;-2\\ 0&amp;amp;1&amp;amp;3&amp;amp;5 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;-1\\ 0&amp;amp;2&amp;amp;5&amp;amp;10 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;-1 \end{bmatrix}\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;-6 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\ 0&amp;amp;1&amp;amp;3&amp;amp;5 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;-1 \\ 0&amp;amp;3&amp;amp;5&amp;amp;14 &amp;amp;\vdots &amp;amp;0&amp;amp;1&amp;amp;0&amp;amp;-2 \\ 0&amp;amp;2&amp;amp;5&amp;amp;10 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;0&amp;amp;-1 \end{bmatrix}\\&amp;amp;\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;-6 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\ 0&amp;amp;1&amp;amp;3&amp;amp;5 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;-1 \\ 0&amp;amp;0&amp;amp;-4&amp;amp;-1 &amp;amp;\vdots &amp;amp;0&amp;amp;1&amp;amp;-3&amp;amp;1 \\ 0&amp;amp;0&amp;amp;-1&amp;amp;0 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;-2&amp;amp;1 \end{bmatrix}\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;-6 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\ 0&amp;amp;1&amp;amp;3&amp;amp;5 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;-1 \\ 0&amp;amp;0&amp;amp;-1&amp;amp;0 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;-2&amp;amp;1 \\ 0&amp;amp;0&amp;amp;-4&amp;amp;-1 &amp;amp;\vdots &amp;amp;0&amp;amp;1&amp;amp;-3&amp;amp;1 \end{bmatrix}\\&amp;amp;\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;-6 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;0&amp;amp;1\\ 0&amp;amp;1&amp;amp;3&amp;amp;5 &amp;amp;\vdots &amp;amp;0&amp;amp;0&amp;amp;1&amp;amp;-1 \\ 0&amp;amp;0&amp;amp;-1&amp;amp;0 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;-2&amp;amp;1 \\ 0&amp;amp;0&amp;amp;0&amp;amp;-1 &amp;amp;\vdots &amp;amp;-4&amp;amp;1&amp;amp;5&amp;amp;-3 \end{bmatrix}\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;-2&amp;amp;0 &amp;amp;\vdots &amp;amp;24&amp;amp;-6&amp;amp;-30&amp;amp;19\\ 0&amp;amp;1&amp;amp;3&amp;amp;0 &amp;amp;\vdots &amp;amp;-20&amp;amp;5&amp;amp;26&amp;amp;-16 \\ 0&amp;amp;0&amp;amp;-1&amp;amp;0 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;-2&amp;amp;1 \\ 0&amp;amp;0&amp;amp;0&amp;amp;-1 &amp;amp;\vdots &amp;amp;-4&amp;amp;1&amp;amp;5&amp;amp;-3 \end{bmatrix} \\ &amp;amp;\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;0&amp;amp;0 &amp;amp;\vdots &amp;amp;22&amp;amp;-6&amp;amp;-26&amp;amp;17\\ 0&amp;amp;1&amp;amp;0&amp;amp;0 &amp;amp;\vdots &amp;amp;-17&amp;amp;5&amp;amp;20&amp;amp;-13 \\ 0&amp;amp;0&amp;amp;-1&amp;amp;0 &amp;amp;\vdots &amp;amp;1&amp;amp;0&amp;amp;-2&amp;amp;1 \\ 0&amp;amp;0&amp;amp;0&amp;amp;-1 &amp;amp;\vdots &amp;amp;-4&amp;amp;1&amp;amp;5&amp;amp;-3 \end{bmatrix}\sim \begin{bmatrix} 1&amp;amp;0&amp;amp;0&amp;amp;0 &amp;amp;\vdots &amp;amp;22&amp;amp;-6&amp;amp;-26&amp;amp;17\\ 0&amp;amp;1&amp;amp;0&amp;amp;0 &amp;amp;\vdots &amp;amp;-17&amp;amp;5&amp;amp;20&amp;amp;-13 \\ 0&amp;amp;0&amp;amp;1&amp;amp;0 &amp;amp;\vdots &amp;amp;-1&amp;amp;0&amp;amp;2&amp;amp;-1 \\ 0&amp;amp;0&amp;amp;0&amp;amp;1 &amp;amp;\vdots &amp;amp;4&amp;amp;-1&amp;amp;-5&amp;amp;3 \end{bmatrix} \end{aligned}\]&lt;/span>&lt;/p>
&lt;p>所以，我们得到 &lt;span class="math">\[A^{-1}= \begin{bmatrix} 22&amp;amp;-6&amp;amp;-26&amp;amp;17\\ -17&amp;amp;5&amp;amp;20&amp;amp;-13 \\ -1&amp;amp;0&amp;amp;2&amp;amp;-1 \\ 4&amp;amp;-1&amp;amp;-5&amp;amp;3 \end{bmatrix} \]&lt;/span>&lt;/p>
&lt;h3 id="伴随矩阵求逆矩阵">伴随矩阵求逆矩阵&lt;/h3>
&lt;p>用伴随矩阵求逆的公式很简单： &lt;span class="math">\[A^{-1}=\frac{1}{\det(A)}A^\ast=\frac{1}{\det(A)}C^T\]&lt;/span> 其中，&lt;span class="math">\(\det(A)\)&lt;/span>表示矩阵&lt;span class="math">\(A\)&lt;/span>的行列式，&lt;span class="math">\(A^\ast\)&lt;/span>表示伴随矩阵，&lt;span class="math">\(C\)&lt;/span>表示余子矩阵。显然&lt;span class="math">\(C^T=A^\ast\)&lt;/span>&lt;/p>
&lt;p>矩阵的行列式我们都知道，那么余子矩阵和伴随矩阵又是什么呢？我们接下来介绍相关内容。首先，从代数余子式开始。&lt;/p>
&lt;blockquote>
&lt;p>元素&lt;span class="math">\(a_{ij}\)&lt;/span>代数余子式：在矩阵&lt;span class="math">\(A_{n\times n}\)&lt;/span>所对应的&lt;span class="math">\(n\)&lt;/span>阶行列式中，划去元素&lt;span class="math">\(a_{ij}\)&lt;/span>所在的第&lt;span class="math">\(i\)&lt;/span>行与第&lt;span class="math">\(j\)&lt;/span>列的元素，剩下的元素不改变原来的顺序所构成的n-1阶&lt;strong>行列式&lt;/strong>称为&lt;strong>元素&lt;span class="math">\(a_{ij}\)&lt;/span>的余子式&lt;/strong>。数学表示上计作&lt;span class="math">\(M_{ij}\)&lt;/span>。&lt;span class="math">\(a_{ij}\)&lt;/span>的&lt;strong>代数余子式&lt;/strong>：&lt;span class="math">\(c_{ij}= (-1)^{i+j} M_{ij}\)&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>余子式和代数余子式都是&lt;span class="math">\(n-1\)&lt;/span>维行列式，也是一个简简单单的数字。区别就在于有没有乘以&lt;span class="math">\((-1)^{i+j}\)&lt;/span>。&lt;/p>
&lt;p>例如对矩阵 &lt;span class="math">\[\begin{bmatrix}\,\,\,1&amp;amp;4&amp;amp;7\\\,\,\,3&amp;amp;0&amp;amp;5\\-1&amp;amp;9&amp;amp;\!11\\\end{bmatrix}\]&lt;/span> 要计算代数余子式&lt;span class="math">\(c_{23}\)&lt;/span>。首先计算余子式&lt;span class="math">\(M_{23}\)&lt;/span>，也就是原矩阵去掉第2行和第3列后的子矩阵的行列式： &lt;span class="math">\[\begin{vmatrix}\,\,1&amp;amp;4&amp;amp;\Box \,\\\,\Box &amp;amp;\Box &amp;amp;\Box \,\\-1&amp;amp;9&amp;amp;\Box \,\\\end{vmatrix},即\begin{vmatrix}\,\,\,1&amp;amp;4\,\\-1&amp;amp;9\,\\\end{vmatrix}=9-(-4)=13\]&lt;/span> 因此，&lt;span class="math">\(c_{23}\)&lt;/span>等于&lt;span class="math">\((-1)^{2+3}M_{23}=-13\)&lt;/span>&lt;/p>
&lt;p>&lt;span class="math">\(A\)&lt;/span>的余子矩阵是指将&lt;span class="math">\(A\)&lt;/span>的&lt;span class="math">\((i, j)\)&lt;/span>项代数余子式&lt;span class="math">\(c_{ij}\)&lt;/span>摆在第i行第j列所得到的矩阵，记为&lt;span class="math">\(C\)&lt;/span>。 &lt;span class="math">\[C=\begin{bmatrix}\,\,c_{11}&amp;amp;\dotsb&amp;amp;c_{1n} \,\\\,\vdots &amp;amp;\vdots &amp;amp;\vdots \,\\c_{n1}&amp;amp;\dotsb&amp;amp;c_{nn} \,\\\end{bmatrix}\]&lt;/span> 其中，&lt;span class="math">\(c_{ij}\)&lt;/span>是元素&lt;span class="math">\(a_{ij}\)&lt;/span>的代数余子式&lt;/p>
&lt;p>余子矩阵&lt;span class="math">\(C\)&lt;/span>的&lt;strong>转置&lt;/strong>矩阵称为&lt;span class="math">\(A\)&lt;/span>的伴随矩阵&lt;span class="math">\(A^\ast\)&lt;/span>。 &lt;span class="math">\[
A^\ast=C^T
\]&lt;/span> 伴随矩阵与逆矩阵联系密切，并且当A可逆时可以用来计算它的逆矩阵。 &lt;span class="math">\[A^{-1}=\frac{1}{\det(A)}A^\ast=\frac{1}{\det(A)}C^T\]&lt;/span>&lt;/p>
&lt;p>例3：设&lt;span class="math">\(A=A=\begin{pmatrix}2&amp;amp;3&amp;amp;4\\ 2&amp;amp;1&amp;amp;1\\ -1&amp;amp;1&amp;amp;2\end{pmatrix}\)&lt;/span>，求&lt;span class="math">\(A^{-1}\)&lt;/span>。&lt;/p>
&lt;p>我们先求行列式： &lt;span class="math">\[
|A|=\begin{vmatrix}2&amp;amp;3&amp;amp;4\\ 2&amp;amp;1&amp;amp;1\\ -1&amp;amp;1&amp;amp;2\end{vmatrix}=\begin{vmatrix}0&amp;amp;5&amp;amp;8\\ 0&amp;amp;3&amp;amp;5\\ -1&amp;amp;1&amp;amp;2\end{vmatrix}=(-1)(-1)^{3+1}\begin{vmatrix}5&amp;amp;8\\ 3&amp;amp;5\end{vmatrix}=-1
\]&lt;/span> 所以矩阵可逆。现在我们来求伴随矩阵。 &lt;span class="math">\[
c_{11}=\begin{vmatrix}1&amp;amp;1\\1&amp;amp;2\end{vmatrix}=1,\quad c_{12}=(-1)^{1+2}\begin{vmatrix}2&amp;amp;1\\ -1&amp;amp;2\end{vmatrix}=-5,\quad c_{13}=\begin{vmatrix}2&amp;amp;1\\-1&amp;amp;1\end{vmatrix}=3\\
c_{21}=(-1)^{2+1}\begin{vmatrix}3&amp;amp;4\\1&amp;amp;2\end{vmatrix}=-2,\quad c_{22}=\begin{vmatrix}2&amp;amp;4\\ -1&amp;amp;2\end{vmatrix}=8,\quad c_{23}=(-1)^{2+3}=\begin{vmatrix}2&amp;amp;2\\-1&amp;amp;1\end{vmatrix}=-5\\
c_{31}=\begin{vmatrix}3&amp;amp;4\\1&amp;amp;1\end{vmatrix}=-1,\quad c_{32}=(-1)^{3+2}\begin{vmatrix}2&amp;amp;4\\ 2&amp;amp;1\end{vmatrix}=6,\quad c_{33}=\begin{vmatrix}2&amp;amp;3\\2&amp;amp;1\end{vmatrix}=-4\\
C=\begin{pmatrix}1&amp;amp;-5&amp;amp;3\\ -2&amp;amp;8&amp;amp;-5\\ -1&amp;amp;6&amp;amp;-4\end{pmatrix}
\]&lt;/span> 所以 &lt;span class="math">\[
A^\ast=C^T=\begin{pmatrix}1&amp;amp;-2&amp;amp;-1\\ -5&amp;amp;8&amp;amp;6\\ 3&amp;amp;-5&amp;amp;-4\end{pmatrix}\\
A^{-1}=\frac{1}{|A|}A^*=-1\begin{pmatrix}1&amp;amp;-2&amp;amp;-1\\ -5&amp;amp;8&amp;amp;6\\ 3&amp;amp;-5&amp;amp;-4\end{pmatrix}=\begin{pmatrix}-1&amp;amp;2&amp;amp;1\\ 5&amp;amp;-8&amp;amp;-6\\ -3&amp;amp;5&amp;amp;4\end{pmatrix}
\]&lt;/span>&lt;/p>
&lt;h3 id="矩阵分解法">矩阵分解法&lt;/h3>
&lt;p>矩阵分解是矩阵求逆非常有效的方式，可以根据不同的分解方式衍生出不同的求逆公式。我们下面列出几种矩阵分解的求逆公式。&lt;/p>
&lt;ul>
&lt;li>LU分解求逆：&lt;span class="math">\(A=LU, A^{-1}=U^{-1}L^{-1}\)&lt;/span>，由于三角矩阵逆容易求，由此简化了求逆计算。&lt;/li>
&lt;li>QR分解求逆：&lt;span class="math">\(A=QR, A^{-1}=R^{-1}Q^{T}\)&lt;/span>，其中两个矩阵分别为正交矩阵&lt;span class="math">\(Q\)&lt;/span>和上三角矩阵&lt;span class="math">\(R\)&lt;/span>。正交矩阵的逆等于转置。&lt;/li>
&lt;li>SVD分解求逆：&lt;span class="math">\(A=UDV^T, A^{-1}=VD^{-1}U^T\)&lt;/span>，其中&lt;span class="math">\(U,V\)&lt;/span>为正交矩阵、&lt;span class="math">\(D\)&lt;/span>为对角矩阵。正交矩阵的逆等于转置。对角矩阵逆为各个元素倒数。&lt;/li>
&lt;/ul>
&lt;p>当然，矩阵分解的具体步骤超出了本文的叙述范围，需要了解的读者可以自行查找矩阵分解的相关内容。&lt;/p>
&lt;h2 id="特殊矩阵的逆">特殊矩阵的逆&lt;/h2>
&lt;p>我们知道矩阵的初等变换有三种，&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>换行(列)变换：交换两行（列）。&lt;/li>
&lt;li>倍法变换：将行列式的某一行（列）的所有元素同乘以数k。&lt;/li>
&lt;li>消法变换：把行列式的某一行（列）的所有元素乘以一个数k并加到另一行（列）的对应元素上。&lt;/li>
&lt;/ol>
&lt;p>而这三种变换分别对应了三种矩阵，即对角矩阵、置换矩阵和消元矩阵。巧的是，这三种矩阵的逆矩阵都有十分简便的求法。以下分别说明。&lt;/p>
&lt;h3 id="对角矩阵的逆">对角矩阵的逆&lt;/h3>
&lt;p>对角矩阵的逆矩阵是最容易、直观的，即对角元素取倒数即可。 &lt;span class="math">\[
\Lambda=\begin{bmatrix}
a_{11}&amp;amp;0&amp;amp;\dotsb&amp;amp;0\\0&amp;amp;a_{22}&amp;amp;\dotsb&amp;amp;0\\\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\vdots\\0&amp;amp;0&amp;amp;\dotsb&amp;amp;a_{nn}
\end{bmatrix}\Rightarrow
\Lambda^{-1}=\begin{bmatrix}
\frac{1}{a_{11}}&amp;amp;0&amp;amp;\dotsb&amp;amp;0\\0&amp;amp;\frac{1}{a_{22}}&amp;amp;\dotsb&amp;amp;0\\\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\vdots\\0&amp;amp;0&amp;amp;\dotsb&amp;amp;\frac{1}{a_{nn}}
\end{bmatrix}
\]&lt;/span> 因为对角矩阵对应线性变换中的&lt;strong>缩放变换&lt;/strong>，右乘对应相应列的缩放，左乘对应相应行的缩放。其逆矩阵就相当于把缩放的倍数变回来，即缩放大小的倒数。&lt;/p>
&lt;h3 id="正交矩阵的逆">正交矩阵的逆&lt;/h3>
&lt;p>由于正交矩阵定义为&lt;span class="math">\(QQ^T=I\)&lt;/span>，所以显然有： &lt;span class="math">\[
Q^{-1}=Q^T
\]&lt;/span> 利用正交矩阵的逆可以快速计算置换矩阵（permutation matrix）的逆矩阵。&lt;/p>
&lt;blockquote>
&lt;p>置换矩阵：是一种系数只由0和1组成的方块矩阵。置换矩阵的每一行和每一列都恰好有一个1，其余元素都是0。&lt;/p>
&lt;/blockquote>
&lt;p>在线性代数中，每个n阶的置换矩阵都代表了一个对n个元素（n维空间的基）的置换。当一个矩阵乘上一个置换矩阵时，所得到的是原来矩阵的横行（置换矩阵在左）或纵列（置换矩阵在右）经过置换后得到的矩阵。一个置换矩阵&lt;span class="math">\(P_π\)&lt;/span>必然是&lt;strong>正交矩阵&lt;/strong>（即满足&lt;span class="math">\(P_{{\pi }}P_{{\pi }}^{{T}}=I\)&lt;/span>），并且它的逆也是置换矩阵： &lt;span class="math">\[P_{{\pi }}^{{-1}}=P_{{\pi ^{{-1}}}}=P_{{\pi }}^{{T}}\]&lt;/span>&lt;/p>
&lt;h3 id="分块矩阵的逆">分块矩阵的逆&lt;/h3>
&lt;p>分块矩阵逆的两种常用情形如下，分别是上三角分块矩阵和下三角分块矩阵。其他分块模式需要考虑各分块是否可逆，具体可参见维基百科：&lt;a href="https://en.wikipedia.org/wiki/Block_matrix#Block_matrix_inversion">分块矩阵求逆&lt;/a>。 &lt;span class="math">\[
U=\begin{bmatrix}A&amp;amp;C\\0&amp;amp;B\end{bmatrix}\Rightarrow U^{-1}=\begin{bmatrix}A^{-1}&amp;amp;-A^{-1}CB^{-1}\\0&amp;amp;B^{-1}\end{bmatrix}\\
L=\begin{bmatrix}A&amp;amp;0\\C&amp;amp;B\end{bmatrix}\Rightarrow L^{-1}=\begin{bmatrix}A^{-1}&amp;amp;0\\-B^{-1}CA^{-1}&amp;amp;B^{-1}\end{bmatrix}\\
\]&lt;/span> 在初等变换中的消法变换（只考虑一次消去一个行或列）在消去特定行（列）其他元素时，如果按照从上到下的顺序消元，那么每一个消元矩阵都是一个下三角矩阵。虽然消元矩阵不完全符合上面给出的两个分块矩阵求逆公式，但是可以根据维基百科中的其他公式求出：消元矩阵&lt;span class="math">\(C\)&lt;/span>的逆为&lt;strong>对角线元素不变，其他元素取反&lt;/strong>。&lt;/p>
&lt;p>从线性方程组消元的角度可以很快理解这个逆的，消去的元素需要取反再加回来，即能恢复原样。&lt;/p>
&lt;h2 id="逆矩阵的性质">逆矩阵的性质&lt;/h2>
&lt;ul>
&lt;li>若矩阵&lt;span class="math">\(A\)&lt;/span>存在逆矩阵&lt;span class="math">\(A^{-1}\)&lt;/span>，则&lt;span class="math">\(A^{-1}\)&lt;/span>唯一。反证法可得。&lt;/li>
&lt;li>&lt;span class="math">\((A^{-1})^{-1}=A\)&lt;/span>，显然。&lt;/li>
&lt;li>&lt;span class="math">\((kA)^{-1}=k^{-1}A^{-1}\)&lt;/span>，其中&lt;span class="math">\(k\)&lt;/span>是常数。显然。&lt;/li>
&lt;li>&lt;span class="math">\(\det(A^{-1})=(\det(A))^{-1}\)&lt;/span>。行列式可以看做是有向面积或体积的概念在一般的欧几里得空间中的推广。或者说，在欧几里得空间中，行列式描述的是一个线性变换对“体积”所造成的影响。因此，&lt;span class="math">\(A^{-1}\)&lt;/span>相当于是将体积变换回去，导致其行列式为原来的倒数。&lt;/li>
&lt;li>&lt;span class="math">\((A_1A_2\dotsb A_k)^{-1}=A_k^{-1}\dotsb A_2^{-1}A_1^{-1}\)&lt;/span>，矩阵乘法结合律+逆矩阵唯一性可证。特别地，若矩阵&lt;span class="math">\(A_1=A_2=\dotsb=A_n\)&lt;/span>，有&lt;span class="math">\((A^n)^{-1}=(A^{-1})^n\)&lt;/span>&lt;/li>
&lt;li>矩阵转置的逆矩阵。&lt;span class="math">\((A^T)^{-1}=(A^{-1})^T\)&lt;/span>。注意，转置和求逆可交换不像是指数的相互交换。其可交换性是一种美妙的巧合。&lt;/li>
&lt;/ul>
&lt;p>证明：矩阵求逆、转置的可交换性。 &lt;span class="math">\[
AA^{-1}=I\\
(AA^{-1})^T=I^T=I\\
\Rightarrow (A^{-1})^TA^T=I\\
\Rightarrow (A^T)^{-1}=(A^{-1})^T
\]&lt;/span>&lt;/p></description></item><item><title>线性代数与矩阵之正规矩阵</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E6%AD%A3%E8%A7%84%E7%9F%A9%E9%98%B5/</link><pubDate>Thu, 30 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E6%AD%A3%E8%A7%84%E7%9F%A9%E9%98%B5/</guid><description>
&lt;h2 id="正规矩阵">正规矩阵&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#例子">例子&lt;/a>&lt;/li>
&lt;li>&lt;a href="#性质">性质&lt;/a>&lt;/li>
&lt;li>&lt;a href="#相似对角化">相似对角化&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>在数学中，正规矩阵（英语：normal matrix）&lt;span class="math">\(\mathbf {A}\)&lt;/span>是与自己的共轭转置满足交换律的复系数方块矩阵，也就是说，&lt;span class="math">\(\mathbf {A}\)&lt;/span>满足 &lt;span class="math">\[\mathbf{A}^\ast\mathbf{A} = \mathbf{A} \mathbf{A}^\ast\]&lt;/span> 其中&lt;span class="math">\(\mathbf{A}^\ast\)&lt;/span>是&lt;span class="math">\(\mathbf{A}\)&lt;/span>的共轭转置。&lt;/p>
&lt;p>如果&lt;span class="math">\(\mathbf{A}\)&lt;/span>是实系数矩阵，则&lt;span class="math">\(\mathbf{A}^\ast = \mathbf{A}^T\)&lt;/span>，从而条件简化为&lt;span class="math">\(\mathbf {A} ^{T}\mathbf {A} =\mathbf {A} \mathbf {A} ^{T}\)&lt;/span>其中&lt;span class="math">\(\mathbf{A}^T\)&lt;/span>是&lt;span class="math">\(\mathbf{A}\)&lt;/span>的转置矩阵。&lt;/p>
&lt;p>任何一个正规矩阵，都是某个正规算子在一组标准正交基下的矩阵；反之，任一正规算子在一组标准正交基下的矩阵都为正规矩阵。&lt;/p>
&lt;p>矩阵的正规性充要条件：&lt;/p>
&lt;blockquote>
&lt;p>任意正规矩阵都可在经过一个酉变换后变为对角矩阵，反过来所有可在经过一个酉变换后变为对角矩阵的矩阵都是正规矩阵。&lt;/p>
&lt;/blockquote>
&lt;h2 id="例子">例子&lt;/h2>
&lt;p>在复系数矩阵中，所有的酉矩阵、埃尔米特矩阵和斜埃尔米特矩阵都是正规的。同理，在实系数矩阵中，所有的正交矩阵、对称矩阵和斜对称矩阵都是正规的。&lt;/p>
&lt;h2 id="性质">性质&lt;/h2>
&lt;h3 id="相似对角化">相似对角化&lt;/h3>
&lt;p>正规矩阵的概念十分重要，因为它们正是能使谱定理成立的对象。&lt;strong>矩阵&lt;span class="math">\(\mathbf{A}\)&lt;/span>正规当且仅当它可以被写成&lt;span class="math">\(\mathbf{A} = \mathbf{U} \mathbf{\Lambda} \mathbf{U}^\ast\)&lt;/span>的形式&lt;/strong>。其中的&lt;span class="math">\(\mathbf{\Lambda} = \operatorname{diag}(\lambda_1, \lambda_2, \dots)\)&lt;/span>为对角矩阵，&lt;span class="math">\(\mathbf{U}\)&lt;/span>为酉矩阵： &lt;span class="math">\[\mathbf{U}^\ast\mathbf{U} = \mathbf{U} \mathbf{U}^\ast = \mathbf{I}\]&lt;/span> 矩阵&lt;span class="math">\(Λ\)&lt;/span>对角线上的元素是&lt;span class="math">\(A\)&lt;/span>的特征值，而组成&lt;span class="math">\(U\)&lt;/span>的列向量则是&lt;span class="math">\(A\)&lt;/span>相应的特征向量。&lt;/p></description></item><item><title>线性代数与矩阵之雅可比矩阵与海森矩阵</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%B5%B7%E6%A3%AE%E7%9F%A9%E9%98%B5/</link><pubDate>Wed, 29 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E9%9B%85%E5%8F%AF%E6%AF%94%E7%9F%A9%E9%98%B5%E4%B8%8E%E6%B5%B7%E6%A3%AE%E7%9F%A9%E9%98%B5/</guid><description>
&lt;h2 id="jacobian矩阵和hessian矩阵">Jacobian矩阵和Hessian矩阵&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#jacobian">Jacobian&lt;/a>&lt;/li>
&lt;li>&lt;a href="#jacobian矩阵">Jacobian矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#jacobian行列式">Jacobian行列式&lt;/a>&lt;/li>
&lt;li>&lt;a href="#hessian矩阵">Hessian矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#hessian矩阵对驻点影响">Hessian矩阵对驻点影响&lt;/a>&lt;/li>
&lt;li>&lt;a href="#海森矩阵在牛顿法中的应用">海森矩阵在牛顿法中的应用&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="jacobian">Jacobian&lt;/h2>
&lt;p>在向量分析中, 雅可比矩阵是一阶偏导数以一定方式排列成的矩阵, 其行列式称为雅可比行列式. 还有, 在代数几何中, 代数曲线的雅可比量表示雅可比簇：伴随该曲线的一个代数群, 曲线可以嵌入其中。&lt;strong>Jacobian矩阵（行列式）和一阶导数（梯度、偏导数）相关&lt;/strong>。&lt;/p>
&lt;h3 id="jacobian矩阵">Jacobian矩阵&lt;/h3>
&lt;p>雅可比矩阵的重要性在于它体现了一个可微方程与给出点的最优线性逼近. 因此, 雅可比矩阵类似于多元函数的导数.&lt;/p>
&lt;p>假设&lt;span class="math">\(F: R_n→R_m\)&lt;/span>是一个从欧式n维空间转换到欧式m维空间的函数. 这个函数由m个实函数组成: y1(x1,…,xn), …, ym(x1,…,xn). 这些函数的偏导数(如果存在)可以组成一个m行n列的矩阵(因变量为行，自变量为列), 这就是所谓的雅可比矩阵： &lt;span class="math">\[\begin{bmatrix} \frac{\partial y_1}{\partial x_1} &amp;amp; \cdots &amp;amp; \frac{\partial y_1}{\partial x_n} \\ \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \frac{\partial y_m}{\partial x_1} &amp;amp; \cdots &amp;amp; \frac{\partial y_m}{\partial x_n} \end{bmatrix}\]&lt;/span>&lt;/p>
&lt;p>此矩阵表示为:&lt;span class="math">\({J_F}({x_1}, \ldots ,{x_n})\)&lt;/span>,或者&lt;span class="math">\(\frac{{\partial ({y_1}, \ldots ,{y_m})}}{{\partial ({x_1}, \ldots ,{x_n})}}\)&lt;/span>&lt;/p>
&lt;p>这个矩阵的第i行是由&lt;strong>梯度函数&lt;/strong>的转置yi(i=1,…,m)表示的.&lt;/p>
&lt;p>如果&lt;span class="math">\(P\)&lt;/span>是&lt;span class="math">\(R_n\)&lt;/span>中的一点, &lt;span class="math">\(F\)&lt;/span>在&lt;span class="math">\(P\)&lt;/span>点可微分, 那么在这一点的导数由&lt;span class="math">\(J_F(p)\)&lt;/span>给出(这是求该点导数最简便的方法). 在此情况下, 由&lt;span class="math">\(F(p)\)&lt;/span>描述的线性算子即接近点&lt;span class="math">\(P\)&lt;/span>的&lt;span class="math">\(F\)&lt;/span>的最优线性逼近, &lt;span class="math">\(\mathbf{x}\)&lt;/span>逼近于&lt;span class="math">\(P\)&lt;/span>,则有: &lt;span class="math">\[F({\bf{x}}) \approx F({\bf{p}}) + {J_F}({\bf{p}}) \cdot ({\bf{x}} – {\bf{p}})\]&lt;/span>&lt;/p>
&lt;h3 id="jacobian行列式">Jacobian行列式&lt;/h3>
&lt;p>如果m = n, 那么&lt;span class="math">\(F\)&lt;/span>是从n维空间到n维空间的函数, 且它的雅可比矩阵是一个方块矩阵. 于是我们可以&lt;strong>取它的行列式&lt;/strong>, 称为Jacobian行列式.&lt;/p>
&lt;p>在某个给定点的雅可比行列式提供了 在接近该点时的表现的重要信息. 例如, 如果连续可微函数&lt;span class="math">\(F\)&lt;/span>在&lt;span class="math">\(P\)&lt;/span>点的雅可比行列式不是零, 那么它在该点附近具有反函数. 这称为反函数定理. 更进一步, 如果&lt;span class="math">\(P\)&lt;/span>点的雅可比行列式是正数, 则&lt;span class="math">\(F\)&lt;/span>在&lt;span class="math">\(P\)&lt;/span>点的取向不变；如果是负数, 则&lt;span class="math">\(F\)&lt;/span>的取向相反. 而从雅可比行列式的绝对值, 就可以知道函数&lt;span class="math">\(F\)&lt;/span>在&lt;span class="math">\(P\)&lt;/span>点的缩放因子；这就是为什么它出现在换元积分法中.&lt;/p>
&lt;p>对于取向问题可以这么理解, 例如一个物体在平面上匀速运动, 如果施加一个正方向的力F, 即取向相同, 则加速运动, 类比于速度的导数加速度为正；如果施加一个反方向的力F, 即取向相反, 则减速运动, 类比于速度的导数加速度为负.&lt;/p>
&lt;h2 id="hessian矩阵">Hessian矩阵&lt;/h2>
&lt;p>在数学中, 海森矩阵(Hessian matrix或Hessian)是一个自变量为向量的&lt;strong>实值&lt;/strong>函数（区别Jacobian矩阵）的二阶偏导数组成的方块矩阵, 此函数如下： &lt;span class="math">\[f(x_1,x_2,\ldots,x_n)\]&lt;/span> 如果&lt;span class="math">\(f\)&lt;/span>的所有二阶导数都存在, 那么&lt;span class="math">\(f\)&lt;/span>的海森矩阵即： &lt;span class="math">\[H{(f)_{ij}}(x) = {D_i}{D_j}f(x)\]&lt;/span> 其中&lt;span class="math">\(x=(x_1,x_2,\ldots,x_n)\)&lt;/span>，即&lt;span class="math">\(H(f)\)&lt;/span>为： &lt;span class="math">\[\begin{bmatrix}\frac{\partial^2 f}{\partial x_1^2} &amp;amp; \frac{\partial^2 f}{\partial x_1\,\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_1\,\partial x_n} \\ \\
\frac{\partial^2 f}{\partial x_2\,\partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_2\,\partial x_n} \\ \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ \\
\frac{\partial^2 f}{\partial x_n\,\partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_n\,\partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_n^2}\end{bmatrix}\]&lt;/span> (也有人把海森定义为以上矩阵的行列式)海森矩阵被应用于牛顿法解决的大规模优化问题.&lt;/p>
&lt;h3 id="hessian矩阵对驻点影响">Hessian矩阵对驻点影响&lt;/h3>
&lt;p>Hessian矩阵我们已经知道是二阶导数矩阵，有时候二阶导数仍然带有未知数，所以求给定点的Hessian矩阵才有意义，给定坐标后，Hessain矩阵变成常数矩阵，然后就可以求其特征值&lt;/p>
&lt;p>1.如果Hessian矩阵所有特征值均为正：开口向上凹的点&lt;br />&lt;img src="../../images/hessian_matrix_1.png" alt="hessian_matrix_1" />&lt;/p>
&lt;p>2.如果均为负：开口向下凹的点&lt;br />&lt;img src="../../images/hessian_matrix_2.png" alt="hessian_matrix_2" />&lt;/p>
&lt;p>3.如果有正有负：存在鞍点&lt;br />&lt;img src="../../images/hessian_matrix_3.png" alt="hessian_matrix_3" />&lt;/p>
&lt;p>4.如果有一项为0：不确定情况。&lt;/p>
&lt;h3 id="海森矩阵在牛顿法中的应用">海森矩阵在牛顿法中的应用&lt;/h3>
&lt;p>一般来说, &lt;strong>牛顿法&lt;/strong>主要应用在两个方面, 1, 求方程的根; 2, 最优化.&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;p>求方程的根&lt;/p>
&lt;p>牛顿法的最初提出是用来求解方程的根问题。并不是所有的方程都有求根公式, 或者求根公式很复杂, 导致求解困难. 利用牛顿法, 可以迭代求解. 原理是利用泰勒公式, 在&lt;span class="math">\(x_0\)&lt;/span>处展开, 且展开到一阶, 即&lt;span class="math">\(f(x)=f(x_0)+(x–x_0)f&amp;#39;(x_0)\)&lt;/span> 求解方程&lt;span class="math">\(f(x)=0\)&lt;/span>, 即&lt;span class="math">\(f(x_0)+(x–x_0)f&amp;#39;(x_0)=0\)&lt;/span>, 解&lt;span class="math">\(x=x_1=x_0–f(x_0)/f&amp;#39;(x_0)\)&lt;/span>, 因为这是利用泰勒公式的一阶展开.但是&lt;span class="math">\(f(x)与f(x_0)+(x–x_0)f&amp;#39;(x_0)\)&lt;/span>处并不是完全相等, 而是近似相等, 这里求得的&lt;span class="math">\(x_1\)&lt;/span>并不能让&lt;span class="math">\(f(x)=0\)&lt;/span>, 只能说&lt;span class="math">\(f(x_1)\)&lt;/span>的值比&lt;span class="math">\(f(x_0)\)&lt;/span>更接近&lt;span class="math">\(f(x)=0\)&lt;/span>, 于是乎, 迭代求解的想法就很自然了, 可以进而推出&lt;span class="math">\(x_{n+1}=x_n–f(x_n)/f&amp;#39;(x_n)\)&lt;/span>, 通过迭代, 这个式子必然在&lt;span class="math">\(f(x∗)=0\)&lt;/span>的时候收敛. 整个过程如下图：&lt;/p>
&lt;img src="../../images/newton_root.gif" alt="newton_root.gif" />
&lt;center>
图1牛顿法求根
&lt;/center>&lt;/li>
&lt;li>&lt;p>最优化&lt;/p>
&lt;p>在最优化的问题中, 线性最优化至少可以使用单纯形法(或称不动点算法)求解, 但对于非线性优化问题, 牛顿法提供了一种求解的办法. 假设任务是优化一个目标函数&lt;span class="math">\(f\)&lt;/span>, 求函数&lt;span class="math">\(f\)&lt;/span>的极大极小问题, 可以转化为求解函数&lt;span class="math">\(f\)&lt;/span>的导数&lt;span class="math">\(f&amp;#39;=0\)&lt;/span>的问题, 这样求可以把优化问题看成方程求解问题(&lt;span class="math">\(f&amp;#39;=0\)&lt;/span>). 剩下的问题就和第一部分提到的牛顿法函数的根很相似了.&lt;/p>
&lt;p>这次为了求解&lt;span class="math">\(f&amp;#39;=0\)&lt;/span>的根, 首先把&lt;span class="math">\(f(x)\)&lt;/span>在探索点&lt;span class="math">\(x_n\)&lt;/span>处泰勒展开, 展开到2阶形式进行近似： &lt;span class="math">\[f(x) = f({x_n}) + f&amp;#39;({x_n})(x – {x_n}) + \frac{{f&amp;#39;&amp;#39;({x_n})}}{2}{(x – {x_n})^2}\]&lt;/span> 相对于&lt;span class="math">\(f(x)\)&lt;/span>的二阶展开，我们现在求的是&lt;span class="math">\(f&amp;#39;=0\)&lt;/span>的根，是&lt;span class="math">\(f&amp;#39;(x)\)&lt;/span>的一阶展开，所以用以下展开式： &lt;span class="math">\[f&amp;#39;(x)=f&amp;#39;(x_0)+f&amp;#39;&amp;#39;(x_0)(x-x_0)\]&lt;/span> 根据牛顿法求解函数的根，我们同理可得到： &lt;span class="math">\[{x_{n + 1}} = {x_n}{\rm{ – }}\frac{{f&amp;#39;({x_n})}}{{f”({x_n})}},n = 0,1,…\]&lt;/span> 一般认为牛顿法可以利用到曲线本身的信息, 比梯度下降法更容易收敛（迭代更少次数）, 如下图是一个最小化一个目标方程的例子, 红色曲线是利用牛顿法迭代求解, 绿色曲线是利用梯度下降法求解。&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/newtonvsgradient.jpg" alt="牛顿法vs梯度法" />&lt;p class="caption">牛顿法vs梯度法&lt;/p>
&lt;/div>
&lt;p>图2牛顿法vs梯度法&lt;/p>
&lt;p>在上面讨论的是2维情况, 高维情况的牛顿迭代公式是： &lt;span class="math">\[x_{n+1}=x_n-[Hf(x_n)]^(-1)\nabla f(x_n),n\geqslant 0\]&lt;/span> 其中&lt;span class="math">\(H\)&lt;/span>是hessian矩阵, 定义见上.&lt;/p>
&lt;p>高维情况依然可以用牛顿迭代求解, 但是问题是Hessian矩阵引入的复杂性, 使得牛顿迭代求解的难度大大增加, 但是已经有了解决这个问题的办法就是Quasi-Newton method, 不再直接计算hessian矩阵, 而是每一步的时候使用梯度向量更新hessian矩阵的近似.&lt;/p>&lt;/li>
&lt;/ol></description></item><item><title>线性代数与矩阵之特征值估计</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%89%B9%E5%BE%81%E5%80%BC%E4%BC%B0%E8%AE%A1/</link><pubDate>Tue, 28 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%89%B9%E5%BE%81%E5%80%BC%E4%BC%B0%E8%AE%A1/</guid><description>
&lt;h2 id="特征值估计">特征值估计&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#盖尔圆方法">盖尔圆方法&lt;/a>&lt;/li>
&lt;li>&lt;a href="#谱半径估计">谱半径估计&lt;/a>&lt;/li>
&lt;li>&lt;a href="#hermite矩阵的rayleigh商方法">Hermite矩阵的Rayleigh商方法&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="盖尔圆方法">盖尔圆方法&lt;/h2>
&lt;p>设&lt;span class="math">\(A=(a_{ij})_{n*n}\)&lt;/span>，称&lt;span class="math">\(A\)&lt;/span>的特征值集合为&lt;span class="math">\(A\)&lt;/span>的谱，特征值中模最大的为&lt;span class="math">\(A\)&lt;/span>的谱半径，记为&lt;span class="math">\(\rho(A)\)&lt;/span> &lt;span class="math">\[\rho(A)=\max_i(\lambda_i)\]&lt;/span> 记 &lt;span class="math">\[R_i=|a_{i1}|+\dotsb+|a_{ii-1}|+|a_{ii+1}|+\dotsb+|a_{in}|（行和）\\
C_i=\{z||z-a_{ii}|≤R_i\}\]&lt;/span> 称为&lt;span class="math">\(A\)&lt;/span>的第&lt;span class="math">\(i\)&lt;/span>个盖尔圆。可以看出，第&lt;span class="math">\(i\)&lt;/span>个盖尔圆以&lt;span class="math">\(a_{ii}\)&lt;/span>为圆心，&lt;span class="math">\(R_i\)&lt;/span>为半径。所有盖尔圆组成&lt;span class="math">\(A\)&lt;/span>的盖尔圆系 &lt;span class="math">\[G=\bigcup_{i=1}^n C_i\]&lt;/span>&lt;/p>
&lt;blockquote>
&lt;p>定理：矩阵&lt;span class="math">\(A\)&lt;/span>的特征值必定在&lt;span class="math">\(A\)&lt;/span>的盖尔圆系中。&lt;/p>
&lt;/blockquote>
&lt;p>需要注意的是并不是每一个盖尔圆中都有特征值，但是在盖尔圆外必无特征值，例如 &lt;span class="math">\[A=\begin{bmatrix}
-4&amp;amp;-10\\1&amp;amp;6
\end{bmatrix}\]&lt;/span> 第一个盖尔圆&lt;span class="math">\(C_1\)&lt;/span>为-4为圆心，10为半径的盖尔圆，第二个盖尔圆&lt;span class="math">\(C_2\)&lt;/span>为6为圆心，1为半径的盖尔圆。特征值为&lt;span class="math">\(\lambda=-1\plusmn\sqrt{15}\)&lt;/span>。&lt;span class="math">\(C_1\)&lt;/span>中有两个特征值，而&lt;span class="math">\(C_2\)&lt;/span>中没有特征值。&lt;/p>
&lt;p>这样来看，盖尔圆和特征值之间的关系很弱，还是没法估计特征值，因此我们需要进一步探讨盖尔圆和特征值的关系。&lt;/p>
&lt;blockquote>
&lt;p>定义：设&lt;span class="math">\(A\in C^{n*n}\)&lt;/span>，在&lt;span class="math">\(A\)&lt;/span>的&lt;span class="math">\(n\)&lt;/span>个盖尔圆中，有&lt;span class="math">\(k\)&lt;/span>个圆构成一个连通区（相切也算连通）但与其余&lt;span class="math">\(n-k\)&lt;/span>个盖尔圆都不相交，则称这个连通区域为&lt;span class="math">\(k-区\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>我们为什么要考虑连通区域呢？这是因为特征值个数和连通区包含的盖尔圆个数是对应的：&lt;/p>
&lt;blockquote>
&lt;p>定理：&lt;span class="math">\(A\)&lt;/span>的盖尔圆的k-区中&lt;strong>有且仅有&lt;/strong>&lt;span class="math">\(A\)&lt;/span>的k个特征值。&lt;/p>
&lt;/blockquote>
&lt;p>例如： &lt;span class="math">\[A=\begin{bmatrix}
2&amp;amp;1&amp;amp;0\\1&amp;amp;4&amp;amp;0\\0&amp;amp;1&amp;amp;2
\end{bmatrix}，
B=\begin{bmatrix}
0&amp;amp;1.2&amp;amp;0\\0&amp;amp;4&amp;amp;0.5\\0&amp;amp;0.5&amp;amp;1\end{bmatrix}\]&lt;/span>&lt;/p>
&lt;img src="../../images/盖尔圆1.png" alt="盖尔圆1" />
&lt;center>
3-区：特征值：2.0000，4.4142，1.5858
&lt;/center>
&lt;img src="../../images/盖尔圆2.png" alt="盖尔圆2" />
&lt;center>
2区：特征值0.00000，0.91886；1区：特征值4.08114
&lt;/center>
&lt;blockquote>
&lt;p>推论：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>如果&lt;span class="math">\(A\)&lt;/span>的n个盖尔圆互不相交，则&lt;span class="math">\(A\)&lt;/span>有n个互不相等的特征值。&lt;/li>
&lt;li>如果&lt;span class="math">\(A\)&lt;/span>的n个盖尔圆互不相交，则&lt;span class="math">\(A\)&lt;/span>一定对角相似。&lt;/li>
&lt;li>如果&lt;span class="math">\(A\)&lt;/span>的n个盖尔圆互不相交，则&lt;span class="math">\(A\)&lt;/span>的特征值都是实数。&lt;/li>
&lt;li>由于转置不改变特征值，又综合&lt;span class="math">\(A^T\)&lt;/span>的盖尔圆综合判断。&lt;/li>
&lt;/ol>
&lt;/blockquote>
&lt;h3 id="谱半径估计">谱半径估计&lt;/h3>
&lt;blockquote>
&lt;p>定理：谱半径（谱范数）小于等于任一范数。简单的可以用行和范数和列和范数估计其上界。 设&lt;span class="math">\(A=(a_{ij})_{n*n}\)&lt;/span>， &lt;span class="math">\[\rho_1=\max_{1≤i≤n}\{\sum_{j=1}^n|a_{ij}|\}，\rho_2=\max_{1≤j≤n}\{\sum_{i=1}^n|a_{ij}|\}\]&lt;/span> 则&lt;span class="math">\(\rho(A)≤\min(\rho_1,\rho_2)\)&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;h2 id="hermite矩阵的rayleigh商方法">Hermite矩阵的Rayleigh商方法&lt;/h2>
&lt;blockquote>
&lt;p>定义：设&lt;span class="math">\(A\)&lt;/span>是n阶Hermite矩阵，则&lt;span class="math">\(\forall x ∈C^n，x^HAx ∈ R\)&lt;/span>，可以定义一复变量的实值函数： &lt;span class="math">\[R(x)=\frac{x^HAx}{x^Hx},\forall x \neq 0,x ∈ c^n\]&lt;/span> 称此函数为&lt;span class="math">\(A\)&lt;/span>的Rayleigh商。&lt;/p>
&lt;/blockquote>
&lt;p>需要指出的是Rayleigh商的定义、定理只适用于Hermite矩阵。因为Hermite矩阵&lt;span class="math">\(A\in C^{n*n}\)&lt;/span>的特征值均为实数，所以可以把他们记作（按照大小进行排序）：&lt;span class="math">\(\lambda_{min}=\lambda_n≤\lambda_{n-1}\dotsb≤\lambda_2≤\lambda_1=\lambda_{max}\)&lt;/span>。&lt;/p>
&lt;blockquote>
&lt;p>定理：&lt;span class="math">\(\lambda_{min}\)&lt;/span>是Rayleigh商的最小值，&lt;span class="math">\(\lambda_{max}\)&lt;/span>是Rayleigh商的最大值。 &lt;span class="math">\[\lambda_{min}=\min_{x\in C^n,x\neq 0}R(x),\lambda_{max}=\max_{x\in C^n,x\neq 0}R(x)\]&lt;/span>&lt;/p>
&lt;/blockquote></description></item><item><title>线性代数与矩阵之Jordan标准型与相似性</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%9B%B8%E4%BC%BC%E6%80%A7%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/</link><pubDate>Mon, 27 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%9B%B8%E4%BC%BC%E6%80%A7%E4%B8%8Ejordan%E6%A0%87%E5%87%86%E5%9E%8B/</guid><description>
&lt;h2 id="线性代数与矩阵之jordan标准型与相似性">线性代数与矩阵之Jordan标准型与相似性&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#相似矩阵">相似矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#相似矩阵的性质">相似矩阵的性质&lt;/a>&lt;/li>
&lt;li>&lt;a href="#相似矩阵的特征值与特征向量">相似矩阵的特征值与特征向量&lt;/a>&lt;/li>
&lt;li>&lt;a href="#相似矩阵与可对角化条件">相似矩阵与可对角化条件&lt;/a>&lt;/li>
&lt;li>&lt;a href="#jordan标准型">Jordan标准型&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>矩阵之间可以通过相似变换进行转换，这种转换保留了很多不变的性质。如果一个矩阵能够和一个对角矩阵相似，那么研究该矩阵就会简单许多，然而并不是所有的矩阵都可以相似对角化。但是，所有矩阵都可以与Jordan标准型相似。&lt;/p>
&lt;h2 id="相似矩阵">相似矩阵&lt;/h2>
&lt;blockquote>
&lt;p>相似矩阵（英语：similar matrix）是指存在相似关系的矩阵。相似关系是两个矩阵之间的一种等价关系。两个&lt;span class="math">\(n × n\)&lt;/span>矩阵&lt;span class="math">\(A\)&lt;/span>与&lt;span class="math">\[为相似矩阵当且仅当存在一个$n × n$的可逆矩阵$P$，使得：
\]&lt;/span>P^{{-1}}AP=B&lt;span class="math">\($ \)&lt;/span>P&lt;span class="math">\(被称为矩阵\)&lt;/span>A&lt;span class="math">\(与\)&lt;/span>B$之间的相似变换矩阵。&lt;/p>
&lt;/blockquote>
&lt;p>相似变换是矩阵之间的一种等价关系，也就是说满足：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>反身性：任意矩阵都与其自身相似。&lt;/li>
&lt;li>对称性：如果&lt;span class="math">\(A\)&lt;/span>和&lt;span class="math">\(B\)&lt;/span>相似，那么&lt;span class="math">\(B\)&lt;/span>也和&lt;span class="math">\(A\)&lt;/span>相似。&lt;/li>
&lt;li>传递性：如果&lt;span class="math">\(A\)&lt;/span>和&lt;span class="math">\(B\)&lt;/span>相似，&lt;span class="math">\(B\)&lt;/span>和&lt;span class="math">\(C\)&lt;/span>相似，那么&lt;span class="math">\(A\)&lt;/span>也和&lt;span class="math">\(C\)&lt;/span>相似。&lt;/li>
&lt;/ol>
&lt;h3 id="相似矩阵的性质">相似矩阵的性质&lt;/h3>
&lt;p>相似矩阵保留了矩阵的许多性质，因此许多对矩阵性质的研究可以通过研究更简单的相似矩阵而得到解决。&lt;/p>
&lt;p>两个相似的矩阵相同的性质主要有：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>两者拥有同样的特征多项式。&lt;/li>
&lt;li>两者的秩相等。&lt;/li>
&lt;li>两者的行列式值相等。&lt;/li>
&lt;li>两者的迹数相等。&lt;/li>
&lt;li>两者拥有同样的特征值，尽管相应的特征向量一般不同。&lt;/li>
&lt;/ol>
&lt;p>其实，后面四个性质都可以算是第一个性质的推论，我们在下一小节证明。&lt;/p>
&lt;p>两个相似的矩阵可以看做是同一个线性变换的「两面」，即在两个不同的基下的表现。因此，在给定了矩阵&lt;span class="math">\(A\)&lt;/span>后，只要能找到一个与之相似而又足够「简单」的「规范形式」&lt;span class="math">\(B\)&lt;/span>，那么对A的研究就可以转化为对更简单的矩阵&lt;span class="math">\(B\)&lt;/span>的研究。&lt;/p>
&lt;h3 id="相似矩阵的特征值与特征向量">相似矩阵的特征值与特征向量&lt;/h3>
&lt;p>我们在相似矩阵性质中最常提到相似矩阵拥有同样的特征值，这其实是第1个性质：两者拥有同样的特征多项式的必然结果。我们从矩阵行列式的角度来证明。&lt;/p>
&lt;p>证明：&lt;/p>
&lt;blockquote>
&lt;p>假设&lt;span class="math">\(n\)&lt;/span>阶矩阵&lt;span class="math">\(A,B\)&lt;/span>相似，&lt;span class="math">\(A\sim B\)&lt;/span>，其特征多项式分别为： &lt;span class="math">\[f(\lambda)=|A-\lambda I|\\g(\lambda)=|B-\lambda I|\]&lt;/span> 由二者相似可知，存在可逆矩阵&lt;span class="math">\(P\)&lt;/span>，使得&lt;span class="math">\(B=P^{-1}AP\)&lt;/span>，即 &lt;span class="math">\[|B-\lambda I|=|(P^{-1}AP)-\lambda I|=|(P^{-1}AP)-\lambda P^{-1}IP|\\
=|P^{-1}(A-\lambda I)P|\]&lt;/span> 根据行列式性质，我们可以将其中的&lt;span class="math">\(P,P^{-1}\)&lt;/span>提出来： &lt;span class="math">\[|P^{-1}(A-\lambda I)P|=|P^{-1}| |A-\lambda I| |P|=|A-\lambda I|\]&lt;/span> 这是因为行列式的计算结果都是数字，且&lt;span class="math">\(|P^{-1}||P|=1\)&lt;/span>，综上可得 &lt;span class="math">\[f(\lambda)=|A-\lambda I|=|B-\lambda I|=g(\lambda)\]&lt;/span> 即矩阵&lt;span class="math">\(A,B\)&lt;/span>拥有相同的特征多项式，因此他们的的特征值也相同。&lt;/p>
&lt;/blockquote>
&lt;p>由于相似矩阵的特征多项式一样，他们的特征值也一样。而特征值是否为0决定了矩阵的秩，因此二者秩相等；特征值的和等于矩阵的迹，因此二者迹相等；特征值的积等于行列式值，因此两者的行列式值相等。&lt;/p>
&lt;p>相似矩阵在不改变特征值的时候，特征向量有什么变化呢？&lt;/p>
&lt;p>由于&lt;span class="math">\(B=P^{-1}AP\)&lt;/span>中，那么对于&lt;span class="math">\(B\)&lt;/span>的特征值&lt;span class="math">\(\lambda\)&lt;/span>与相应的特征向量&lt;span class="math">\(x_B\)&lt;/span>有： &lt;span class="math">\[
Bx_B=\lambda x_B
\]&lt;/span> 将&lt;span class="math">\(B=P^{-1}AP\)&lt;/span>代入得： &lt;span class="math">\[
\lambda x_B=Bx_B=P^{-1}APx_B
\]&lt;/span> 两边同时左乘&lt;span class="math">\(P\)&lt;/span>： &lt;span class="math">\[
\lambda(Px_B)=PP^{-1}APx_B=A(Px_B)
\]&lt;/span> 由于&lt;span class="math">\(\lambda\)&lt;/span>也是&lt;span class="math">\(A\)&lt;/span>的特征值，那么&lt;span class="math">\(x_A=Px_B\)&lt;/span>就是&lt;span class="math">\(A\)&lt;/span>的特征向量。&lt;/p>
&lt;h3 id="相似矩阵与可对角化条件">相似矩阵与可对角化条件&lt;/h3>
&lt;p>首先我们引入一个定义：（详细有关正规矩阵的内容见笔记&lt;a href="线性代数与矩阵之正规矩阵.md">线性代数与矩阵之正规矩阵&lt;/a>）&lt;/p>
&lt;blockquote>
&lt;p>正规矩阵：在数学中，正规矩阵（英语：normal matrix）&lt;span class="math">\(A\)&lt;/span>是与自己的共轭转置满足交换律的复系数方块矩阵，也就是说，&lt;span class="math">\(A\)&lt;/span>满足 &lt;span class="math">\[A^\ast A=AA^\ast\]&lt;/span> 其中&lt;span class="math">\(A\ast\)&lt;/span>是&lt;span class="math">\(A\)&lt;/span>的共轭转置。如果&lt;span class="math">\(A\)&lt;/span>是实系数矩阵，则&lt;span class="math">\(A^\ast=A^T\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>可对角化条件：&lt;/p>
&lt;p>可对角化的矩阵一定是正规矩阵吗？&lt;/p>
&lt;p>不一定。&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>矩阵可对角化，意思就是矩阵与对角阵相似。&lt;/li>
&lt;li>矩阵与对角阵相似，分为正交（酉）相似、和非正交（酉）相似。&lt;/li>
&lt;li>正交（酉）相似于对角阵，当且仅当是正规矩阵。&lt;/li>
&lt;li>非正规矩阵，可以与对角阵相似，但不是正交（酉）相似。&lt;/li>
&lt;/ol>
&lt;p>关于正交相似：在线性代数中，实对称矩阵一定可以对角化，而且是正交对角化，也叫正交相似于对角阵。&lt;/p>
&lt;h2 id="jordan标准型">Jordan标准型&lt;/h2>
&lt;p>如果把矩阵转换成其相似的对角阵，那么矩阵的研究会简化许多。然而，可惜的是并不是所有矩阵都可以相似对角化。只有正规矩阵可以相似对角化，那么有没有另一种简单而标准的形态，使得矩阵都可与之相似呢？&lt;/p>
&lt;p>答案是Jordan标准型。&lt;/p>
&lt;blockquote>
&lt;p>Jordan标准型：是一种分块对角矩阵。 &lt;span class="math">\[
J={\begin{bmatrix}J_{1}&amp;amp;\;&amp;amp;\;\\\;&amp;amp;\ddots &amp;amp;\;\\\;&amp;amp;\;&amp;amp;J_{p}\end{bmatrix}}
\]&lt;/span> 其中，每一个分块矩阵&lt;span class="math">\(J_i\)&lt;/span>都具备一种很简单的形状 &lt;span class="math">\[
J_{i}=\begin{bmatrix}
\lambda_{i}&amp;amp;1&amp;amp;\;&amp;amp;\;\\
\;&amp;amp;\lambda_{i}&amp;amp;\ddots &amp;amp;\;\\
\;&amp;amp;\;&amp;amp;\ddots &amp;amp;1\\
\;&amp;amp;\;&amp;amp;\;&amp;amp;\lambda_{i}
\end{bmatrix}
\]&lt;/span> 其中主对角线上都是同一个系数，而对角线上方一排全是1。形同以上&lt;span class="math">\(J_{i}\)&lt;/span>的矩阵称为Jordan矩阵。而矩阵&lt;span class="math">\(J\)&lt;/span>中每一个这样的小块被称为Jordan块。&lt;/p>
&lt;/blockquote>
&lt;p>线性代数中有如下的结果：&lt;/p>
&lt;p>对任意系数域为&lt;span class="math">\(\mathbb {K}\)&lt;/span>，例如实数域，复数域的矩阵&lt;span class="math">\(M\)&lt;/span>，只要其特征值都在&lt;span class="math">\(\mathbb {K}\)&lt;/span>中，就存在一个与之相似的Jordan标准型&lt;span class="math">\(J：M=PJP^{{-1}}\)&lt;/span>，其中&lt;span class="math">\(P\)&lt;/span>是一个可逆矩阵。并且满足：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>矩阵&lt;span class="math">\(J\)&lt;/span>的特征值（计入重数）就是主对角线上的系数。&lt;/li>
&lt;li>对于&lt;span class="math">\(J\)&lt;/span>的一个特征值&lt;span class="math">\(\lambda_i\)&lt;/span>，它的几何重数就是属于特征值&lt;span class="math">\(\lambda_i\)&lt;/span>的Jordan块的个数。&lt;/li>
&lt;li>所有属于特征值&lt;span class="math">\(\lambda_i\)&lt;/span>的Jordan块的维数之和是特征值&lt;span class="math">\(\lambda_i\)&lt;/span>的代数重数。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>Jordan定理：任意&lt;span class="math">\(n\)&lt;/span>阶矩阵&lt;span class="math">\(A\)&lt;/span>都与一个Jordan矩阵&lt;span class="math">\(J\)&lt;/span>相似。Jordan矩阵中的每一个Jordan块对应一个特征向量。若矩阵具有&lt;span class="math">\(n\)&lt;/span>个不同的特征向量，则可以对角化，此时其Jordan标准型&lt;span class="math">\(J\)&lt;/span>就是对角矩阵&lt;span class="math">\(Λ\)&lt;/span>。若出现重特征值，则特征向量个数可能变少，减少的数量取决于Jordan块大小。&lt;/p>
&lt;/blockquote>
&lt;p>Jordan标准型虽然很好，但是将矩阵转换为Jordan标准型并不是一个容易的过程。因此，Jordan标准型的应用也受到了限制。&lt;/p></description></item><item><title>线性代数与矩阵之理解向量、线性变换与矩阵乘法</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%90%86%E8%A7%A3%E5%90%91%E9%87%8F%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/</link><pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%90%86%E8%A7%A3%E5%90%91%E9%87%8F%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95/</guid><description>
&lt;h2 id="线性代数与矩阵之理解向量线性变换与矩阵乘法">线性代数与矩阵之理解向量、线性变换与矩阵乘法&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#三个需要认可的前提">三个需要认可的前提&lt;/a>&lt;/li>
&lt;li>&lt;a href="#向量的表示及其分解">向量的表示及其分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#线性组合与基">线性组合与基&lt;/a>&lt;/li>
&lt;li>&lt;a href="#空间的基">空间的基&lt;/a>&lt;/li>
&lt;li>&lt;a href="#线性变换与矩阵">线性变换与矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#线性变换">线性变换&lt;/a>&lt;/li>
&lt;li>&lt;a href="#用矩阵描述线性变换">用矩阵描述线性变换&lt;/a>&lt;/li>
&lt;li>&lt;a href="#从基变换的角度再看矩阵">从基变换的角度再看矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#矩阵乘以矩阵">矩阵乘以矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#从左边乘一个矩阵">从左边乘一个矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#从右边乘一个矩阵">从右边乘一个矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#bp-1ap">&lt;span class="math">\(B=P^{-1}AP\)&lt;/span>&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tips">Tips&lt;/a>&lt;/li>
&lt;li>&lt;a href="#n维空间有多少个向量">N维空间有多少个向量&lt;/a>&lt;/li>
&lt;li>&lt;a href="#逆矩阵">逆矩阵&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="三个需要认可的前提">三个需要认可的前提&lt;/h2>
&lt;ol style="list-style-type: decimal">
&lt;li>对于空间，只考虑拓扑维数，不考虑分形维数。 （像这种“不说人话”的描述其实无助于理解，其实就是想说，我们考虑的空间都是自然数维度的，零维、一维、二维、三维、四维……） &lt;img src="../../images/空间维数.svg" alt="空间维数" />&lt;/li>
&lt;li>事物是客观存在的，对事物的观测是主观的。 对于同一个事物，如果观测的角度、方式等不同，会得出不同的结果。 &lt;img src="../../images/多角度观测.jpg" alt="多角度观测" />&lt;/li>
&lt;li>运动是相对的。比如右下图，如果要以地球为坐标系，太阳系天体实际上运动是复杂且诡异的。但是也不能说右下图的描述不对或无用，只是参考坐标系不一样。比如天球坐标系是位置天文学上很实用的工具。 &lt;embed src="../../images/日心说地心说.webp" />&lt;/li>
&lt;/ol>
&lt;h2 id="向量的表示及其分解">向量的表示及其分解&lt;/h2>
&lt;p>到了这里，别忘了这篇文章不是讲哲学，也不敢尝试探究过深的问题，只是谈谈自己对向量、线性变化、矩阵的理解。&lt;/p>
&lt;p>首先说的是最基础的向量(不做特殊说明时一般都以列向量的形式表示)。对于向量的理解，各有各的说法。向量可以是任何东西，只需要保证：两个&lt;strong>向量相加及数字与向量相乘&lt;/strong>是有意义的即可。向量的加法和数乘是两个基础运算贯穿始终。而所有这些向量组成的集合，称为&lt;strong>空间&lt;/strong>。&lt;a href="#N维空间有多少个向量">Tips：N维空间有多少个向量？&lt;/a>&lt;/p>
&lt;p>&lt;img src="../../images/向量是什么.png" alt="向量是什么" /> 截图自&lt;a href="https://www.bilibili.com/video/av6731067?p=2">线性代数的本质-系列合集&lt;/a>&lt;/p>
&lt;p>我们主要关注的是，我们是如何描述一个向量的。还记得，我们的第一个前提吗？“我们考虑的空间都是自然数维度的”，&lt;strong>维度&lt;/strong>是指空间中独立参数的数目，也就是我们用来描述空间中&lt;strong>所有&lt;/strong>向量&lt;strong>最少&lt;/strong>需要的参数个数。比如，在二维平面中，我们至少需要两个量&lt;span class="math">\([a_1,a_2]^T\)&lt;/span>来描述空间中&lt;strong>任一个点&lt;/strong>的位置，类似的，在三维空间中至少需要3个量&lt;span class="math">\([a_1,a_2,a_3]^T\)&lt;/span>。&lt;/p>
&lt;p>线性代数描述的三维空间中，我们使用3个数字表示一个向量，例如&lt;span class="math">\([a_1,a_2,a_3]^T\)&lt;/span>，我们在使用这个3个数字的时候，经常只关注到数值，并没有关心3个数的顺序，也是说，不仅仅数值中含有空间向量的信息，他们的顺序也是含有信息的，顺序+数值=空间向量。但是，回过头来说，这3个数字+顺序到底代表这什么呢？&lt;/p>
&lt;p>现实中，我们如何描述某地的位置呢？假设我们需要把一个快递送到指定位置，如下图的中航广场4楼。如果超人，可以无视地理环境沿着绿色的箭头直接飞过去就行了。但实际上，送快递的活计都是凡人在做，所以我们得先向前走400m，然后左转再走200m，最后坐电梯向上10m。有意思的地方来了，虽然我们无法直接飞达目的地，但是我们能够通过麻烦一点的方法，向着三个方向走三次，到达同样的目的地。这两种方式异曲同工。从另一个角度来讲，&lt;strong>把绿色向量这个向量可以拆分成三个红色向量的和（向量的加法）&lt;/strong>。而且，我们在描述这3个方向的步骤时，可以换一种更细碎的描述：&lt;em>先向前走1m，然后沿着这个方向走，直到走到1m的400倍；然后向左走1米，沿着向左的方向走直到走到1m的200倍；最后坐电梯向上1m，沿着向上的方向坐电梯直到1m的10倍&lt;/em>。也就是说，我们沿某一个方向行进时，可以行进某一特定长度的倍数（&lt;strong>向量的数乘&lt;/strong>），如果每个方向都取一样的特定长度，那我们就把这个方向与特定长度的组合称为&lt;strong>单位向量&lt;/strong>（例子中特定长度不一定非要是1，其他值也行）。&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/三维坐标.png" alt="三维坐标.png" />&lt;p class="caption">三维坐标.png&lt;/p>
&lt;/div>
&lt;p>现在，我们知道可以把在三维空间中的1个向量，分解成3个单位向量&lt;strong>分别&lt;/strong>乘以其倍数的和（向量加法与数乘的线性组合）。那么能不能分成2个向量之和呢？当然可以！如果我们把向左200m的向量和向上10m的（红色）向量，变成1个等效的向量比如向左上方&lt;span class="math">\(\sqrt{200^2+10^2}m\)&lt;/span>（黄色的向量）就可以了啊。但是现在问题来了，收快递的人说我现在不在4楼，被发配到地下1层了，需要坐电梯向下3m到负1层。那么按照&lt;span class="math">\([向前,向左上]\)&lt;/span>的2个向量行进方式，是无论如何也到不了中航广场地下1层的。然而，原来用3个向量的分解方式，只要说在最后一个方向上，沿着向上的方向坐电梯直到1m的-3倍，那么还是能够完成送达的任务。总结来说，如果是分成2个方向，换了一个地点，那么方向大概率也得换（这个概率→1，因为三维空间中的二维平面测度是0，所以目标点恰好落在两个特定向量组成的平面的概率也是0）；而分成3个方向，依旧保证只沿着3个方向目标可达。因此，在我们生活的三维空间中，&lt;strong>所有&lt;/strong>位置都可以用&lt;strong>至少&lt;/strong>3个单位向量&lt;strong>分别&lt;/strong>乘以其倍数的和到达。在三维空间中用至少用3个向量是为了保证组成向量的&lt;strong>任意性&lt;/strong>。&lt;/p>
&lt;p>回顾一下，之前说三维空间中至少需要3个量&lt;span class="math">\([a_1,a_2,a_3]^T\)&lt;/span>来描述空间中&lt;strong>任一个点&lt;/strong>的位置，我们把这个向量换一种表述方式，即&lt;span class="math">\(a_1\vec{x}+a_2\vec{y}+a_3\vec{z}\)&lt;/span>。是不是就是上例中的3个单位向量&lt;strong>分别&lt;/strong>乘以其倍数的和？3个数字，分别对应了在3个方向上的行进倍数，因此它们的顺序是不能调换的。这3个单位向量的选择不是唯一的，只要他们&lt;strong>线性无关&lt;/strong>即可。这个概念下节会说的，先按下不表。我们同样可以想象：N维空间所有点至少需要N个向量来表示，可数无穷维空间所有点至少需要可数无穷个向量来表示。&lt;/p>
&lt;p>现在总结一下这一节的内容，如何表示向量呢？在N维空间中，可以用N个有序的数字表示&lt;span class="math">\([a_1,a_2,\dots,a_N]^T\)&lt;/span>，这是一种方便的描述方式。而这个向量，一定可以分解成N个单位向量的特定倍数的和。&lt;/p>
&lt;h2 id="线性组合与基">线性组合与基&lt;/h2>
&lt;p>上一节中，提到一个向量可以分解成&lt;strong>多个单位向量特定倍数的和&lt;/strong>，即&lt;span class="math">\(\vec{v}=a_1\vec{v_1}+a_2\vec{v_2}+a_3\vec{v_3}+\dotsb\)&lt;/span>。总是这么描述很费劲，因此，我们给他起个名字，叫它&lt;strong>线性组合&lt;/strong>。&lt;/p>
&lt;p>所谓线性，&lt;em>我觉得&lt;/em>是一种&lt;strong>平直均匀&lt;/strong>的特性（记住以后还会提到）。具体来看，其实主要是两条，&lt;strong>一个是数乘，一个是相加&lt;/strong>。假设一组向量只包含这两种运算，那我们就可以把他叫做线性组合。写成符号语言就是：&lt;span class="math">\(a\vec{u}+b\vec{v}+c\vec{w}\)&lt;/span>。N维空间所有点至少需要N个向量来表示。也就是说，一个N维空间中的任意向量，一定能表示成至少N个单位向量的线性组合。&lt;/p>
&lt;p>那么换个角度来看，N个单位向量的线性组合可以表示多少个向量呢？&lt;/p>
&lt;p>首先，我们先说明向量&lt;strong>张成&lt;/strong>的空间。我们把&lt;strong>所有&lt;/strong>可以表示为给定向量线性组合的&lt;strong>向量的集合&lt;/strong>，被称为给定向量&lt;strong>张成的空间&lt;/strong>。&lt;strong>张成&lt;/strong>英文原文为“span”，有包括；遍及的意思（If something spans a range of things, all those things are included in it. 柯林斯高阶英汉双解词典）。张成二字可以理解为由N个单位向量&lt;strong>所有的线性组合&lt;/strong>。这样就好理解了，N个单位向量的线性组合能够表示的向量都在它们所张成的空间中。如果这N个向量可以线性组和成N维空间中的任意一个向量，那么这N个向量张成的空间就等于这个N维空间。&lt;/p>
&lt;p>有人心里又有疑惑：&lt;em>来表示任一N维向量的N个单位向量是否是随便选的？或者说，满足什么条件的N个单位向量才能表示出N维空间的所有向量？&lt;/em>&lt;/p>
&lt;p>之前说过，&lt;em>N维空间所有点至少需要N个向量来表示&lt;/em>。那么选定N个单位向量张成的空间就是N维吗？有时候所选的N个单位向量能被降维成N-1个单位向量，并且张成的向量空间维数（≥N-1维）与降维前一致 ，那么这N个单位向量就无法表示出N维空间的所有向量。也就是说，N个单位向量中存在没用（冗余）的向量，那些用所选的N个单位向量能表示出来的向量，都可以用其中N-1个单位向量表示出来。假如N个单位向量&lt;span class="math">\({\vec{v_1},\dotsb,\vec{v}_N}\)&lt;/span>中，多余的向量是&lt;span class="math">\(\vec{v_r}(1≤r≤N)\)&lt;/span>，那么 &lt;span class="math">\[\begin{aligned}
&amp;amp;\forall \vec{w}=a_1\vec{v}_1+a_2\vec{v}_2+\dotsb+a_N\vec{v}_N\\
&amp;amp;可以改写成：\\
&amp;amp;\vec{w}=b_1\vec{v}_1+\dotsb+b_{r-1}\vec{v}_{r-1}+b_{r+1}\vec{v}_{r+1}+\dotsb+b_N\vec{v}_N
\end{aligned}\]&lt;/span> 由于这两个式子是相等的，即 &lt;span class="math">\[\begin{aligned}
&amp;amp;\quad a_1\vec{v}_1+a_2\vec{v}_2+\dotsb+a_N\vec{v}_N\\
&amp;amp;=b_1\vec{v}_1+\dotsb+b_{r-1}\vec{v}_{r-1}+b_{r+1}\vec{v}_{r+1}+\dotsb+b_N\vec{v}_N \\
&amp;amp;\Rightarrow(a_1-b_1)\vec{v}_1+\dotsb+(a_{r-1}-b_{r-1})\vec{v}_{r-1}\\
&amp;amp;+a_r\vec{v}_r+(a_{r+1}-b_{r+1})\vec{v}_{r+1}+\dotsb+(b_N-a_N)\vec{v}_N=0\\
&amp;amp;(单独列出a_r\vec{v}_r)\\
&amp;amp;\Rightarrow a_r\vec{v}_r=(b_1-a_1)\vec{v}_1+\dotsb+(b_{r-1}-a_{r-1})\vec{v}_{r-1}\\
&amp;amp;+(b_{r+1}-a_{r+1})\vec{v}_{r+1}+\dotsb+(b_N-a_N)\vec{v}_N
\end{aligned}\]&lt;/span> 这个式子最后发现，如果存在多余的单位向量&lt;span class="math">\(\vec{v_r}(1≤r≤N)\)&lt;/span>，那么这个多余的向量必然可以被其他N-1个单位向量线性组合出来。换句话说，他们之间是有关系的。基于这种线性组合关系（加法与数乘），我们称这种关系为&lt;strong>线性相关&lt;/strong>。总结一下，线性相关的两个角度描述：&lt;/p>
&lt;ul>
&lt;li>【表达一】你有多个向量，并且可以移除其中一个而不减小张成的空间，我们称它们（这些向量）线性相关&lt;/li>
&lt;li>【表达二】其中一个向量，可以表示为其他向量的线性组合，因为这个向量已经落在其他向量张成的空间之中&lt;/li>
&lt;/ul>
&lt;p>在几何中，线性相关表现在2D是共线，3D中是共面或共线（比如&lt;span class="math">\([0,0,1]^T,[0,0,2]^T,[0,0,3]^T\)&lt;/span> 3个三维线性相关向量共线。）&lt;/p>
&lt;p>相反的，如果N个单位向量中，任一个向量&lt;span class="math">\(\vec{v_i}\)&lt;/span>都不能表示成其他N-1个向量&lt;span class="math">\(\vec v_1,\vec v_2,\dots,\vec v_{i-1},\vec v_{i+i},\dots,\vec v_N\)&lt;/span>的线性组合，那么这N个向量就是&lt;strong>线性无关&lt;/strong>的，也就是他们之前没有线性组合的关系。&lt;/p>
&lt;h3 id="空间的基">空间的基&lt;/h3>
&lt;p>现在回看问题：满足什么条件的N个单位向量才能表示出N维空间的所有向量？答案就是&lt;strong>线性无关的N个单位向量&lt;/strong>。讲了这么多，我们终于知道满足线性无关要求的N个单位向量能够表示出N维空间所有的向量，这些满足条件的N个单位向量，我们称之为&lt;strong>N维空间的基（Basis）&lt;/strong>。所谓基，以基为砖，万物皆可构筑:dog:。&lt;strong>用基可以构建出空间中任一向量，任一向量也可分解成空间基的线性组合&lt;/strong>。&lt;/p>
&lt;p>相应的，每一组基都是一个极大的线性无关集合，也就是说在N维空间中，找不出N+1个线性无关的向量。因为第N+1个向量必然属于N维空间，而N维空间的所有向量都可以被表示为N个线性无关的单位向量的线性组合，那么第N+1个向量必然也可以是这N个单位向量的线性组合，即是线性相关的。&lt;/p>
&lt;p>最后还要强调一点，大家先再读一遍&lt;a href="#三个需要认可的前提">三个需要认可的前提&lt;/a>的第2条。之前在说基或单位向量的时候，一直避免说基的具体值，比为二维空间中&lt;span class="math">\([1,0]^T,[0,1]^T\)&lt;/span>这样常见的基，是因为不想给大家一个固定印象，认为基的取法是固定的。下图中，左右两幅图中同一个向量在不同基下，表示方式也不同。&lt;/p>
&lt;img src="../../images/不同基底对空间中同一向量的描述.png" alt="不同基底对空间中同一向量的描述" />
&lt;center>
不同基底对空间中同一向量的描述
&lt;/center>
&lt;p>在基&lt;span class="math">\([1,0]^T,[0,1]^T\)&lt;/span>下，向量为&lt;span class="math">\([4,5]^T\)&lt;/span>；在基&lt;span class="math">\([\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}}]^T,[-\frac{1}{\sqrt{2}},\frac{1}{\sqrt{2}}]^T\)&lt;/span>下，向量为&lt;span class="math">\([\frac{9}{\sqrt{2}},\frac{1}{\sqrt{2}}]^T\)&lt;/span>。向量的值，只是表示对应单位向量在线性组合中的倍数，因此在不同基下&lt;span class="math">\([4,5]^T\)&lt;/span>与&lt;span class="math">\([\frac{9}{\sqrt{2}},\frac{1}{\sqrt{2}}]^T\)&lt;/span>是同一个向量也就不奇怪了。大多数人一开始以为基就是&lt;span class="math">\([1,0]^T,[0,1]^T\)&lt;/span>这样的向量组，是因为它们实在是太常用了，以至于很多情况下默认的基就是这个样子。类似于&lt;span class="math">\({e_1=(1,0,0), e_2=(0,1,0), e_3=(0,0,1)}\)&lt;/span>组成的基&lt;strong>全称是标准正交基&lt;/strong>。&lt;/p>
&lt;p>关于上面那幅不同基底对空间中同一向量的描述的图，留一个思考题： &lt;span class="math">\[\begin{bmatrix}1&amp;amp;0\\0&amp;amp;1\end{bmatrix}\begin{bmatrix}4\\5\end{bmatrix}\overset{?}{=}\begin{bmatrix}\frac{1}{\sqrt{2}}&amp;amp;-\frac{1}{\sqrt{2}}\\\frac{1}{\sqrt{2}}&amp;amp;\frac{1}{\sqrt{2}}\end{bmatrix}\begin{bmatrix}\frac{9}{\sqrt{2}}\\ \frac{1}{\sqrt{2}}\end{bmatrix}\]&lt;/span> 直观的解释，为什么会相等呢？&lt;/p>
&lt;h2 id="线性变换与矩阵">线性变换与矩阵&lt;/h2>
&lt;p>矩阵，最直观的理解当然是一个写成方阵的数字&lt;span class="math">\(\begin{bmatrix}1&amp;amp;2\\3&amp;amp;4\end{bmatrix}\)&lt;/span>。这一节的核心是为了说明：矩阵从变换的角度来看就是一种线性变换。&lt;/p>
&lt;h3 id="线性变换">线性变换&lt;/h3>
&lt;p>【变换】本质上是【函数】（左）的一种花哨的说法，它接受输入内容，并输出对应结果。那矩阵也是变换吗？是的。以矩阵为变换（右），其过程表示为接收一个向量，然后输出另一个向量如下图。也可以说矩阵是【向量的函数】。&lt;/p>
&lt;p>&lt;img src="../../images/变换与函数.gif" width=200px>&lt;/img> &lt;img src="../../images/变换与函数2.gif" width=200px>&lt;/img>&lt;/p>
&lt;p>【变换】，直观的解释就是向量从一个地方变到了另一个地方，这暗示了我们可以用运动的方法来理解【向量的函数】这一概念。可以用可视化的方法来展现这组【变换】即输入-输出关系：&lt;/p>
&lt;p>&lt;img src="../../images/InputOutput.gif" alt="InputOutput.gif" width=400px>&lt;/img>&lt;/p>
&lt;p>但是通常所说的运动是一个连续的过程，而变换是将向量直接放到另一个地方。有点像瞬移：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/teleport.gif" alt="瞬移" />&lt;p class="caption">瞬移&lt;/p>
&lt;/div>
&lt;p>在变换中，有一类变换特别重要，就是线性变换。几何角度来说，具有以下两个性质的就是线性变换（直观可视化如下图）：&lt;/p>
&lt;img src="../../images/LinearTransform.gif" alt="LinearTransform.gif" />
&lt;center>
线性变换的几何演示
&lt;/center>
&lt;ul>
&lt;li>直线在变换后&lt;strong>仍然保持为直线&lt;/strong>，不能有所弯曲（&lt;strong>平直性，这也是线性的直观几何反映&lt;/strong>）。从图上来看，线性变换是“保持网格线平行且等距分布（均匀性）”的变换。&lt;/li>
&lt;li>&lt;strong>原点&lt;/strong>必须保持&lt;strong>固定&lt;/strong>&lt;/li>
&lt;/ul>
&lt;p>如果保持保持直线但&lt;strong>原点改变&lt;/strong>就称为：仿射变换（Affine Transformation）。仿射变换就是在线性变换的基础上加了一个偏移量。比如&lt;span class="math">\(y=2x\)&lt;/span>是线性变换，&lt;span class="math">\(y=2x+3\)&lt;/span>就是仿射变换。实际上，N维空间的仿射变换等价于N+1维空间的线性变换。详细理解参见&lt;a href="https://www.matongxue.com/madocs/244/">如何通俗的解释仿射变换？&lt;/a>&lt;/p>
&lt;p>线性变换有个非常重要的特性。如果&lt;span class="math">\(\vec{w}=a_1\vec{v}_1+a_2\vec{v}_2+\dotsb+a_N\vec{v}_N\)&lt;/span>。那么 &lt;span class="math">\[L(\vec{w})=L(a_1\vec{v}_1)+L(a_2\vec{v}_2)+\dotsb+L(a_N\vec{v}_N)\\
=a_1L(\vec{v}_1)+a_2L(\vec{v}_2)+\dotsb+a_NL(\vec{v}_N)\]&lt;/span> 其中&lt;span class="math">\(L(\cdot)\)&lt;/span>代表线性变换。我们在“线性组合和基”那一节说过，线性是一种&lt;strong>平直均匀&lt;/strong>的特性。上面的公式就是说的&lt;strong>均匀&lt;/strong>这一点（平直反映在直线线性变换后仍然时直线）。所谓均匀的特性，就是线性变换对&lt;strong>整体的每一部分变换都是一致的&lt;/strong>，这样的话，我们就可以把整体拆成一个个部分，对每一个部分先做线性变换，然后再合并。在上图“线性变换的几何演示”中，我们可以发现整体的变换和局部是一致的：一个大正方形（四个小正方形组成）变成平四边形等效于其中每个小正方形变成平行四边形再组合。上面的等式是用数学的方式表示，对向量整体的线性变换，等于对组成向量整体的每一部分分别做一样的线性变换再组合。&lt;strong>这就是线性的可加性&lt;/strong>。数乘可以算是可加性的一种特例，就是&lt;span class="math">\(a∈R\)&lt;/span>个向量&lt;span class="math">\(\vec{v}\)&lt;/span>相加，根据上面对线性变换均匀特性的解释，也就容易解释为何&lt;span class="math">\(aL(\vec{v})=L(a\vec{v})\)&lt;/span>了。&lt;strong>这称为线性的齐次性&lt;/strong>。&lt;/p>
&lt;h3 id="用矩阵描述线性变换">用矩阵描述线性变换&lt;/h3>
&lt;p>在开始的时候，我们谈到空间中用一组有序数列的方式描述一个向量。那么在空间中，描述线性变换是什么呢？就是矩阵。直观上来看，矩阵一点也体现不出线性。但是，我们回想一下刚刚所说的，对向量整体的线性变换，等于对组成向量整体的每一部分分别做一样的线性变换再组合。&lt;/p>
&lt;p>这里需要使用上一节提到的工具，空间的基，也就是单位向量。“线性组合与基”一节中，我们已经知道，空间中任一向量可以表示成空间基的线性组合。为了方便描述，我们选取&lt;strong>标准正交基&lt;/strong>来分解向量。例如，二维空间中，有向量&lt;span class="math">\(\vec w\)&lt;/span>分解： &lt;span class="math">\[\vec{w}=\begin{bmatrix}-1\\2\end{bmatrix}=-1*\begin{bmatrix}1\\0\end{bmatrix}+2*\begin{bmatrix}0\\1\end{bmatrix}\]&lt;/span> 令&lt;span class="math">\(e_1=[1,0]^T,e_2=[0,1]^T\)&lt;/span>，所以简写成&lt;span class="math">\(\vec{w}=-1\vec{e}_1+2\vec{e}_2\)&lt;/span>。现在有一个线性变换&lt;span class="math">\(L(\cdot)\)&lt;/span>，则 &lt;span class="math">\[\begin{aligned}
&amp;amp;L(\vec{w})=L(-1\vec{e}_1+2\vec{e}_2)\\
&amp;amp;根据上小节线性变换的特性有：\\
&amp;amp;=-1L(\vec{e}_1)+2L(\vec{e}_2)
\end{aligned}\]&lt;/span> 假设这个线性变换将2个基向量分别变成： &lt;span class="math">\[e_1&amp;#39;=L(\vec{e}_1)=\begin{bmatrix}3\\1\end{bmatrix},e_2&amp;#39;=L(\vec{e}_2)=\begin{bmatrix}1\\2\end{bmatrix}\]&lt;/span> 则&lt;span class="math">\(L(\vec{w})\)&lt;/span>有： &lt;span class="math">\[L(\vec{w})=-1*\begin{bmatrix}3\\1\end{bmatrix}+2*\begin{bmatrix}1\\2\end{bmatrix}\]&lt;/span> 如果我们再把变换后的基写到一起，那么就有 &lt;span class="math">\[[e_1&amp;#39;,e_2&amp;#39;]=\begin{bmatrix}3&amp;amp;1\\1&amp;amp;2\end{bmatrix}\]&lt;/span> 这就构成了一个矩阵。说白了，矩阵是从&lt;strong>局部变换&lt;/strong>的角度描述线性变换，局部就是向量分解成的基向量。也可以说矩阵是从&lt;strong>基变换&lt;/strong>的角度描述线性变换，只需要关注基向量变换后的位置即可。&lt;/p>
&lt;p>上个例子的几何描述如下图所示：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/线性变换和矩阵.gif" alt="线性变换和矩阵.gif" />&lt;p class="caption">线性变换和矩阵.gif&lt;/p>
&lt;/div>
&lt;p>更加一般的情况，我们用变量来代替其中的具体值：绿色代表&lt;span class="math">\(\vec i\)&lt;/span> 变换后的向量，红色代表&lt;span class="math">\(\vec j\)&lt;/span>变换后的向量 &lt;span class="math">\[\begin{bmatrix} \color{green}{a}&amp;amp;\color{red}b \\ \color{green}c&amp;amp;\color{red}d \end{bmatrix} \begin{bmatrix}x\\y\end{bmatrix}=\underbrace{x \begin{bmatrix}\color{green}a\\\color{green}c \end{bmatrix} + y \begin{bmatrix} \color{red}b\\\color{red}d\end{bmatrix}}_{\text{直观的部分这里}} =\begin{bmatrix} \color{green}{a}\color{black}{x}+\color{red}{b}\color{black}{y}\\\color{green}{c}\color{black}{x}+\color{red}{d}\color{black}{y}\end{bmatrix}\]&lt;/span> 上面的公式就是我们常说的矩阵乘法公式，就是线性变换后基的线性组合。&lt;/p>
&lt;h3 id="从基变换的角度再看矩阵">从基变换的角度再看矩阵&lt;/h3>
&lt;p>还记得我们在上节中如何导出矩阵的吗？是把几个变换后基向量写到了一起。现在到了关键的一步。看上去矩阵就是由一组向量组成的，而且如果矩阵非奇异的话（现在只考虑这种情况，如果是奇异矩阵就是个降维了的坐标系），那么组成这个矩阵的那一组向量也就是线性无关的了，也就可以成为度量线性空间的一个基。结论：&lt;strong>矩阵描述了一个空间的基&lt;/strong>。刚刚不是还说矩阵是变换描述向量的运动吗？怎么变成了基呢？现在回去读读&lt;a href="#三个需要认可的前提">三个需要认可的前提&lt;/a>第3点，实际上物体的运动可以等效成参考系的运动。&lt;/p>
&lt;p>在“线性组合和基”小节的最后，我们留了个思考题： &amp;gt;&lt;span class="math">\[\begin{bmatrix}1&amp;amp;0\\0&amp;amp;1\end{bmatrix}\begin{bmatrix}4\\5\end{bmatrix}\overset{?}{=}\begin{bmatrix}\frac{1}{\sqrt{2}}&amp;amp;-\frac{1}{\sqrt{2}}\\\frac{1}{\sqrt{2}}&amp;amp;\frac{1}{\sqrt{2}}\end{bmatrix}\begin{bmatrix}\frac{9}{\sqrt{2}}\\ \frac{1}{\sqrt{2}}\end{bmatrix}\]&lt;/span> &amp;gt;直观的解释，为什么会相等呢？&lt;/p>
&lt;p>因为它们只是用不同的基描述同一个向量啊。从这个角度看，矩阵&lt;span class="math">\(M\vec a = \vec b\)&lt;/span>的意思是：有一个向量，它在空间基&lt;span class="math">\(M\)&lt;/span>的度量下得到的度量结果向量为&lt;span class="math">\(\vec a\)&lt;/span>，那么它在标准正交基&lt;span class="math">\(E\)&lt;/span>的度量下，这个向量的度量结果是&lt;span class="math">\(\vec b\)&lt;/span>，而本质上它俩说的是一个向量，所以是相等的。更完整的写法应该是这样：&lt;span class="math">\(M\vec a = E\vec b\)&lt;/span>。&lt;/p>
&lt;p>如果这个角度还不好懂，我再提供一个大神的理解方式&lt;a href="https://www.bilibili.com/video/av6731067/">3B1B的关于线性代数系列视频&lt;/a>，大体内容如下：&lt;/p>
&lt;p>如果假设有一个二维向量，使用标准正交基&lt;span class="math">\(\vec{i}=e_1\)&lt;/span> 和 &lt;span class="math">\(\vec{j}=e_2\)&lt;/span> 来描述是 &lt;span class="math">\(\begin{bmatrix} 3 \\ 2 \end{bmatrix}\)&lt;/span> ，我们把这种描述称为：我们的语言。如果有另一组基向量&lt;span class="math">\(\vec{i}&amp;#39;=\begin{bmatrix}2 \\1\end{bmatrix}\)&lt;/span>和 &lt;span class="math">\(\vec{j}&amp;#39; = \begin{bmatrix} -1 \\ 1 \end{bmatrix}\)&lt;/span> （写成列向量的形式是为了形式上的统一）来描述同样一个向量变成 &lt;span class="math">\(\begin{bmatrix} \frac{5}{3} \\ \frac{1}{3} \end{bmatrix}\)&lt;/span> ，我们把这种语言记为：詹妮弗的语言。显然两种语言描述同一样东西，所以： &lt;span class="math">\[\begin{bmatrix}1&amp;amp;0\\0&amp;amp;1\end{bmatrix}\begin{bmatrix}3\\2\end{bmatrix}=\begin{bmatrix}2&amp;amp;-1\\1&amp;amp;1\end{bmatrix}\begin{bmatrix}5/3\\1/3\end{bmatrix}\]&lt;/span> 在不同的【语言】之间的转化使用矩阵向量乘法，在上面的例子中，转移矩阵是 &lt;span class="math">\(\mathbf T = \begin{bmatrix} 2 &amp;amp; -1 \\ 1 &amp;amp; 1 \end{bmatrix}\)&lt;/span> ，矩阵的列表示用我们的语言表达詹妮弗的基向量，称为基变换。反过来，就是求转移矩阵的逆 &lt;span class="math">\(\mathbf T^{-1}\)&lt;/span> ，称为&lt;strong>基变换矩阵的逆&lt;/strong>，作用是可以表示从詹妮弗的基向量转换回我们的语言需要做的变换。&lt;/p>
&lt;h2 id="矩阵乘以矩阵">矩阵乘以矩阵&lt;/h2>
&lt;p>我们已经知道矩阵是线性变换的一种描述。那么&lt;strong>多次线性变换&lt;/strong>就可以用&lt;strong>多个矩阵&lt;/strong>来描述。举个例子：如果对一个向量先进行一次&lt;em>旋转变换&lt;/em>，再进行一次&lt;em>剪切变换&lt;/em>（ &lt;span class="math">\(\vec{i}\)&lt;/span> 保持不变第一列为&lt;span class="math">\([1,0]^T\)&lt;/span>， &lt;span class="math">\(\vec{j}\)&lt;/span> 移动到坐标&lt;span class="math">\([1,1]^T\)&lt;/span>） ，如下图左半边所示：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/复合变换与矩阵乘法.png" alt="复合变换与矩阵乘法" />&lt;p class="caption">复合变换与矩阵乘法&lt;/p>
&lt;/div>
&lt;p>那么通过旋转矩阵和剪切矩阵两次线性变换的过程是否可以用一个复合线性变换（复合矩阵）来表示呢（上图右边部分）？为了解决这个问题，我们定义这个复合的过程叫做矩阵的乘法（矩阵乘矩阵）。&lt;/p>
&lt;p>在这里我们需要指出，矩阵乘法的变换顺序是&lt;strong>从右往左&lt;/strong>读的（这一个常识很重要），进一步联系和思考发现，和复合函数的形式，如 &lt;span class="math">\(f(g(x))\)&lt;/span> ，是一致的。&lt;/p>
&lt;h3 id="从左边乘一个矩阵">从左边乘一个矩阵&lt;/h3>
&lt;p>之前我们说过，矩阵乘法的变换顺序是&lt;strong>从右往左&lt;/strong>读。从左边乘一个矩阵等效于施加一个线性变换。每从左边乘一个矩阵就是施加一次线性变换。假设有两个矩阵： &lt;span class="math">\[M_1=\begin{bmatrix}a&amp;amp;b\\c&amp;amp;d\end{bmatrix},M_2=\begin{bmatrix}e&amp;amp;f\\g&amp;amp;h\end{bmatrix}\]&lt;/span> 我们先施加线性变换&lt;span class="math">\(M_1\)&lt;/span>，再施加线性变换&lt;span class="math">\(M_2\)&lt;/span>，表达式为&lt;span class="math">\(M_2*M_1(从右向左原则)\)&lt;/span>。通过“线性变换与矩阵”那一节的描述，我们知道&lt;span class="math">\(M_1\)&lt;/span>每一列表示一个线性变换后的新基向量，我们按照列向量的形式重写矩阵&lt;span class="math">\(M_1=[w_1,w_2]\)&lt;/span>，其中&lt;span class="math">\(w_1=[a,c]^T,w_2=[b,d]^T\)&lt;/span>。那么&lt;span class="math">\(M_2*[w_1,w_2]\)&lt;/span>可以看成&lt;span class="math">\(M_2\)&lt;/span>分别和两个向量的线性变换，按照向量分解为基再线性变换的理解方式，分别对&lt;span class="math">\(w_1,w_2\)&lt;/span>进行操作，就能够类推出矩阵乘以矩阵运算规则：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/矩阵乘法.gif" alt="矩阵乘法.gif" />&lt;p class="caption">矩阵乘法.gif&lt;/p>
&lt;/div>
&lt;p>总结，矩阵从左边乘，是线性变换的复合，而我们观察两次线性变换的角度都没有变，都是最开始的标准正交基，每次变换都是在标准正交基的度量下。&lt;/p>
&lt;h3 id="从右边乘一个矩阵">从右边乘一个矩阵&lt;/h3>
&lt;p>先补充一点，矩阵从右边乘以&lt;strong>行向量&lt;/strong>等效于矩阵的&lt;strong>行&lt;/strong>进行线性组合。那么矩阵也可以从右边乘一个矩阵。整体的效果上来看，大多数情况下&lt;span class="math">\(M_1*M\neq M*M_1\)&lt;/span>，如果矩阵从左边乘理解成施加一个线性变换，那么矩阵右乘是什么意思？是观察点的变化，或者说坐标系的变化。如果说左乘矩阵是发现物体&lt;span class="math">\(P\)&lt;/span>有了向东的加速度&lt;span class="math">\(\vec a_1\)&lt;/span>，又有了向北的加速度&lt;span class="math">\(\vec a_2\)&lt;/span>，那么看看其整体的加速度是什么。那么右乘矩阵就是，我看物体&lt;span class="math">\(P\)&lt;/span>有加速度&lt;span class="math">\(\vec b_1\)&lt;/span>，然后别人观察我，认为我有加速度&lt;span class="math">\(\vec b_2\)&lt;/span>，那么那个人看物体&lt;span class="math">\(P\)&lt;/span>的加速度是多少，这就是观察点的变化。&lt;/p>
&lt;h2 id="bp-1ap">&lt;span class="math">\(B=P^{-1}AP\)&lt;/span>&lt;/h2>
&lt;h2 id="tips">Tips&lt;/h2>
&lt;h3 id="n维空间有多少个向量">N维空间有多少个向量&lt;/h3>
&lt;p>N维空间当然有无穷个向量。这是显然的。更精确的说，N维空间有&lt;span class="math">\(\aleph_1\)&lt;/span>个向量。那&lt;span class="math">\(\aleph_1\)&lt;/span>具体是多少呢？我们先做这样一个标记，记自然数的个数有&lt;span class="math">\(\aleph_0\)&lt;/span>个，那么&lt;span class="math">\(\aleph_1=2^{\aleph_0}\)&lt;/span>。更有意思的是1维（实数个数），2维，3维，……，N维空间的向量个数是一样多的（应该叫等势的）。具体了解可看集合论、测度论和实变函数相关内容（万恶的康托尔和勒贝格啊，:dog:）。&lt;/p>
&lt;h3 id="逆矩阵">逆矩阵&lt;/h3>
&lt;p>所谓逆，就是反过来的意思。根据基向量代表整个空间，已经变换过的 &lt;span class="math">\(\vec{i}’\)&lt;/span> 和 &lt;span class="math">\(\vec{j}’\)&lt;/span> 如何通过一个矩阵变换，变回 &lt;span class="math">\(\vec{i}\)&lt;/span>和 &lt;span class="math">\(\vec{j}\)&lt;/span> ，这个矩阵就是逆矩阵 ，写作 &lt;span class="math">\(\mathbf A^{-1}\)&lt;/span>，直观理解如下图&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/ReverseMatrix.gif" alt="逆变换与逆矩阵" />&lt;p class="caption">逆变换与逆矩阵&lt;/p>
&lt;/div>
&lt;p>逆矩阵乘原矩阵等于恒等变换，写作 &lt;span class="math">\(\mathbf A \mathbf A^{-1} = \mathbf I\)&lt;/span> 。&lt;span class="math">\(\mathbf I\)&lt;/span> 矩阵表示基向量，对角线元素为1，其余为0（矩阵说对角线，默认为左上方到右下方）&lt;/p></description></item><item><title>线性代数与矩阵之资料网址</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E8%B5%84%E6%96%99%E7%BD%91%E5%9D%80/</link><pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E8%B5%84%E6%96%99%E7%BD%91%E5%9D%80/</guid><description>
&lt;h2 id="线性代数与矩阵之资料网址">线性代数与矩阵之资料网址&lt;!-- omit in toc -->&lt;/h2>
&lt;p>线性代数的几何解释&lt;a href="https://space.bilibili.com/88461692/channel/detail?cid=9450">https://space.bilibili.com/88461692/channel/detail?cid=9450&lt;/a>&lt;/p>
&lt;h2 id="学渣的笔记流mit各种数学">学渣的笔记流—MIT各种数学&lt;/h2>
&lt;p>知乎：学渣的笔记流—MIT各种数学&lt;a href="https://www.zhihu.com/column/c_1029672383375949824">https://www.zhihu.com/column/c_1029672383375949824&lt;/a>&lt;/p></description></item><item><title>线性代数与矩阵之矩阵分解</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/</link><pubDate>Fri, 24 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/</guid><description>
&lt;h2 id="线性代数与矩阵论之矩阵分解">线性代数与矩阵论之矩阵分解&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#三角分解">三角分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#lu分解">LU分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#crout分解">Crout分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#doolittle分解">Doolittle分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#舒尔分解">舒尔分解&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#拓展实矩阵的舒尔分解">拓展：实矩阵的舒尔分解&lt;/a>&lt;/li>
&lt;/ul>&lt;/li>
&lt;li>&lt;a href="#极分解">极分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#qr分解">QR分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#满秩分解">满秩分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征值分解谱分解">特征值分解（谱分解）&lt;/a>&lt;/li>
&lt;li>&lt;a href="#奇异值分解svd">奇异值分解(SVD)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#svd几何解释">SVD几何解释&lt;/a>&lt;/li>
&lt;li>&lt;a href="#奇异值分解与特征值分解的联系">奇异值分解与特征值分解的联系&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="三角分解">三角分解&lt;/h2>
&lt;p>三角分解是矩阵分解的基本形式，最初的三角分解是LU分解，它来自矩阵的高斯消元法。其他三角分解还有：当&lt;span class="math">\(L\)&lt;/span>是单位下三角（主对角元都是1的下三角矩阵）时，称为Doolittle分解，当&lt;span class="math">\(U\)&lt;/span>是单位下三角时，称为Crout分解，以及任何矩阵都可以进行的舒尔分解。&lt;/p>
&lt;h3 id="lu分解">LU分解&lt;/h3>
&lt;p>在线性代数与数值分析中，LU分解是矩阵分解的一种，将一个矩阵分解为一个&lt;strong>下三角矩阵和一个上三角矩阵的乘积&lt;/strong>，&lt;strong>有时需要再乘上一个置换矩阵&lt;/strong>。LU分解可以被视为高斯消元法的矩阵形式。在数值计算上，LU分解经常被用来解线性方程组、且在求逆矩阵和计算行列式中都是一个关键的步骤。&lt;/p>
&lt;p>对于方阵&lt;span class="math">\(A\)&lt;/span>，&lt;span class="math">\(A\)&lt;/span>的LU分解是将它分解成一个下三角矩阵&lt;span class="math">\(L\)&lt;/span>与上三角矩阵&lt;span class="math">\(U\)&lt;/span> 的乘积，也就是 &lt;span class="math">\[A=LU\]&lt;/span> 通常，我们需要让&lt;span class="math">\(L\)&lt;/span>矩阵的对角线元素为1，如果矩阵&lt;span class="math">\(A\)&lt;/span>的对角线上出现0元素，我们应适当的改变&lt;span class="math">\(A\)&lt;/span>的行的顺序，在此尝试将&lt;span class="math">\(A\)&lt;/span>做LU分解。&lt;/p>
&lt;p>举例来说一个&lt;span class="math">\(3\times 3\)&lt;/span>的矩阵&lt;span class="math">\(A\)&lt;/span>，其 LU 分解会写成下面的形式： &lt;span class="math">\[A={\begin{bmatrix}
a_{11}&amp;amp;a_{12}&amp;amp;a_{13}\\
a_{21}&amp;amp;a_{22}&amp;amp;a_{23}\\
a_{31}&amp;amp;a_{32}&amp;amp;a_{33}\\
\end{bmatrix}}=
{\begin{bmatrix}
1&amp;amp;0&amp;amp;0\\
l_{21}&amp;amp;1&amp;amp;0\\
l_{31}&amp;amp;l_{32}&amp;amp;1\\
\end{bmatrix}}
{\begin{bmatrix}
u_{11}&amp;amp;u_{12}&amp;amp;u_{13}\\
0&amp;amp;u_{22}&amp;amp;u_{23}\\
0&amp;amp;0&amp;amp;u_{33}\\
\end{bmatrix}}\]&lt;/span> 事实上，并不是每个矩阵都有 LU 分解。例如，从上式可知&lt;span class="math">\(a_{11}=u_{11}\)&lt;/span>，若&lt;span class="math">\(a_{11}=0\)&lt;/span>，则&lt;span class="math">\(u_{11}\)&lt;/span>等于 0，故&lt;span class="math">\(L\)&lt;/span>或&lt;span class="math">\(U\)&lt;/span>是不可逆矩阵，&lt;span class="math">\(A\)&lt;/span>必然也是不可逆矩阵。&lt;/p>
&lt;p>然而，存在着可逆矩阵&lt;span class="math">\(A\)&lt;/span>不可LU分解的情况。例如，主对角线元素&lt;span class="math">\(a_{11}=0\)&lt;/span>，如果按照LU分解的一般步骤，&lt;span class="math">\(A\)&lt;/span>就是没有&lt;span class="math">\(LU\)&lt;/span>分解的例子。该问题可借由置换&lt;span class="math">\(A\)&lt;/span>的各行顺序来解决，最终会得到一个&lt;span class="math">\(A\)&lt;/span>的&lt;span class="math">\(PLU\)&lt;/span>分解，其中&lt;span class="math">\(P\)&lt;/span>是置换矩阵。&lt;/p>
&lt;p>LU分解的具体步骤和&lt;strong>高斯消元法是相同&lt;/strong>的。我们以一个例子来进行说明：&lt;/p>
&lt;blockquote>
&lt;p>将一个简单的3×3矩阵A进行LU分解： &lt;span class="math">\[A={\begin{bmatrix}1&amp;amp;2&amp;amp;3\\2&amp;amp;5&amp;amp;7\\3&amp;amp;5&amp;amp;3\\\end{bmatrix}}\]&lt;/span> 先将矩阵第一列元素中&lt;span class="math">\(a_{11}\)&lt;/span>以下的所有元素变为0，即 &lt;span class="math">\[L_{{1}}A={\begin{bmatrix}1&amp;amp;0&amp;amp;0\\-2&amp;amp;1&amp;amp;0\\-3&amp;amp;0&amp;amp;1\\\end{bmatrix}}\times {\begin{bmatrix}1&amp;amp;2&amp;amp;3\\2&amp;amp;5&amp;amp;7\\3&amp;amp;5&amp;amp;3\\\end{bmatrix}}={\begin{bmatrix}1&amp;amp;2&amp;amp;3\\0&amp;amp;1&amp;amp;1\\0&amp;amp;-1&amp;amp;-6\\\end{bmatrix}}\]&lt;/span> 再将矩阵第二列元素中a22以下的所有元素变为0，即 &lt;span class="math">\[L_{{2}}(L_{{1}}A)={\begin{bmatrix}1&amp;amp;0&amp;amp;0\\0&amp;amp;1&amp;amp;0\\0&amp;amp;1&amp;amp;1\\\end{bmatrix}}\times {\begin{bmatrix}1&amp;amp;2&amp;amp;3\\0&amp;amp;1&amp;amp;1\\0&amp;amp;-1&amp;amp;-6\\\end{bmatrix}}={\begin{bmatrix}1&amp;amp;2&amp;amp;3\\0&amp;amp;1&amp;amp;1\\0&amp;amp;0&amp;amp;-5\\\end{bmatrix}}=U\]&lt;/span> 显然，&lt;span class="math">\(L=(L_1^{-1}L_2^{-1})\)&lt;/span>，根据&lt;a href="线性代数与矩阵之逆矩阵.md">矩阵求逆笔记&lt;/a>可知，消元矩阵的逆矩阵是主对角线元素不变，其他元素取反，则有： &lt;span class="math">\[L_{1}^{-1}L_{2}^{-1}={\begin{bmatrix}1&amp;amp;0&amp;amp;0\\2&amp;amp;1&amp;amp;0\\3&amp;amp;0&amp;amp;1\\\end{bmatrix}} {\begin{bmatrix}1&amp;amp;0&amp;amp;0\\0&amp;amp;1&amp;amp;0\\0&amp;amp;-1&amp;amp;1\\\end{bmatrix}}\Rightarrow\\
L={\begin{bmatrix}1&amp;amp;0&amp;amp;0\\2&amp;amp;1&amp;amp;0\\3&amp;amp;-1&amp;amp;1\\\end{bmatrix}}\]&lt;/span> 因此有 &lt;span class="math">\[A=LU={\begin{bmatrix}1&amp;amp;0&amp;amp;0\\2&amp;amp;1&amp;amp;0\\3&amp;amp;-1&amp;amp;1\\\end{bmatrix}}{\begin{bmatrix}1&amp;amp;2&amp;amp;3\\0&amp;amp;1&amp;amp;1\\0&amp;amp;0&amp;amp;-5\\\end{bmatrix}}\]&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>如果存在主对角线元素为0时，则使用一个置换矩阵，把下面的一个非0元素换上来，如果该列元素都为0，则说明此矩阵不可逆。（但是也能进行LU分解，不管这一行，继续从下行开始消元分解。）&lt;/p>
&lt;h3 id="crout分解">Crout分解&lt;/h3>
&lt;p>TODO&lt;/p>
&lt;h3 id="doolittle分解">Doolittle分解&lt;/h3>
&lt;p>TODO&lt;/p>
&lt;h3 id="舒尔分解">舒尔分解&lt;/h3>
&lt;p>舒尔分解(Schur分解)是最基本的矩阵分解之一，在矩阵分析中作为重要的理论工具，能够将&lt;strong>任何一般方阵&lt;/strong>转化成上三角矩阵来研究。舒尔分解可以用来求解非对称矩阵的特征值，求不可对角化方阵的幂等。此外，舒尔分解也是推导特征值分解和SVD分解的一个有效途径。&lt;/p>
&lt;blockquote>
&lt;p>舒尔分解定理：如果&lt;span class="math">\(A∈\mathbb{C}^n\)&lt;/span>是&lt;span class="math">\(n\)&lt;/span>阶的&lt;strong>复方阵&lt;/strong>，则存在&lt;span class="math">\(n\)&lt;/span>阶酉矩阵&lt;span class="math">\(U\)&lt;/span>，&lt;span class="math">\(n\)&lt;/span>阶上三角矩阵&lt;span class="math">\(T\)&lt;/span>，使得 &lt;span class="math">\[A=UTU^{-1}=UTU^{H}\]&lt;/span> 即任何一个&lt;span class="math">\(n\)&lt;/span>阶复方阵&lt;span class="math">\(A\)&lt;/span>酉相似于一个&lt;span class="math">\(n\)&lt;/span>阶上三角矩阵&lt;span class="math">\(T\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>由于&lt;span class="math">\(U\)&lt;/span>为酉矩阵，所以有&lt;span class="math">\(U^{-1}=U^H\)&lt;/span>。因为&lt;span class="math">\(A，T\)&lt;/span>相似，所以两者有相同的特征值，且相同特征值的代数重数也相同。又因&lt;span class="math">\(T\)&lt;/span>是上三角矩阵，所以&lt;span class="math">\(T\)&lt;/span>的对角元素实际上是&lt;span class="math">\(A\)&lt;/span>的所有特征值。&lt;/p>
&lt;p>可通过数学归纳法证明。&lt;/p>
&lt;blockquote>
&lt;p>证明：显然，对于任意一阶矩阵，这个舒尔分解是平凡的，任意&lt;span class="math">\(A_{1×1}=[1]A[1]^H\)&lt;/span>，而&lt;span class="math">\([1]_{1×1}\)&lt;/span>显然是个最简单的酉矩阵，&lt;span class="math">\(A\)&lt;/span>只有一个元素，符合三角矩阵的定义。&lt;/p>
&lt;p>现在我们假设对于任意&lt;span class="math">\(n-1\)&lt;/span>维矩阵，舒尔分解定理是成立的。现在我们需要证明对于&lt;span class="math">\(n\)&lt;/span>阶矩阵，舒尔分解定理也是成立的。最重要的是构建连接&lt;span class="math">\(n\)&lt;/span>维矩阵和&lt;span class="math">\(n-1\)&lt;/span>维矩阵的桥梁。构造方法如下：&lt;/p>
&lt;p>我们首先找到矩阵&lt;span class="math">\(A\)&lt;/span>任一非0特征值&lt;span class="math">\(\lambda_1\)&lt;/span>（如果特征值都是0，那么此矩阵只能是零矩阵，显然也满足舒尔分解）以及对应的标准化的（模为1）特征向量&lt;span class="math">\(x_1\)&lt;/span>，接下来我们在与&lt;span class="math">\(x_1\)&lt;/span>所在一维子空间互补的&lt;span class="math">\(n-1\)&lt;/span>维子空间中，选出另外&lt;span class="math">\(n-1\)&lt;/span>个相互正交的单位向量&lt;span class="math">\(x_2,x_3,\dotsb,x_n\)&lt;/span>，关于互补空间的概念请看笔记&lt;a href="线性代数与矩阵之四类空间.md">线性代数与矩阵之四类空间&lt;/a>。&lt;/p>
&lt;p>由于&lt;span class="math">\(n-1\)&lt;/span>维子空间必然存在&lt;span class="math">\(n-1\)&lt;/span>个线性不相关的向量，因此我们可以选择任意&lt;span class="math">\(n-1\)&lt;/span>个线性不相关向量进行施密特正交化，就可以得到&lt;span class="math">\(n-1\)&lt;/span>个相互正交的单位向量。因为互补空间的向量是相互正交的，因此&lt;span class="math">\(x_1\)&lt;/span>也垂直与&lt;span class="math">\(x_2,\dotsb,x_n\)&lt;/span>。我们将&lt;span class="math">\(x_1,x_2,\dotsb,x_n\)&lt;/span>组合到一起，就得到一个&lt;strong>酉矩阵&lt;/strong>&lt;span class="math">\(X\)&lt;/span>，其中第1个向量是&lt;span class="math">\(A\)&lt;/span>的标准化的特征向量，后面&lt;span class="math">\(n-2\)&lt;/span>个是一般的向量。那么 &lt;span class="math">\[AX=A\begin{bmatrix}x_1&amp;amp;x_2&amp;amp;\dotsb&amp;amp;x_n\end{bmatrix}=\begin{bmatrix}\lambda_1x_1&amp;amp;Ax_2&amp;amp;\dotsb&amp;amp;Ax_n\end{bmatrix}\\
X^HAX=\begin{bmatrix}x_1^H\\x_2^H\\\vdots\\x_n^H\end{bmatrix}
\begin{bmatrix}\lambda_1x_1&amp;amp;Ax_2&amp;amp;\dotsb&amp;amp;Ax_n\end{bmatrix}=\begin{bmatrix}
\lambda_1x_1^Hx_1&amp;amp;x_1^HAx_2&amp;amp;\dotsb&amp;amp;x_1^HAx_n\\
\lambda_1x_2^Hx_1&amp;amp;x_2^HAx_2&amp;amp;\dotsb&amp;amp;x_2^HAx_n\\
\vdots&amp;amp;\vdots&amp;amp;\ddots&amp;amp;\vdots\\
\lambda_1x_n^Hx_1&amp;amp;x_1^HAx_n&amp;amp;\dotsb&amp;amp;x_n^HAx_n
\end{bmatrix}\\
(x_i \perp x_j,i\neq j)=\left[\begin{array}{c:c}
\lambda_1 &amp;amp; &amp;amp;A_{12}&amp;amp; \\
\hdashline0&amp;amp; &amp;amp; &amp;amp;\\
\vdots&amp;amp; &amp;amp;A_{22} &amp;amp;\\
0&amp;amp; &amp;amp; &amp;amp;\\
\end{array}\right]=\hat{T}\]&lt;/span> 其中，&lt;span class="math">\(A_{12}=\begin{bmatrix}x_1^HAx_2&amp;amp;\dotsb&amp;amp;x_1^HAx_n\end{bmatrix}\)&lt;/span>是一个&lt;span class="math">\(1×n\)&lt;/span>维矩阵。&lt;span class="math">\(A_{22}\)&lt;/span>是由剩下的元素组成的&lt;span class="math">\((n-1)×(n-1)\)&lt;/span>维矩阵。&lt;/p>
&lt;p>现在我们已经有了一个雏形，&lt;span class="math">\(X^HAX=\hat{T}\Rightarrow A=XAX^H\)&lt;/span>，如果从分块矩阵的角度来看，这已经是一个分块上三角矩阵了，而且我们知道里面&lt;span class="math">\((n-1)×(n-1)\)&lt;/span>维矩阵&lt;span class="math">\(A_{22}\)&lt;/span>是能够进行了舒尔分解成&lt;span class="math">\(A_{22}=P_1^H\tilde{T}P_1\)&lt;/span>，现在我们要做的就是将&lt;span class="math">\(\hat{T}\)&lt;/span>与&lt;span class="math">\(A_{22}=P_1^H\tilde{T}P_1\)&lt;/span>联系起来。其实，&lt;span class="math">\(\hat{T}\)&lt;/span>就是多了一维，因此我们可以将&lt;span class="math">\(n-1\)&lt;/span>维酉矩阵&lt;span class="math">\(P_1\)&lt;/span>进行升维，如下： &lt;span class="math">\[
P=\left[\begin{array}{c:c}
1 &amp;amp; 0 &amp;amp; \dotsb &amp;amp; 0\\
\hdashline0&amp;amp;\\
\vdots&amp;amp; &amp;amp;P_1\\
0&amp;amp;\\
\end{array}\right]
\]&lt;/span> 显然，&lt;span class="math">\(P^HP=I\)&lt;/span>是一个&lt;span class="math">\(n\)&lt;/span>维酉矩阵。而&lt;span class="math">\(P^H\hat{T}P\)&lt;/span>的结果为： &lt;span class="math">\[
P^H\hat{T}P=\left[\begin{array}{c:c}
1 &amp;amp; 0 &amp;amp; \dotsb &amp;amp; 0\\
\hdashline0&amp;amp;\\
\vdots&amp;amp; &amp;amp;P^H_1\\
0&amp;amp;\\
\end{array}\right]
\left[\begin{array}{c:c}
\lambda_1 &amp;amp; &amp;amp;A_{12}&amp;amp; \\
\hdashline0&amp;amp; &amp;amp; &amp;amp;\\
\vdots&amp;amp; &amp;amp;A_{22} &amp;amp;\\
0&amp;amp; &amp;amp; &amp;amp;\\
\end{array}\right]
\left[\begin{array}{c:c}
1 &amp;amp; 0 &amp;amp; \dotsb &amp;amp; 0\\
\hdashline0&amp;amp;\\
\vdots&amp;amp; &amp;amp;P_1\\
0&amp;amp;\\
\end{array}\right]\\
=\left[\begin{array}{c:c}
\lambda_1 &amp;amp; &amp;amp;A_{12}P_1&amp;amp; \\
\hdashline0&amp;amp; &amp;amp; &amp;amp;\\
\vdots&amp;amp; &amp;amp;P_1^HA_{22}P_1 &amp;amp;\\
0&amp;amp; &amp;amp; &amp;amp;\\
\end{array}\right]
=\left[\begin{array}{c:c}
\lambda_1 &amp;amp; &amp;amp;A_{12}P_1&amp;amp; \\
\hdashline0&amp;amp; &amp;amp; &amp;amp;\\
\vdots&amp;amp; &amp;amp;\tilde{T} &amp;amp;\\
0&amp;amp; &amp;amp; &amp;amp;\\
\end{array}\right]=T
\]&lt;/span> 其中，&lt;span class="math">\(\tilde{T}\)&lt;/span>为上三角矩阵，因此&lt;span class="math">\(P^H\hat{T}P\)&lt;/span>的结果为一个上三角矩阵&lt;span class="math">\(T\)&lt;/span>。我们再将&lt;span class="math">\(\hat{T}=X^HAX\)&lt;/span>代入&lt;span class="math">\(T=P^H\hat{T}P\)&lt;/span>可得： &lt;span class="math">\[T=X^HP^HAXP=(XP)^HAXP\]&lt;/span> 因为，&lt;span class="math">\(X,P\)&lt;/span>都是&lt;span class="math">\(n\)&lt;/span>维酉矩阵，而酉矩阵的乘积依然是酉矩阵，因此&lt;span class="math">\(XP\)&lt;/span>也是酉矩阵，我们有： &lt;span class="math">\[A=((XP)^H)^{-1}T(XP)^{-1}=(XP)T(XP)^H\\
\overset{令U=XP}{=}UTU^H\]&lt;/span> 其中，&lt;span class="math">\(U\)&lt;/span>是一个酉矩阵，&lt;span class="math">\(T\)&lt;/span>是一个上三角矩阵。至此，我们证明了对于任意&lt;span class="math">\(n\)&lt;/span>阶矩阵，舒尔分解定理也是成立的。得证。&lt;/p>
&lt;/blockquote>
&lt;p>舒尔分解的证明过程证明了舒尔分解的存在性的同时，也提供了一种舒尔分解构造的方法，即从一阶矩阵开始，逐步使用&lt;span class="math">\(1\sim n-1\)&lt;/span>维酉矩阵经过升维相乘，最终得到&lt;span class="math">\(n\)&lt;/span>维酉矩阵&lt;span class="math">\(U\)&lt;/span>。然后，左乘、右乘原矩阵，得到上三角矩阵&lt;span class="math">\(T\)&lt;/span>（虽然这种方法相当麻烦）。此外，由于步骤中正交基的选择并不唯一，由此舒尔分解也是不唯一的。&lt;/p>
&lt;h4 id="拓展实矩阵的舒尔分解">拓展：实矩阵的舒尔分解&lt;/h4>
&lt;p>舒尔分解是针对复矩阵而言的，如果将数域缩小到实数域，舒尔分解就不完全适用了。问题就在于一个矩阵可能存在非实数特征值，即我们在递推过程中存在某个子矩阵找不到实数域内的特征值，导致后面就无法继续。&lt;/p>
&lt;blockquote>
&lt;p>实数域的舒尔分解：&lt;del>设&lt;span class="math">\(A\in R^{n\times n}\)&lt;/span>，则存在实正交矩阵&lt;span class="math">\(U\)&lt;/span>和实上三角矩阵&lt;span class="math">\(T\)&lt;/span>使得&lt;span class="math">\(A=UTU^H\)&lt;/span>。&lt;/del>&lt;/p>
&lt;/blockquote>
&lt;p>上面的这结论是错的。然而在实数域，我们可以对上述舒尔分解定理做适当修正，使得在实数域也可以进行舒尔分解。&lt;/p>
&lt;blockquote>
&lt;p>实数域的舒尔分解定理：如果&lt;span class="math">\(A∈\mathbb{R}^n\)&lt;/span>是&lt;span class="math">\(n\)&lt;/span>阶的&lt;strong>实方阵&lt;/strong>，则存在&lt;span class="math">\(n\)&lt;/span>阶正交矩阵&lt;span class="math">\(Q\)&lt;/span>，&lt;span class="math">\(n\)&lt;/span>阶&lt;strong>拟上三角&lt;/strong>矩阵&lt;span class="math">\(T\)&lt;/span>，使得 &lt;span class="math">\[A=QTQ^{-1}=QTQ^T\]&lt;/span> 即任何一个&lt;span class="math">\(n\)&lt;/span>阶实方阵&lt;span class="math">\(A\)&lt;/span>正交相似于一个&lt;span class="math">\(n\)&lt;/span>阶&lt;strong>拟上三角&lt;/strong>矩阵&lt;span class="math">\(T\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>然而，虽然不能将任意实矩阵正交相似上三角化，但我们可以放宽要求，将任意实矩阵正交相似拟上三角化。区别就在于&lt;strong>拟三角&lt;/strong>！ &lt;span class="math">\[
T=\begin{bmatrix}
R_{11}&amp;amp;R_{12}&amp;amp;\dotsb&amp;amp;R_{1m}\\
&amp;amp;R_{22}&amp;amp;\dotsb&amp;amp;R_{2m}\\
&amp;amp; &amp;amp; \ddots &amp;amp; \vdots\\
&amp;amp; &amp;amp; &amp;amp; R_{mm}
\end{bmatrix}
\]&lt;/span> 其中对角子块&lt;span class="math">\(R_{ii}\)&lt;/span>是&lt;span class="math">\(1 × 1\)&lt;/span>矩阵或有一对共轭的虚特征值的&lt;span class="math">\(2\times 2\)&lt;/span>矩阵，也因为对角子块的存在，最终的行列也不是&lt;span class="math">\(n\)&lt;/span>，而是&lt;span class="math">\(m\leq n\)&lt;/span>。证明方法也是数学归纳法，这里我们就省略不证了。&lt;/p>
&lt;h2 id="极分解">极分解&lt;/h2>
&lt;p>一个复系数矩阵&lt;span class="math">\(A\)&lt;/span>的极分解将其分解成两个矩阵的乘积，可以表示为： &lt;span class="math">\[A=UP\]&lt;/span> 其中&lt;span class="math">\(U\)&lt;/span>是一个&lt;strong>酉矩阵&lt;/strong>，&lt;span class="math">\(P\)&lt;/span>是一个&lt;strong>半正定的埃尔米特矩阵&lt;/strong>。这样的分解对&lt;strong>任意&lt;/strong>的矩阵&lt;span class="math">\(A\)&lt;/span>都存在。当&lt;span class="math">\(A\)&lt;/span>是可逆矩阵时，分解是唯一的，并且&lt;span class="math">\(P\)&lt;/span>必然为正定矩阵。&lt;/p>
&lt;h2 id="qr分解">QR分解&lt;/h2>
&lt;p>见&lt;a href="线性代数与矩阵之正交（酉）矩阵与正交化.md">《线性代数与矩阵之正交（酉）矩阵与正交化》&lt;/a>&lt;/p>
&lt;h2 id="满秩分解">满秩分解&lt;/h2>
&lt;blockquote>
&lt;p>定义：满秩分解：对于&lt;span class="math">\(m×n\)&lt;/span>的矩阵&lt;span class="math">\(A\)&lt;/span>，假设其秩为&lt;span class="math">\(r\)&lt;/span>，若存在秩同样为&lt;span class="math">\(r\)&lt;/span>两个矩阵：&lt;span class="math">\(F_{m×r}\)&lt;/span>（列满秩）和&lt;span class="math">\(G_{r×n}\)&lt;/span>（行满秩），使得&lt;span class="math">\(A=FG\)&lt;/span>，则称其为矩阵&lt;span class="math">\(A\)&lt;/span>的满秩分解。&lt;/p>
&lt;/blockquote>
&lt;p>根据可逆矩阵和高斯消元法，容易得到以下定理。&lt;/p>
&lt;blockquote>
&lt;p>定理：满秩分解有两个性质：不唯一性和存在性&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>满秩分解不唯一：假设存在&lt;span class="math">\(r\)&lt;/span>阶可逆方阵&lt;span class="math">\(D\)&lt;/span>，则&lt;span class="math">\(A=FG=F(DD^{−1})G=(FD)(D^{−1}G)=F&amp;#39;G&amp;#39;\)&lt;/span>；&lt;/li>
&lt;li>任何非零矩阵一定存在满秩分解。&lt;/li>
&lt;/ol>
&lt;p>证明：假设存在初等变换矩阵&lt;span class="math">\(B_{m×m}\)&lt;/span>，使得 &lt;span class="math">\[BA=\begin{bmatrix}G\\O\end{bmatrix}\]&lt;/span> 显然，&lt;span class="math">\(B\)&lt;/span>可以看成是带置换的高斯消元法。其中&lt;span class="math">\(G\)&lt;/span>是个&lt;span class="math">\(m×r\)&lt;/span>的行满秩矩阵。由上面的公式，可以推出， &lt;span class="math">\[\begin{aligned}
A &amp;amp;= B^{-1}\left(
\begin{array}{c}
G\\
O
\end{array}
\right)\\
&amp;amp;= (F|S) \left(
\begin{array}{c}
G\\
O
\end{array}
\right)\\
&amp;amp;= FG
\end{aligned}\]&lt;/span> 公式第二行中，我们将&lt;span class="math">\(B^{−1}\)&lt;/span>分块为&lt;span class="math">\((F|S)\)&lt;/span>，其中&lt;span class="math">\(F\)&lt;/span>为&lt;span class="math">\(m×r\)&lt;/span>矩阵（秩为&lt;span class="math">\(r\)&lt;/span>），&lt;span class="math">\(G\)&lt;/span>为&lt;span class="math">\(r×n\)&lt;/span>矩阵（秩为&lt;span class="math">\(r\)&lt;/span>）。&lt;/p>
&lt;/blockquote>
&lt;p>从满秩分解的存在性证明，也可以看出满秩分解的求法：先导出高斯消元的初等矩阵和主元矩阵，然后求高斯消元的初等矩阵的逆矩阵，在分割成两部分。此外，还可以用&lt;strong>Hermite标准型&lt;/strong>来求满秩分解。&lt;/p>
&lt;blockquote>
&lt;p>定义：Hermite标准型：对于&lt;span class="math">\(m×n\)&lt;/span>的矩阵&lt;span class="math">\(H\)&lt;/span>，假设其秩为&lt;span class="math">\(r\)&lt;/span>，若&lt;span class="math">\(H\)&lt;/span>满足 &lt;span class="math">\(H\)&lt;/span>的&lt;span class="math">\(j_1,j_2,…,j_r\)&lt;/span>列是单位矩阵&lt;span class="math">\(E_m\)&lt;/span>的前&lt;span class="math">\(r\)&lt;/span>行，则称&lt;span class="math">\(H\)&lt;/span>为Hermite标准型。简单来说，&lt;span class="math">\(H\)&lt;/span>具有以下形式： &lt;span class="math">\[H=\begin{bmatrix}I_{r×r}&amp;amp;X_{r×(n-r)}\\O_{(m-r)×r}&amp;amp;O_{(m-r)×(n-r)}\end{bmatrix}\]&lt;/span>&lt;/p>
&lt;/blockquote>
&lt;p>Hermite标准型就是将秩为&lt;span class="math">\(r\)&lt;/span>的&lt;span class="math">\(m×n\)&lt;/span>矩阵&lt;span class="math">\(A\)&lt;/span>经初等变换（高斯消元）而成的&lt;strong>阶梯型矩阵&lt;/strong>。所以也叫做Hermite最简型。&lt;/p>
&lt;p>算出Hermite标准型后，对于矩阵的满秩分解&lt;span class="math">\(A=FG\)&lt;/span>来说，矩阵&lt;span class="math">\(F\)&lt;/span>就是矩阵&lt;span class="math">\(A\)&lt;/span>中&lt;span class="math">\(j_1,j_2,…,j_r\)&lt;/span>列构成的&lt;span class="math">\(m×r\)&lt;/span>矩阵，而&lt;span class="math">\(G\)&lt;/span>则是Hermite标准型的前&lt;span class="math">\(r\)&lt;/span>行构成的矩阵。&lt;/p>
&lt;h2 id="特征值分解谱分解">特征值分解（谱分解）&lt;/h2>
&lt;p>见&lt;a href="线性代数与矩阵之特征值与特征向量.md">线性代数与矩阵之特征值与特征向量&lt;/a>&lt;/p>
&lt;h2 id="奇异值分解svd">奇异值分解(SVD)&lt;/h2>
&lt;p>特征值分解可以将矩阵分解成对角矩阵的形式，大大方便了矩阵的研究与计算，然后我们也知道只有正规矩阵才可以进行特征分解，那么是否能有一种能够分解成类似模式的分解，但是并没有矩阵类似的要求呢？&lt;/p>
&lt;p>这就是这一小节要引入的奇异值分解（Singular value decomposition），简称SVD。&lt;strong>SVD的一大好处就是任何矩阵都可以进行奇异值分解&lt;/strong>。&lt;/p>
&lt;blockquote>
&lt;p>假设&lt;span class="math">\(A\)&lt;/span>是一个&lt;span class="math">\(m×n\)&lt;/span>阶矩阵，其中的元素全部属于域&lt;span class="math">\(K\)&lt;/span>，也就是实数域或复数域。如此则存在一个分解使得 &lt;span class="math">\[A= U \Sigma V^*\]&lt;/span> 其中&lt;span class="math">\(U\)&lt;/span>是&lt;span class="math">\(m×m\)&lt;/span>阶酉矩阵；&lt;span class="math">\(Σ\)&lt;/span>是&lt;span class="math">\(m×n\)&lt;/span>阶非负实数对角矩阵；而&lt;span class="math">\(V*\)&lt;/span>，即&lt;span class="math">\(V\)&lt;/span>的共轭转置，是&lt;span class="math">\(n×n\)&lt;/span>阶酉矩阵。这样的分解就称作&lt;span class="math">\(A\)&lt;/span>的&lt;strong>奇异值分解&lt;/strong>。&lt;span class="math">\(Σ\)&lt;/span>对角线上的元素&lt;span class="math">\(Σ_{ii}\)&lt;/span>即为&lt;span class="math">\(A\)&lt;/span>的奇异值。&lt;/p>
&lt;/blockquote>
&lt;div class="figure">
&lt;img src="../../images/Singular_value_decomposition_visualisation.svg" alt="奇异值分解" />&lt;p class="caption">奇异值分解&lt;/p>
&lt;/div>
&lt;p>常见的做法是将奇异值由大而小排列。如此&lt;span class="math">\(Σ\)&lt;/span>便能由&lt;span class="math">\(A\)&lt;/span>唯一确定了。（虽然&lt;span class="math">\(U\)&lt;/span>和&lt;span class="math">\(V\)&lt;/span>仍然不能确定。）&lt;/p>
&lt;p>SVD的存在性证明可以用谱定理或者变分法证明，这里不详述，维基百科的英文版上有。&lt;/p>
&lt;p>那么我们如果找到这个奇异值分解呢？&lt;/p>
&lt;p>这个分解中有相互正交的向量和很像特征值的奇异值，觉得和特征分解类似，那我们可不可以往特征分解上靠一靠呢。如果能有对称矩阵，就可以套用特征分解的方法获得特征值和正交（酉）矩阵了。&lt;/p>
&lt;p>显然，&lt;span class="math">\(A^TA,AA^T\)&lt;/span>都是由&lt;span class="math">\(A\)&lt;/span>构成的对称矩阵，而且在&lt;span class="math">\(A=U\Sigma V^T\)&lt;/span>的前提下有： &lt;span class="math">\[
A^TA=(U\Sigma V^T)^TU\Sigma V^T=V^T\Sigma^2V\\
AA^T=U\Sigma V^T(U\Sigma V^T)^T=U^T\Sigma^2U
\]&lt;/span> 这正好是两个对称矩阵&lt;span class="math">\(A^TA,AA^T\)&lt;/span>的对角化分解！那么我们只需要求出&lt;span class="math">\(A^TA,AA^T\)&lt;/span>的特征分解，就可以求出&lt;span class="math">\(U,V,\Sigma\)&lt;/span>的矩阵！！！&lt;/p>
&lt;p>需要注意的是，我们&lt;span class="math">\(A^TA,AA^T\)&lt;/span>求出来的是奇异值的平方，实际使用记得要开根号。下面我们举两个例子：&lt;/p>
&lt;p>例1：对矩阵&lt;span class="math">\(A=\begin{bmatrix}0&amp;amp;1\\1&amp;amp;1\\1&amp;amp;0\end{bmatrix}\)&lt;/span>进行奇异值分解。&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/svd分解例1.png" alt="svd分解例1" />&lt;p class="caption">svd分解例1&lt;/p>
&lt;/div>
&lt;p>接下来这个例子，给我们说明，完全依赖上面的方法有可能是错的！&lt;/p>
&lt;p>例2：对矩阵&lt;span class="math">\(A=\begin{bmatrix}4&amp;amp;4\\-3&amp;amp;3\end{bmatrix}\)&lt;/span>进行奇异值分解。&lt;/p>
&lt;p>我们首先求出&lt;span class="math">\(A^TA,AA^T\)&lt;/span>： &lt;span class="math">\[
A^TA=\begin{bmatrix}4&amp;amp;-3\\4&amp;amp;3\end{bmatrix}\begin{bmatrix}4&amp;amp;4\\-3&amp;amp;3\end{bmatrix}=\begin{bmatrix}25&amp;amp;7\\7&amp;amp;25\end{bmatrix}\\
AA^T=\begin{bmatrix}4&amp;amp;4\\-3&amp;amp;3\end{bmatrix}\begin{bmatrix}4&amp;amp;-3\\4&amp;amp;3\end{bmatrix}=\begin{bmatrix}32&amp;amp;0\\0&amp;amp;18\end{bmatrix}
\]&lt;/span> 出现了一个对角矩阵，显然奇异值为：&lt;span class="math">\(\lambda_1=\sqrt{32},\lambda_2=\sqrt{18}\)&lt;/span>，剩余奇异值都是0。 进而求出&lt;span class="math">\(V\)&lt;/span>中的特征向量： &lt;span class="math">\[A^TAv_1=\lambda_1 v_1=\sqrt{32}v_1\Rightarrow v_1=\begin{bmatrix}1\over\sqrt{2}\\1\over\sqrt{2}\end{bmatrix}\\
A^TAv_2=\lambda_2 v_2=\sqrt{18}v_2\Rightarrow v_2=\begin{bmatrix}1\over\sqrt{2}\\-1\over\sqrt{2}\end{bmatrix}\\
V=\begin{bmatrix}1\over\sqrt{2}&amp;amp;1\over\sqrt{2}\\1\over\sqrt{2}&amp;amp;-1\over\sqrt{2}\end{bmatrix}\]&lt;/span> 同样求出&lt;span class="math">\(U\)&lt;/span>的特征向量： &lt;span class="math">\[AA^Tu_1=\lambda_1 u_1=\sqrt{32}u_1\Rightarrow u_1=\begin{bmatrix}1\\0\end{bmatrix}\\
AA^Tu_2=\lambda_2 u_2=\sqrt{18}u_2\Rightarrow u_2=\begin{bmatrix}0\\1\end{bmatrix}\\
U=\begin{bmatrix}1&amp;amp;0\\0&amp;amp;1\end{bmatrix}\]&lt;/span> 到这里看似没有问题，但是我们计算一下： &lt;span class="math">\[
U\Sigma V^\ast=\begin{bmatrix}1&amp;amp;0\\0&amp;amp;1\end{bmatrix}\begin{bmatrix}\sqrt{32}&amp;amp;0\\0&amp;amp;\sqrt{18}\end{bmatrix}\begin{bmatrix}1\over\sqrt{2}&amp;amp;1\over\sqrt{2}\\1\over\sqrt{2}&amp;amp;-1\over\sqrt{2}\end{bmatrix}\\
=\begin{bmatrix}4&amp;amp;4\\3&amp;amp;-3\end{bmatrix}
\]&lt;/span> 这和矩阵&lt;span class="math">\(A\)&lt;/span>并不一样！！！底下两个正负号反了，难道奇异值分解有BUG吗？&lt;/p>
&lt;p>这是因为确定特征向量的过程中，特征向量反向仍然符合要求，通过&lt;span class="math">\(A^TA,AA^T\)&lt;/span>求解特征向量的方法无法确认向量的正负符号，但是一旦我们确认&lt;span class="math">\(V\)&lt;/span>中向量的方向之后，&lt;span class="math">\(U\)&lt;/span>中向量的方向也就随之确定。关键是，&lt;strong>我们在开&lt;span class="math">\(\Sigma^2\)&lt;/span>的时候只考虑使用正值，人为地忽略了&lt;span class="math">\(U,V\)&lt;/span>之间的正负号联系&lt;/strong>，为此可以使用&lt;span class="math">\(AV=U\Sigma\)&lt;/span>替代计算可以避免这种问题。 &lt;span class="math">\[
U=AV\Sigma^{-1}=2\begin{bmatrix}1&amp;amp;0\\0&amp;amp;-1\end{bmatrix}
\]&lt;/span> 归一化可得&lt;span class="math">\(U=\begin{bmatrix}1&amp;amp;0\\0&amp;amp;-1\end{bmatrix}\)&lt;/span>。由于本例中&lt;span class="math">\(\Sigma\)&lt;/span>可逆，才可以直接用&lt;span class="math">\(\Sigma^{-1}\)&lt;/span>，否则就老老实实求解。&lt;/p>
&lt;p>因此&lt;span class="math">\(A\)&lt;/span>正确的SVD为： &lt;span class="math">\[
A=U\Sigma V^\ast=\begin{bmatrix}1&amp;amp;0\\0&amp;amp;-1\end{bmatrix}\begin{bmatrix}\sqrt{32}&amp;amp;0\\0&amp;amp;\sqrt{18}\end{bmatrix}\begin{bmatrix}1\over\sqrt{2}&amp;amp;1\over\sqrt{2}\\1\over\sqrt{2}&amp;amp;-1\over\sqrt{2}\end{bmatrix}\\
\]&lt;/span>&lt;/p>
&lt;p>SVD应用的资料还可以看：&lt;a href="../../网页资料/线性代数与矩阵-这次终于彻底理解了奇异值分解(SVD)原理及应用.html">这次终于彻底理解了奇异值分解(SVD)原理及应用&lt;/a>&lt;/p>
&lt;h3 id="svd几何解释">SVD几何解释&lt;/h3>
&lt;p>在几何中，任意的线性变换都可以拆成三步：旋转-拉伸-再旋转。至于为什么能这样，我还不知道。但是，这三布正好对应了SVD的三个矩阵分量。&lt;/p>
&lt;p>我们知道，&lt;span class="math">\(U,V\)&lt;/span>是酉矩阵（单位正交矩阵），模长为1，这叫矩阵的几何意义正是向量的旋转。所以&lt;span class="math">\(U\Sigma V^\ast\)&lt;/span>就相当于先使用一个旋转矩阵&lt;span class="math">\(V^\ast\)&lt;/span>转动向量，然后再用对角矩阵&lt;span class="math">\(\Sigma\)&lt;/span>拉伸各个向量分量，最后再用矩阵&lt;span class="math">\(U\)&lt;/span>再旋转一次，得到线性变换的结果。&lt;/p>
&lt;p>下图是矩阵&lt;span class="math">\(M=U\Sigma V^\ast\)&lt;/span>各个矩阵作用与一个二维空间基的演示：&lt;/p>
&lt;div class="figure">
&lt;img src="../../images/SVD几何意义.gif" alt="SVD几何意义" />&lt;p class="caption">SVD几何意义&lt;/p>
&lt;/div>
&lt;h3 id="奇异值分解与特征值分解的联系">奇异值分解与特征值分解的联系&lt;/h3>
&lt;p>奇异值分解能够用于任意&lt;span class="math">\(m\times n\)&lt;/span>矩阵，而特征分解只能适用于特定类型的方阵，故奇异值分解的适用范围更广。不过，这两个分解之间是有关联的。给定一个&lt;span class="math">\(M\)&lt;/span>的奇异值分解，根据上面的论述，两者的关系式如下：&lt;/p>
&lt;p>&lt;span class="math">\[
M^{*} M = V \Sigma^{*} U^{*}\, U \Sigma V^{*} =
V (\Sigma^{*} \Sigma) V^{*}\,\]&lt;/span> &lt;span class="math">\[M M^{*} = U \Sigma V^{*} \, V \Sigma^{*} U^{*} =
U (\Sigma \Sigma^{*}) U^{*}\,\]&lt;/span> 关系式的右边描述了关系式左边的特征值分解。于是：&lt;/p>
&lt;p>&lt;span class="math">\(V\)&lt;/span>的列向量（右奇异向量）是&lt;span class="math">\(M^{*}M\)&lt;/span>的特征向量。&lt;/p>
&lt;p>&lt;span class="math">\(U\)&lt;/span>的列向量（左奇异向量）是&lt;span class="math">\(MM^{*}\)&lt;/span>的特征向量。&lt;/p>
&lt;p>&lt;span class="math">\(\Sigma\)&lt;/span>的非零对角元（非零奇异值）是&lt;span class="math">\(M^{*}M\)&lt;/span>或者&lt;span class="math">\(MM^{*}\)&lt;/span>的非零特征值的平方根。&lt;/p>
&lt;p>特殊情况下，当&lt;span class="math">\(M\)&lt;/span>是一个&lt;strong>正规矩阵&lt;/strong>（因而必须是方阵）根据谱定理，M可以被一组特征向量酉对角化，所以它可以表为： &lt;span class="math">\[M = U D U^\ast\]&lt;/span> 其中&lt;span class="math">\(U\)&lt;/span>为一个酉矩阵，&lt;span class="math">\(D\)&lt;/span>为一个对角阵。如果&lt;span class="math">\(M\)&lt;/span>是半正定的，&lt;span class="math">\(M = U D U^\ast\)&lt;/span>的分解也是一个奇异值分解。&lt;/p>
&lt;p>然而，一般矩阵的特征分解跟奇异值分解不同。特征分解如下： &lt;span class="math">\[M=UDU^{-1}\]&lt;/span> 其中&lt;span class="math">\(U\)&lt;/span>是不需要是酉的，&lt;span class="math">\(D\)&lt;/span>也不需要是半正定的。而奇异值分解如下： &lt;span class="math">\[M=U\Sigma V^\ast\]&lt;/span> 其中&lt;span class="math">\(\Sigma\)&lt;/span>是对角半正定矩阵，&lt;span class="math">\(U\)&lt;/span>和&lt;span class="math">\(V\)&lt;/span>是酉矩阵，两者除了通过矩阵&lt;span class="math">\(M\)&lt;/span>没有必然的联系。&lt;/p></description></item><item><title>线性代数与矩阵之行列式</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E8%A1%8C%E5%88%97%E5%BC%8F/</link><pubDate>Thu, 23 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E8%A1%8C%E5%88%97%E5%BC%8F/</guid><description>
&lt;h2 id="行列式">行列式&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#行列式的几何意义">行列式的几何意义&lt;/a>&lt;/li>
&lt;li>&lt;a href="#行列式计算">行列式计算&lt;/a>&lt;/li>
&lt;li>&lt;a href="#k阶子式">K阶子式&lt;/a>&lt;/li>
&lt;li>&lt;a href="#k阶主子式">K阶主子式&lt;/a>&lt;/li>
&lt;li>&lt;a href="#顺序主子式">顺序主子式&lt;/a>&lt;/li>
&lt;li>&lt;a href="#余子式和代数余子式">余子式和代数余子式&lt;/a>&lt;/li>
&lt;li>&lt;a href="#余因子矩阵与伴随矩阵">余因子矩阵与伴随矩阵&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="行列式的几何意义">行列式的几何意义&lt;/h2>
&lt;p>行列式看起来计算非常复杂，但是有十分明确的几何意义。行列式可以看做是有向面积或体积的概念在一般的欧几里得空间中的推广。或者说，在欧几里得空间中，行列式描述的是一个线性变换对“体积”所造成的影响。&lt;/p>
&lt;p>当作为一个N维空间的标准基&lt;span class="math">\(E=(\vec{e_1},\vec{e_2},\dotsb,\vec{e_N})\)&lt;/span>，其中&lt;span class="math">\(\vec{e_i}\)&lt;/span>是N维单位列向量，经过一个线性变换矩阵&lt;span class="math">\(M\)&lt;/span>后，其单位“体积”有原来的1变成了&lt;span class="math">\(\det(M)\)&lt;/span>。即行列式反映了矩阵对线性空间的拉伸效果。此外，行列式也等同于矩阵&lt;span class="math">\(M\)&lt;/span>的各个分向量&lt;span class="math">\(M=(\vec{m_1},\vec{m_2},\dotsb,\vec{m_N})\)&lt;/span>所围成的N维方体的“体积”，其中&lt;span class="math">\(\vec{m_i}\)&lt;/span>是N维列向量。&lt;/p>
&lt;p>在二维空间中，行列式的值是2个2维向量组成的平行四边形的面积。&lt;span class="math">\(\det (M_{2\times 2})=\vec{m_1}\times \vec{m_2}=||\vec{m_1}||_2||\vec{m_2}||_2\sin\theta\)&lt;/span>，其中&lt;span class="math">\(\times\)&lt;/span>表示叉乘或外积，&lt;span class="math">\(\theta\)&lt;/span>是向量&lt;span class="math">\(\vec{m_1}\)&lt;/span>逆时针转到&lt;span class="math">\(\vec{m_2}\)&lt;/span>的角度。显然，有&lt;span class="math">\(\vec{m_1}\times \vec{m_2}=-\vec{m_2}\times \vec{m_1}\)&lt;/span>。这其实有些不准确，因为叉乘的结果是一个垂直于此二维平面的向量，面积大小等于&lt;span class="math">\(\det (M_{2\times 2})\)&lt;/span>。疑问：这还是二维空间向量吗？&lt;/p>
&lt;p>在三维空间中，行列式的值是3个3维向量组成的平行六面体的体积。&lt;span class="math">\(\det (M_{3\times 3})=(\vec{m_1}\times \vec{m_2})\cdot \vec{m_3}\)&lt;/span>，其中&lt;span class="math">\(\times\)&lt;/span>表示叉乘或外积，&lt;span class="math">\(\cdot\)&lt;/span>表示点积或内积，在一起称为&lt;strong>混合积&lt;/strong>。从几何角度很好理解混合积，就是求体积。前面的叉乘的计算出大小是组成的平行六面体底面积大小，其向量方向就是平行六面体高的方向，后面的点积是第三个向量在高上的投影，计算结果最终就是：底面积×高=平行六面体的体积。&lt;/p>
&lt;h2 id="行列式计算">行列式计算&lt;/h2>
&lt;p>版权声明：以下文章为CSDN博主「PoemK」的原创文章，遵循 cc 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。 原文链接：&lt;a href="https://blog.csdn.net/yskyskyer123/java/article/details/87891051">https://blog.csdn.net/yskyskyer123/java/article/details/87891051&lt;/a>&lt;/p>
&lt;h3 id="k阶子式">K阶子式&lt;/h3>
&lt;p>以3阶行列式为例：&lt;/p>
&lt;p>&lt;span class="math">\[\begin{vmatrix} a_1 &amp;amp; a_2 &amp;amp; a_3 \\ b_1 &amp;amp; b_2 &amp;amp; b_3\\ c_1 &amp;amp; c_2 &amp;amp; c_3 \end{vmatrix}\]&lt;/span> 则它的3阶子式是它本身。&lt;/p>
&lt;p>它的2阶子式有 第1、2行和第1、2列相交处元素组成的行列式： &lt;span class="math">\[\begin{vmatrix} a_1 &amp;amp; a_2 \\ b_1 &amp;amp; b_2 \end{vmatrix}\]&lt;/span> 第1、2行和第1、3列相交处元素组成的行列式： &lt;span class="math">\[\begin{vmatrix} a_1 &amp;amp; a_3 \\ b_1 &amp;amp; b_3 \end{vmatrix}\]&lt;/span> 等等。行列式的每一项都是一个一阶子式。&lt;/p>
&lt;p>方法就是选取&lt;span class="math">\(k\)&lt;/span>行再选取&lt;span class="math">\(k\)&lt;/span>列 可以试着划出&lt;span class="math">\(2k\)&lt;/span>条线 然后相交处的元素组成的新的行列式就是&lt;span class="math">\(k\)&lt;/span>阶子式。&lt;/p>
&lt;h3 id="k阶主子式">K阶主子式&lt;/h3>
&lt;p>在子式的基础上，要求子式包含的&lt;strong>行序数和包含的列序数相同&lt;/strong>。详细说来：在n 阶行列式中，选取行号（例如 1、3、7行），再选取相同行号的列号（1、3、7 列），则有行和列都为i个的行列式即为n阶行列式的r阶主子式，也可以说由上述选取的行列交汇处的元素所组成的新的行列式就称为“n 阶行列式的一个r阶主子式”。&lt;/p>
&lt;p>举个例子： &lt;span class="math">\[A=\begin{vmatrix} -3&amp;amp;1&amp;amp;-3\\20&amp;amp;3&amp;amp;10\\2&amp;amp;-2&amp;amp;4\end{vmatrix}\]&lt;/span> 其一阶主子式就是&lt;span class="math">\(-3，3，4\)&lt;/span>。二阶主子式是 &lt;span class="math">\[\begin{vmatrix} -3&amp;amp;1\\20 &amp;amp;3\end{vmatrix}=-29,
\begin{vmatrix} 3&amp;amp;10\\-2&amp;amp;4\end{vmatrix}=32,
\begin{vmatrix} -3&amp;amp;-3\\2&amp;amp;4\end{vmatrix}=-6.\]&lt;/span> 三阶主子式是行列式本身&lt;span class="math">\(det(A)=-18\)&lt;/span>&lt;/p>
&lt;p>主子式是从n个元素中挑出r个，因此r阶主子式共有&lt;span class="math">\(c_n^{r}=\frac{n!}{r!(n-r)!}\)&lt;/span>个。&lt;/p>
&lt;h3 id="顺序主子式">顺序主子式&lt;/h3>
&lt;p>由第1→r行和第1→r列所确定的子式即为“n 阶行列式的r阶&lt;strong>顺序主子式&lt;/strong>”。&lt;/p>
&lt;p>例如：&lt;/p>
&lt;ul>
&lt;li>1阶时：取第1行，第1列&lt;/li>
&lt;li>2阶时：取第1、2行，第1、2列&lt;/li>
&lt;li>3阶时：取第1、2、3行，第1、2、3列&lt;/li>
&lt;li>4阶时：取第1、2、3、4行，第1、2、3、4列&lt;/li>
&lt;/ul>
&lt;p>实际上，主子式的主对角线元素是原 n 阶行列式的主对角线元素的一部分，且顺序相同。值得注意的是，根据定义，r阶主子式是&lt;strong>不唯一&lt;/strong>的，而r阶&lt;strong>顺序主子式是唯一&lt;/strong>的。&lt;/p>
&lt;h3 id="余子式和代数余子式">余子式和代数余子式&lt;/h3>
&lt;p>一个矩阵&lt;span class="math">\(A\)&lt;/span>的余子式（又称余因式，英语：minor）是指将&lt;span class="math">\(A\)&lt;/span>的某些行与列去掉之后所余下的方阵的行列式。相应的方阵有时被称为余子阵。&lt;/p>
&lt;p>在&lt;span class="math">\(n\)&lt;/span>阶行列式中，划去元&lt;span class="math">\(a_{ij}\)&lt;/span>所在的第i行与第j列的元，剩下的元不改变原来的顺序所构成的n-1阶行列式称为&lt;strong>元&lt;span class="math">\(a_{ij}\)&lt;/span>的余子式&lt;/strong>。数学表示上计作&lt;span class="math">\(M_{ij}\)&lt;/span>。&lt;/p>
&lt;p>&lt;span class="math">\(a_{ij}\)&lt;/span>的&lt;strong>代数余子式&lt;/strong>：&lt;span class="math">\(c_{ij}= (-1)^{i+j} M_{ij}\)&lt;/span>&lt;/p>
&lt;p>对矩阵 &lt;span class="math">\[\begin{pmatrix}\,\,\,1&amp;amp;4&amp;amp;7\\\,\,\,3&amp;amp;0&amp;amp;5\\-1&amp;amp;9&amp;amp;\!11\\\end{pmatrix}\]&lt;/span> 要计算代数余子式&lt;span class="math">\(c_{23}\)&lt;/span>。首先计算余子式&lt;span class="math">\(M_{23}\)&lt;/span>，也就是原矩阵去掉第2行和第3列后的子矩阵的行列式： &lt;span class="math">\[\begin{vmatrix}\,\,1&amp;amp;4&amp;amp;\Box \,\\\,\Box &amp;amp;\Box &amp;amp;\Box \,\\-1&amp;amp;9&amp;amp;\Box \,\\\end{vmatrix},即\begin{vmatrix}\,\,\,1&amp;amp;4\,\\-1&amp;amp;9\,\\\end{vmatrix}=9-(-4)=13\]&lt;/span> 因此，&lt;span class="math">\(c_{23}\)&lt;/span>等于&lt;span class="math">\((-1)^{2+3}M_{23}=-13\)&lt;/span>&lt;/p>
&lt;p>其某一行列式&lt;span class="math">\(\det A\)&lt;/span>可以用余因子表示： &lt;span class="math">\[\det(A)=a_{{1j}}c_{{1j}}+a_{{2j}}c_{{2j}}+a_{{3j}}c_{{3j}}+...+a_{{nj}}c_{{nj}}\]&lt;/span> （对第 j 纵行的余因子分解） &lt;span class="math">\[\det(A)=a_{{i1}}c_{{i1}}+a_{{i2}}c_{{i2}}+a_{{i3}}c_{{i3}}+...+a_{{in}}c_{{in}}\]&lt;/span> （对第 i 横列的余因子分解）&lt;/p>
&lt;h3 id="余因子矩阵与伴随矩阵">余因子矩阵与伴随矩阵&lt;/h3>
&lt;p>&lt;span class="math">\(A\)&lt;/span>的余子矩阵是指将&lt;span class="math">\(A\)&lt;/span>的&lt;span class="math">\((i, j)\)&lt;/span>项代数余子式&lt;span class="math">\(c_{ij}\)&lt;/span>摆在第i行第j列所得到的矩阵，记为&lt;span class="math">\(C\)&lt;/span>。&lt;/p>
&lt;p>余子矩阵&lt;span class="math">\(C\)&lt;/span>的&lt;strong>转置&lt;/strong>矩阵称为&lt;span class="math">\(A\)&lt;/span>的伴随矩阵&lt;span class="math">\(A^\ast\)&lt;/span>，伴随矩阵类似于逆矩阵，并且当A可逆时可以用来计算它的逆矩阵。 &lt;span class="math">\[A^{-1}=\frac{1}{\det(A)}A^\ast=\frac{1}{\det(A)}C^T\]&lt;/span>&lt;/p></description></item><item><title>线性代数与矩阵之-海森矩阵校正</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B-%E6%B5%B7%E6%A3%AE%E7%9F%A9%E9%98%B5%E6%A0%A1%E6%AD%A3/</link><pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B-%E6%B5%B7%E6%A3%AE%E7%9F%A9%E9%98%B5%E6%A0%A1%E6%AD%A3/</guid><description>
&lt;h2 id="海森矩阵校正">海森矩阵校正&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#海森矩阵校正的两种思路">海森矩阵校正的两种思路&lt;/a>&lt;/li>
&lt;li>&lt;a href="#modified_cholesky分解">Modified_Cholesky分解&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="海森矩阵校正的两种思路">海森矩阵校正的两种思路&lt;/h2>
&lt;p>解决海森矩阵不正定问题的方法称为海森校正（Hessian Modification）。思路是让海森矩阵加上一个微小的量，使其正定，相当于用&lt;span class="math">\(B_k=\nabla^2f(x_k)+E_k\)&lt;/span>替代&lt;span class="math">\(\nabla^2f(x_k)\)&lt;/span>。其中，&lt;span class="math">\(E_k\)&lt;/span>为修正矩阵，需要尽可能小，以避免修改后的方向&lt;span class="math">\(d_k=-B_k^{-1}g_k\)&lt;/span>与牛顿方向&lt;span class="math">\(-H_k^{-1}g_k\)&lt;/span>相差太远。&lt;/p>
&lt;p>我们知道令&lt;span class="math">\(B_k=\nabla^2f(x_k)+v_kI\)&lt;/span>，当 &lt;span class="math">\(v_k&amp;gt;|\lambda_1|\)&lt;/span>时，&lt;span class="math">\(B_k\)&lt;/span>正定。其中&lt;span class="math">\(\lambda_1\)&lt;/span>是&lt;span class="math">\(\nabla^2f(x_k)\)&lt;/span>最小的特征值。因此可以得到&lt;span class="math">\(E_k=\tau I\)&lt;/span>，其中&lt;span class="math">\(\tau=\max\{0,\delta-\lambda_1\}\)&lt;/span>，&lt;strong>&lt;span class="math">\(\delta\)&lt;/span>是一个略大于零的常数&lt;/strong>。这样原矩阵加上了一个标量乘以单位矩阵，所有特征值都大于零，&lt;span class="math">\(B_k\)&lt;/span>正定。&lt;/p>
&lt;p>但是这种方法不是改动最小的方案，如果我们做的更精细一些：对于任意对称矩阵&lt;span class="math">\(A\)&lt;/span>，可以将其分解为&lt;span class="math">\(A=Q\Lambda Q^T\)&lt;/span>，其中&lt;span class="math">\(\Lambda\)&lt;/span>是由&lt;span class="math">\(A\)&lt;/span>的特征值组成的对角矩阵。如果我们令&lt;span class="math">\(A&amp;#39;=Q(\Lambda+\mathop{diag(\tau_i)})Q^T\)&lt;/span>，其中&lt;span class="math">\(\tau_i\)&lt;/span>由&lt;span class="math">\(\lambda_i\)&lt;/span>确定，并满足 &lt;span class="math">\[\tau_i=\begin{cases}
0,&amp;amp;\lambda_i&amp;gt;\delta\\
\delta-\lambda_i,&amp;amp;\lambda_i&amp;lt;\delta
\end{cases}\]&lt;/span> 这意味着直接修改&lt;span class="math">\(A\)&lt;/span>的特征值，将所有小于&lt;span class="math">\(\delta\)&lt;/span>的特征值调整到&lt;span class="math">\(\delta\)&lt;/span>，从而保证&lt;span class="math">\(A&amp;#39;\)&lt;/span>的正定性。该方法相当于令&lt;span class="math">\(E_k=Q\mathop{diag(\tau_i)}Q^T\)&lt;/span>。&lt;/p>
&lt;p>这两种方法都是根据特征值确定&lt;span class="math">\(E_k\)&lt;/span>，哪种更好呢？&lt;/p>
&lt;p>其实说不上哪个更好，本质上，他们是&lt;strong>在不同范数约束下的最优结果&lt;/strong>。前面提到，我们希望&lt;span class="math">\(E_k\)&lt;/span>越小越好，因此可以用矩阵范数来衡量&lt;span class="math">\(E_k\)&lt;/span>的大小。第一种方案其实是在欧氏范数下的最小改动，因为&lt;span class="math">\(||E_k||=||\tau I||=\tau\)&lt;/span>，不存在使&lt;span class="math">\(||E_k||\)&lt;/span>更小的其它&lt;span class="math">\(\tau\)&lt;/span>。第二种方案则是在Frobenius范数下的最小改动。Frobenius范数定义为 &lt;span class="math">\[||A||_F=\bigg(\sum_{i=1}^m\sum_{j=1}^na_{ij}^2\bigg)^{1/2}\]&lt;/span> 即所有矩阵元素的平方和再开根号，该范数刻画了矩阵所有元素值的大小。在该定义下， &lt;span class="math">\[||E_k||_F=||Q\mathop{diag(\tau_i)}Q^T||_F\\
=||\mathop{diag(\tau_i)}||_F=\sqrt{\sum_i^N \tau_i^2}\]&lt;/span> 第二行去掉了矩阵&lt;span class="math">\(Q\)&lt;/span>和&lt;span class="math">\(Q^T\)&lt;/span>，因为实对称矩阵的特征向量构成的矩阵&lt;span class="math">\(Q\)&lt;/span>是正交矩阵，而正交矩阵相当于旋转，不改变Frobenius范数。容易验证，第一种方案的Frobenius范数为&lt;span class="math">\(||\tau I||_F=\sqrt{N}\tau\)&lt;/span>，做个简单的放缩就能发现&lt;span class="math">\(\sqrt{\sum_i^N \tau_i^2}≤\sqrt{N}\tau\)&lt;/span>，所以第二种方案是Frobenius范数下的最小改动。&lt;/p>
&lt;p>了解上面两种方法，其实并不能在实际中帮上忙。&lt;strong>因为海森矩阵的特征值我们根本无从得知，那是一个需要花大代价才能知道的数字&lt;/strong>。在实际中，我们一般采取&lt;span class="math">\(E_k=\tau I\)&lt;/span>这种方案，但不通过特征向量确定&lt;span class="math">\(\tau\)&lt;/span>，而是以迭代的方式&lt;strong>把可行的&lt;span class="math">\(\tau\)&lt;/span>试出来&lt;/strong>。&lt;/p>
&lt;p>具体怎么做呢？我们可以先从一个稍小的数开始尝试，比如令&lt;span class="math">\(\tau_0=||A||_F/2\)&lt;/span>，在每次迭代中对校正后的海森矩阵进行Cholesky分解， &lt;span class="math">\[LL^T=A+\tau_k I=B_k\]&lt;/span> 如果分解成功，那么分解的结果&lt;span class="math">\(L\)&lt;/span>就可以用来快速求解式&lt;span class="math">\(B_kd_k=-g_k\)&lt;/span>。如果分解失败，那么将&lt;span class="math">\(\tau_k\)&lt;/span>扩大一倍，进入下一次尝试，直到分解成功。&lt;/p>
&lt;h2 id="modified_cholesky分解">Modified_Cholesky分解&lt;/h2>
&lt;p>对海森矩阵进行校正，即叠加一个小矩阵，使其正定。但是海森校正苦于无法得知特征值的大小，只能多试几次，试的次数越多，浪费的时间就越多。&lt;/p>
&lt;p>但问题难不倒聪明的研究者，有人提出了一种新的海森校正方法，称为&lt;strong>modified Cholesky分解，可以在做Cholesky分解的过程中调整原矩阵的值，不需要迭代，不需要试错，分解完毕后直接得到新的正定海森矩阵&lt;/strong>。让我们看看这种方法是如何实现的。&lt;/p>
&lt;p>对于任意一个正定对称矩阵，一定可以分解为如下形式 &lt;span class="math">\[A=LDL^T\]&lt;/span> 其中，&lt;span class="math">\(L\)&lt;/span>是对角线元素全为1的下三角矩阵，&lt;span class="math">\(D\)&lt;/span>是对角矩阵。为了直观地解释分解的过程，我们以3×3对称矩阵为例 &lt;span class="math">\[\begin{bmatrix}
a_{11}&amp;amp;a_{21}&amp;amp;a_{31}\\
a_{21}&amp;amp;a_{22}&amp;amp;a_{32}\\
a_{31}&amp;amp;a_{32}&amp;amp;a_{33}
\end{bmatrix}=
\begin{bmatrix}1&amp;amp;0&amp;amp;0\\l_{21}&amp;amp;1&amp;amp;0\\l_{31}&amp;amp;l_{32}&amp;amp;1\end{bmatrix}
\begin{bmatrix}d_1&amp;amp;0&amp;amp;0\\0&amp;amp;d_2&amp;amp;0\\0&amp;amp;0&amp;amp;d_3\end{bmatrix}
\begin{bmatrix}1&amp;amp;l_{21}&amp;amp;l_{31}\\0&amp;amp;1&amp;amp;l_{32}\\0&amp;amp;0&amp;amp;1\end{bmatrix}\\
=\begin{bmatrix}d_1&amp;amp;l_{21}d_1&amp;amp;l_{31}d_1\\l_{21}d_1&amp;amp;l_{21}^2d_1+d_2&amp;amp;l_{31}l_{21}d_1+l_{32}d_2\\l_{31}d_1&amp;amp;l_{31}l_{21}d_1+l_{32}d_2&amp;amp;l_{31}^2d_1+l_{32}^2d_2+d_3\end{bmatrix}\]&lt;/span> 令等号左右第一列相等，可以得到 &lt;span class="math">\[d_1=a_{11}\\
l_{21}=a_{21}/d_1\\
l_{31}=a_{31}/d_1\]&lt;/span> 再令第二列、第三列相等，可以得到 &lt;span class="math">\[d_2=a_{22}-l_{21}^2d_1\\
l_{32}=(a_{32}-l_{31}l_{21}d_1)/d_2\\
d_3=a_{33}-l_{31}^2d_1-l_{32}^2d_2\]&lt;/span>&lt;/p>
&lt;p>如果矩阵&lt;span class="math">\(A\)&lt;/span>不正定，那么计算出的&lt;span class="math">\(d_i\)&lt;/span>很可能是负的，同时导致&lt;span class="math">\(L\)&lt;/span>矩阵的元素值不稳定，很可能过大。也就是说，分解成&lt;span class="math">\(LDL^T\)&lt;/span>形式后再修改&lt;span class="math">\(d_i\)&lt;/span>的值已经来不及了，我们需要在分解的过程中随时修改&lt;span class="math">\(d_i\)&lt;/span>。以上面的例子为例，如果&lt;span class="math">\(d_1\)&lt;/span>和&lt;span class="math">\(d_2\)&lt;/span>都是正数，而&lt;span class="math">\(d_3\)&lt;/span>是个负数，那么我们就直接把&lt;span class="math">\(d_3\)&lt;/span>替换为一个正数。由于&lt;span class="math">\(d_3\)&lt;/span>是最后一步算出来的，所以它的改变不影响其它分解结果。但假设另一种情况，&lt;span class="math">\(d_1\)&lt;/span>是正数，&lt;span class="math">\(d_2\)&lt;/span>就已经是负数了，这时我们仍然直接把&lt;span class="math">\(d_2\)&lt;/span>替换为正数，不过这会影响下一步&lt;span class="math">\(l_{32}\)&lt;/span>的计算，所以这种情况下&lt;span class="math">\(L\)&lt;/span>矩阵会随之改变。&lt;/p>
&lt;p>为什么要这样做呢？回到我们最初的目标，如果&lt;span class="math">\(A\)&lt;/span>不正定，我们想要找到一个正定矩阵&lt;span class="math">\(A&amp;#39;=A+E\)&lt;/span>来替代&lt;span class="math">\(A\)&lt;/span>，这样一来，虽然&lt;span class="math">\(A=LDL^T\)&lt;/span>可能不存在，但我们可以找到使&lt;span class="math">\(A&amp;#39;=L&amp;#39;D&amp;#39;L&amp;#39;^T\)&lt;/span>成立的&lt;span class="math">\(A&amp;#39;\)&lt;/span>。上面的分解步骤相当于找到了一个&lt;span class="math">\(A&amp;#39;=L&amp;#39;(D+diag(\tau_i))L&amp;#39;^T\)&lt;/span>，其中&lt;span class="math">\(\tau_i=\begin{cases} 0,&amp;amp;d_i&amp;gt;\delta\\ \delta-d_i,&amp;amp;d_i&amp;lt;\delta \end{cases}\)&lt;/span>。&lt;/p>
&lt;p>到这里还没完，这一方法有一个神奇的性质，&lt;span class="math">\(L&amp;#39;D&amp;#39;L&amp;#39;^T=LDL^T+diag(\tau_i)\)&lt;/span>恒成立，即&lt;span class="math">\(A&amp;#39;=A+diag(\tau_i)\)&lt;/span>。我们在&lt;span class="math">\(D\)&lt;/span>的对角线元素上的改动竟然直接相当于修改&lt;span class="math">\(A\)&lt;/span>的对角线元素，同时保持非对角线元素不变。这个性质非常完美，可以最大限度地保留&lt;span class="math">\(A\)&lt;/span>本身的值，只对某些对角线元素做微小的修改，它的改动最小，也最高效。至于为什么会存在这样的性质，观察上面的推导，可以发现&lt;span class="math">\(A\)&lt;/span>的非对角线元素都包含&lt;span class="math">\(l_{ij}d_i\)&lt;/span>项，而这一项在整个推导过程中其实是不变的。&lt;/p>
&lt;p>由于篇幅有限，modified Cholesky的实际操作上的细节我们就不展开讲了。&lt;/p></description></item><item><title>线性代数与矩阵之广义逆矩阵</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/</link><pubDate>Tue, 21 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%B9%BF%E4%B9%89%E9%80%86%E7%9F%A9%E9%98%B5/</guid><description>
&lt;h2 id="广义逆矩阵">广义逆矩阵&lt;!-- omit in toc -->&lt;/h2>
&lt;p>广义逆（Generalized inverse），是线性代数中针对矩阵的一种运算。一个矩阵&lt;span class="math">\(A\)&lt;/span>的广义逆叫做&lt;span class="math">\(A\)&lt;/span>的广义逆阵，是指具有部分逆矩阵的特性，但是不一定具有逆矩阵的所有特性的另一矩阵。假设一矩阵&lt;span class="math">\(A\in \mathbb {R} ^{n\times m}\)&lt;/span>及另一矩阵&lt;span class="math">\(A^{\mathrm {g} }\in \mathbb {R} ^{m\times n}\)&lt;/span>，若&lt;span class="math">\(A^{\mathrm {g} }\)&lt;/span>满足&lt;span class="math">\(AA^{\mathrm {g} }A=A\)&lt;/span>，则&lt;span class="math">\(A^{\mathrm {g} }\)&lt;/span>即为&lt;span class="math">\(A\)&lt;/span>的广义逆阵。&lt;/p>
&lt;p>广义逆也称为伪逆（pseudoinverse），有些时候，伪逆特指&lt;strong>摩尔－彭若斯广义逆&lt;/strong>。&lt;/p>
&lt;h2 id="摩尔彭若斯广义逆">摩尔－彭若斯广义逆&lt;/h2>
&lt;p>彭若斯条件可以用来定义不同的广义逆阵：针对&lt;span class="math">\(A\in \mathbb {R} ^{n\times m}\)&lt;/span>及&lt;span class="math">\(A^{\mathrm {g} }\in \mathbb {R} ^{m\times n}\)&lt;/span>，&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;span class="math">\({\displaystyle AA^{\mathrm {g} }A=A}\)&lt;/span>&lt;/li>
&lt;li>&lt;span class="math">\(\displaystyle A^{\mathrm {g} }AA^{\mathrm {g} }=A^{\mathrm {g}}\)&lt;/span>&lt;/li>
&lt;li>&lt;span class="math">\({\displaystyle (AA^{\mathrm {g} })^{\mathrm {T} }=AA^{\mathrm {g}}}\)&lt;/span>&lt;/li>
&lt;li>&lt;span class="math">\({\displaystyle (A^{\mathrm {g} }A)^{\mathrm {T} }=A^{\mathrm {g} }A}\)&lt;/span>&lt;/li>
&lt;/ol>
&lt;p>若&lt;span class="math">\({\displaystyle A^{\mathrm {g} }}\)&lt;/span>满足条件(1)，即为&lt;span class="math">\(A\)&lt;/span>的广义逆阵，若满足条件(1)和(2)，则为&lt;span class="math">\(A\)&lt;/span>的广义反身逆阵（generalized reflexive inverse），若四个条件都满足，则为&lt;span class="math">\(A\)&lt;/span>的摩尔－彭若斯广义逆。&lt;/p>
&lt;p>广义逆矩阵可以通过满秩分解或者SVD分解求得，虽然方法不同，满秩分解也不是唯一的，但是计算出的广义逆矩阵是一样的。&lt;/p>
&lt;p>假设&lt;span class="math">\(A=BC\)&lt;/span>为任一满秩分解，则&lt;span class="math">\(A^g=C^H(CC^H)^{-1}(B^HB)^{-1}B^H\)&lt;/span>&lt;/p>
&lt;p>假设&lt;span class="math">\(A=U\Sigma V^T\)&lt;/span>为SVD分解，则&lt;span class="math">\(A^g=V\Sigma^gU^T\)&lt;/span>，其中&lt;span class="math">\(\Sigma^g\)&lt;/span>中元素为对应&lt;span class="math">\(\Sigma\)&lt;/span>中非零元素的倒数。&lt;/p>
&lt;h2 id="单边逆矩阵">单边逆矩阵&lt;/h2>
&lt;p>单边逆矩阵（左逆矩阵或是右逆矩阵）若矩阵&lt;span class="math">\(A\)&lt;/span>的维度是&lt;span class="math">\(n\times m\)&lt;/span>且为(行或列)满秩，若&lt;span class="math">\(n&amp;gt;m\)&lt;/span>则用左逆矩阵，若&lt;span class="math">\(n&amp;lt;m\)&lt;/span>则用右逆矩阵。&lt;/p>
&lt;p>左逆矩阵为&lt;span class="math">\(A_{\mathrm {left} }^{-1}=\left(A^{\mathrm {T} }A\right)^{-1}A^{\mathrm {T} }\)&lt;/span>，也就是&lt;span class="math">\(A_{\mathrm {left} }^{-1}A=I_{m}\)&lt;/span>，其中&lt;span class="math">\(I_{m}\)&lt;/span>为&lt;span class="math">\(m\times m\)&lt;/span>单位矩阵。&lt;/p>
&lt;p>右逆矩阵为&lt;span class="math">\(A_{\mathrm {right} }^{-1}=A^{\mathrm {T} }\left(AA^{\mathrm {T} }\right)^{-1}\)&lt;/span>，也就是&lt;span class="math">\(AA_{\mathrm {right} }^{-1}=I_{n}\)&lt;/span>，其中&lt;span class="math">\(I_n\)&lt;/span>为&lt;span class="math">\(n\times n\)&lt;/span>单位矩阵。&lt;/p>
&lt;h2 id="性质">性质&lt;/h2>
&lt;ol style="list-style-type: decimal">
&lt;li>可逆矩阵有&lt;span class="math">\((AB)^{-1}=B^{-1}A^{-1}\)&lt;/span>，但是广义逆&lt;span class="math">\((AB)^g\)&lt;/span>与&lt;span class="math">\(B^gA^g\)&lt;/span>一般不相等。&lt;/li>
&lt;li>&lt;span class="math">\((A^g)^g=A\)&lt;/span>&lt;/li>
&lt;li>&lt;span class="math">\((A^H)^g=(A^g)^H\)&lt;/span>&lt;/li>
&lt;li>&lt;span class="math">\(k\in R\)&lt;/span>，则有&lt;span class="math">\((kA^g)=k^gA^g，k^g=\begin{cases}k^{-1}，k\neq 0\\0，k=0\end{cases}\)&lt;/span>&lt;/li>
&lt;li>区别于性质1，有&lt;span class="math">\((A^H A)^g=A^g(A^H)^g\)&lt;/span>&lt;/li>
&lt;li>&lt;span class="math">\(A^g=(A^HA)^gA^H=A^H(AA^H)^g\)&lt;/span>&lt;/li>
&lt;li>对于酉矩阵&lt;span class="math">\(U,V\)&lt;/span>，则&lt;span class="math">\((UAV)^g=V^HA^gU^H\)&lt;/span>。从这点也可以看出用SVD分解求广义逆的方法。&lt;/li>
&lt;li>&lt;span class="math">\(A^gAB=A^gAC\Leftrightarrow AB=AC\)&lt;/span>&lt;/li>
&lt;/ol>
&lt;h2 id="广义逆矩阵的应用">广义逆矩阵的应用&lt;/h2>
&lt;p>当&lt;span class="math">\(Ax=b\)&lt;/span>无解时可以用广义逆矩阵求近似解，实际是就是求&lt;span class="math">\(||Ax-b||_2\)&lt;/span>最小。&lt;/p>
&lt;p>其通解为 &lt;span class="math">\[x=A^gb+(I-A^gA)y，y\in C^n\]&lt;/span> 其中，&lt;span class="math">\(A^gb\)&lt;/span>是唯一的极小最小二乘解。极小指长度（范数）最小。&lt;/p></description></item><item><title>线性代数与矩阵之对称矩阵</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5/</link><pubDate>Sun, 19 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%AF%B9%E7%A7%B0%E7%9F%A9%E9%98%B5/</guid><description>
&lt;h2 id="线性代数与矩阵之对称矩阵">线性代数与矩阵之对称矩阵&lt;!-- omit in toc -->&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="#对称矩阵">对称矩阵&lt;/a>&lt;/li>
&lt;li>&lt;a href="#简单性质">简单性质&lt;/a>&lt;/li>
&lt;li>&lt;a href="#实对称矩阵的特征值与特征向量">实对称矩阵的特征值与特征向量&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征值都是实数">特征值都是实数&lt;/a>&lt;/li>
&lt;li>&lt;a href="#不同特征值的特征向量正交">不同特征值的特征向量正交&lt;/a>&lt;/li>
&lt;li>&lt;a href="#对称矩阵与正定性">对称矩阵与正定性&lt;/a>&lt;/li>
&lt;li>&lt;a href="#对称矩阵的分解">对称矩阵的分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#特征分解谱分解">特征分解（谱分解）&lt;/a>&lt;/li>
&lt;li>&lt;a href="#cholesky分解">Cholesky分解&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#分解唯一性">分解唯一性&lt;/a>&lt;/li>
&lt;li>&lt;a href="#分解方法">分解方法&lt;/a>&lt;/li>
&lt;/ul>&lt;/li>
&lt;li>&lt;a href="#cholesky分解变形ldl分解">Cholesky分解变形——LDL分解&lt;/a>&lt;/li>
&lt;li>&lt;a href="#拓展埃米特矩阵">拓展：埃米特矩阵&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="对称矩阵">对称矩阵&lt;/h2>
&lt;p>在线性代数中，对称矩阵（英语：symmetric matrix）是一个方形矩阵，其&lt;strong>转置矩阵和自身相等&lt;/strong>。 &lt;span class="math">\[A = A^{\textrm{T}}\]&lt;/span> 对称矩阵中的右上至左下方向元素以主对角线（左上至右下）为轴进行对称。若将其写作&lt;span class="math">\(A = (a_{ij})\)&lt;/span>，则对所有的&lt;span class="math">\(i和j\)&lt;/span>， &lt;span class="math">\[a_{ij}=a_{ji}.\]&lt;/span> 下列是3×3的对称矩阵： &lt;span class="math">\[\begin{bmatrix}
1 &amp;amp; 2 &amp;amp; 3\\
2 &amp;amp; 4 &amp;amp; -5\\
3 &amp;amp; -5 &amp;amp; 6\end{bmatrix}\]&lt;/span> 下列是&lt;strong>斜对称矩阵&lt;/strong>（英语：skew-symmetric matrix，又称&lt;strong>反对称矩阵&lt;/strong>，英语：antisymmetric matrix）： &lt;span class="math">\[\begin{bmatrix}
0 &amp;amp; -3 &amp;amp; 4\\
3 &amp;amp; 0 &amp;amp; -5\\
-4 &amp;amp; 5 &amp;amp; 0\end{bmatrix}\]&lt;/span>&lt;/p>
&lt;h2 id="简单性质">简单性质&lt;/h2>
&lt;ul>
&lt;li>对于任何方形矩阵&lt;span class="math">\(X\)&lt;/span>，&lt;span class="math">\(X+X^T\)&lt;/span>是对称矩阵。（此外，对称矩阵的和也是对称矩阵。）&lt;/li>
&lt;li>&lt;span class="math">\(A\)&lt;/span>为方形矩阵是&lt;span class="math">\(A\)&lt;/span>为对称矩阵的&lt;strong>必要条件&lt;/strong>，即对称矩阵行数必等于列数（显而易见）。&lt;/li>
&lt;li>对角矩阵都是对称矩阵（显而易见）。&lt;/li>
&lt;li>每个实方形矩阵都可写作&lt;strong>两个实对称矩阵的积&lt;/strong>，每个复方形矩阵都可写作&lt;strong>两个复对称矩阵的积&lt;/strong>。（神奇，未曾自己证明）&lt;/li>
&lt;li>若对称矩阵&lt;span class="math">\(A\)&lt;/span>的每个元素均为&lt;strong>实数&lt;/strong>，&lt;span class="math">\(A\)&lt;/span>是实对称矩阵。&lt;/li>
&lt;li>一个矩阵同时为对称矩阵及斜对称矩阵当且仅当所有元素都是零。（显而易见）&lt;/li>
&lt;li>如果X是对称矩阵，那么&lt;span class="math">\(AXA^T\)&lt;/span> 也是对称矩阵.证明：&lt;span class="math">\((AXA^T)^T=(A^T)^TX^TA^T=AX^TA^T;\because X^T=X;\therefore AX^TA^T=AXA^T\)&lt;/span>。&lt;/li>
&lt;/ul>
&lt;h2 id="实对称矩阵的特征值与特征向量">实对称矩阵的特征值与特征向量&lt;/h2>
&lt;p>先说结论：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>实对称矩阵的特征值都是&lt;strong>实数&lt;/strong>。实际上，即使是对称矩阵在复数域上的推广埃米特矩阵，其特征值也都是实数。关于埃米特矩阵的简介，见笔记末尾&lt;a href="#拓展埃米特矩阵">拓展：埃米特矩阵&lt;/a>。&lt;/li>
&lt;li>实对称矩阵的&lt;strong>属于不同特征值&lt;/strong>的特征向量都是&lt;strong>正交&lt;/strong>的。&lt;/li>
&lt;li>特征值符号和主元符号相同，即正特征值数等于正主元数。（证明略）&lt;/li>
&lt;/ol>
&lt;h3 id="特征值都是实数">特征值都是实数&lt;/h3>
&lt;p>对于实对称矩阵的特征值都是&lt;strong>实数&lt;/strong>的证明，我们直接证明埃米特矩阵&lt;span class="math">\(A\)&lt;/span>，因为实对称矩阵只是埃米特矩阵的特殊情况。&lt;/p>
&lt;blockquote>
&lt;p>我们需要用到&lt;strong>共轭转置&lt;/strong>，即&lt;span class="math">\(A^H,x^H\)&lt;/span>，具体操作为所有元素行列位置交换并取共轭，共轭转置是转置在复数域的推广。 设&lt;span class="math">\(\lambda_1, x_1\)&lt;/span>分别是埃米特矩阵&lt;span class="math">\(A\)&lt;/span>的&lt;strong>任意一对&lt;/strong>特征值和特征向量，因而有： &lt;span class="math">\[Ax_1=\lambda_1 x_1\]&lt;/span> 两边同时左乘&lt;span class="math">\(x_1^H\)&lt;/span>可得 &lt;span class="math">\[x_1^H A x_1=\lambda_1 x_1^Hx=\lambda_1 |x_1|^2\tag{1}\]&lt;/span> 同时，由于&lt;span class="math">\(A\)&lt;/span>是埃米特矩阵，有&lt;span class="math">\(A^H=A\)&lt;/span>，所以有： &lt;span class="math">\[(Ax_1)^H=(\lambda_1 x_1)^H=x_1^H\underbrace{A^H}_{=A}=\underbrace{\bar{\lambda}_1}_{取共轭}x_1^H\]&lt;/span> 两边同时右乘&lt;span class="math">\(x_1\)&lt;/span>可得： &lt;span class="math">\[x_1^H A x_1=\bar{\lambda}_1 x_1^Hx=\bar{\lambda}_1 |x_1|^2\tag{2}\]&lt;/span> 显然，式（1）等于式（2），所以： &lt;span class="math">\[\lambda_1 |x_1|^2=\bar{\lambda}_1 |x_1|^2\Rightarrow \lambda_1=\bar{\lambda}_1\]&lt;/span> 即&lt;span class="math">\(\lambda_1\)&lt;/span>是实数。因为&lt;span class="math">\(\lambda_1\)&lt;/span>是埃米特矩阵&lt;span class="math">\(A\)&lt;/span>的任意一特征值，所以&lt;span class="math">\(A\)&lt;/span>的所有特征值都是实数。&lt;/p>
&lt;/blockquote>
&lt;h3 id="不同特征值的特征向量正交">不同特征值的特征向量正交&lt;/h3>
&lt;p>这里需要指出的是，这个特性只针对不同特征值下的特征向量。而对于同一特征值下的特征向量，我们可以取该特征值特征空间中的一组正交基，来保证其正交性。&lt;strong>后面我们将通过对称矩阵特征值分解的存在性，说明特征空间维数等于特征值代数重数，所以我们能在&lt;span class="math">\(n\)&lt;/span>维对称矩阵中找出&lt;span class="math">\(n\)&lt;/span>个正交的特征向量&lt;/strong>。&lt;/p>
&lt;p>现在，我们先证明不同特征值条件下的特征向量正交性。&lt;/p>
&lt;blockquote>
&lt;p>我们假设对称矩阵&lt;span class="math">\(A\)&lt;/span>任意两个不同的特征值&lt;span class="math">\(\lambda_1,\lambda_2\)&lt;/span>相应的特征向量为&lt;span class="math">\(x_1,x_2\)&lt;/span>，显然有： &lt;span class="math">\[Ax_1=\lambda_1 x_1\quad Ax_2=\lambda_2 x_2\]&lt;/span> 我们将第二个式子做转置加上&lt;span class="math">\(A\)&lt;/span>的对称性可得：&lt;span class="math">\((Ax_2)^T=x_2^TA^T=x_2^TA=\lambda_2 x_2^T\)&lt;/span>。我们用&lt;span class="math">\(x_2^T\)&lt;/span>左乘&lt;span class="math">\(Ax_1=\lambda_1 x_1\)&lt;/span>，再用&lt;span class="math">\(x_1\)&lt;/span>右乘&lt;span class="math">\(x_2^TA=\lambda_2 x_2^T\)&lt;/span>可得： &lt;span class="math">\[x_2^TAx_1=\lambda_1 x_2^Tx_1\\x_2^TAx_1=\lambda_2 x_2^Tx_1\]&lt;/span> 因此可得： &lt;span class="math">\[\lambda_1 x_2^Tx_1=\lambda_2 x_2^Tx_1\Rightarrow (\lambda_1-\lambda_2)x_2^Tx_1=0\]&lt;/span> 由于&lt;span class="math">\(\lambda_1\neq \lambda_2\)&lt;/span>，所以&lt;span class="math">\(x_2^Tx_1=0\)&lt;/span>，即&lt;span class="math">\(x_2^T\perp x_1\)&lt;/span>二者正交。又因为特征值&lt;span class="math">\(\lambda_1,\lambda_2\)&lt;/span>，特征向量&lt;span class="math">\(x_1,x_2\)&lt;/span>的任意性，我们可证不同特征值的特征向量正交。&lt;/p>
&lt;/blockquote>
&lt;h2 id="对称矩阵与正定性">对称矩阵与正定性&lt;/h2>
&lt;p>谈到对称矩阵多少会聊到矩阵的正定性，通常&lt;strong>正定性是定义在对称矩阵（或埃米特矩阵）上&lt;/strong>的，如果一个矩阵不是对称矩阵，就不具备讨论正定性的前提条件。&lt;/p>
&lt;blockquote>
&lt;p>一个&lt;span class="math">\(n×n\)&lt;/span>的实对称矩阵&lt;span class="math">\(A\)&lt;/span>是&lt;strong>正定的&lt;/strong>，当且仅当对于所有的非零实系数向量&lt;span class="math">\(x\)&lt;/span>，都有&lt;span class="math">\(x^TAx&amp;gt;0\)&lt;/span>，其中&lt;span class="math">\(x^T\)&lt;/span>表示x的转置。&lt;/p>
&lt;p>类似的，如果&lt;span class="math">\(x^TAx\geq 0\)&lt;/span>，则&lt;span class="math">\(A\)&lt;/span>称为&lt;strong>半正定矩阵&lt;/strong>；如果&lt;span class="math">\(x^TAx&amp;lt;0\)&lt;/span>，则&lt;span class="math">\(A\)&lt;/span>称为&lt;strong>负定矩阵&lt;/strong>；如果&lt;span class="math">\(x^TAx\leq 0\)&lt;/span>，则&lt;span class="math">\(A\)&lt;/span>称为&lt;strong>半负定矩阵&lt;/strong>。&lt;/p>
&lt;/blockquote>
&lt;p>正定性还有这几个等价命题：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有特征值为正&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有主元为正&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的顺序主子式为正&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>与单位阵&lt;span class="math">\(I\)&lt;/span>合同，即存在可逆矩阵&lt;span class="math">\(C\)&lt;/span>，使得&lt;span class="math">\(A=C^TIC\)&lt;/span>&lt;/li>
&lt;/ol>
&lt;p>类似的，半正定矩阵有以下等价命题：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有特征值为非负&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的所有主元为非负&lt;/li>
&lt;li>矩阵&lt;span class="math">\(A\)&lt;/span>的顺序主子式为非负&lt;/li>
&lt;/ol>
&lt;p>我们可以通过例子说明，非对称矩阵可以在满足上述1，2，3的前提下不满足正定矩阵的定义&lt;span class="math">\(x^TAx&amp;gt;0\)&lt;/span>。如下例 &lt;span class="math">\[
\begin{bmatrix}
1&amp;amp;-100\\0&amp;amp;1
\end{bmatrix}
\]&lt;/span> 显然，其主元、特征值都是1，顺序主子式也都大于0，但是对于&lt;span class="math">\(x^TAx\)&lt;/span>，我们随便找一个向量&lt;span class="math">\(x=[1,1]^T\)&lt;/span>，则 &lt;span class="math">\[
[1\quad 1]\begin{bmatrix}1&amp;amp;-100\\0&amp;amp;1\end{bmatrix}\begin{bmatrix}1\\1\end{bmatrix}=-98&amp;lt;0
\]&lt;/span> 这并不满足&lt;span class="math">\(x^TAX&amp;gt;0\)&lt;/span>。这说明，&lt;strong>正定性必须建立在对称矩阵上&lt;/strong>。&lt;/p>
&lt;h2 id="对称矩阵的分解">对称矩阵的分解&lt;/h2>
&lt;p>对称矩阵分解最重要的就是特征分解，又称谱分解。本节将着重介绍对称矩阵特征分解的存在性。同时，对于对称矩阵而言，SVD分解和特征分解是一样的。最后，我们对埃米特矩阵补充了Cholesky分解的相关内容，Cholesky分解是正定埃尔米特矩阵的LU分解，且具有唯一性。&lt;/p>
&lt;h3 id="特征分解谱分解">特征分解（谱分解）&lt;/h3>
&lt;p>特征分解的具体方法可见笔记&lt;a href="线性代数与矩阵之特征值与特征向量.md">线性代数与矩阵之特征值与特征向量&lt;/a>。这节我们着重说明对称矩阵特征分解的必定存在性。&lt;/p>
&lt;p>首先，我们需要引入实矩阵的舒尔分解，详细内容见&lt;a href="线性代数与矩阵之矩阵分解.md">线性代数与矩阵之矩阵分解&lt;/a>：&lt;/p>
&lt;blockquote>
&lt;p>实数域的舒尔分解定理：如果&lt;span class="math">\(A∈\mathbb{R}^n\)&lt;/span>是&lt;span class="math">\(n\)&lt;/span>阶的&lt;strong>实方阵&lt;/strong>，则存在&lt;span class="math">\(n\)&lt;/span>阶正交矩阵&lt;span class="math">\(Q\)&lt;/span>，&lt;span class="math">\(n\)&lt;/span>阶&lt;strong>拟上三角&lt;/strong>矩阵&lt;span class="math">\(T\)&lt;/span>，使得 &lt;span class="math">\[A=QTQ^{-1}=QTQ^T\]&lt;/span> 即任何一个&lt;span class="math">\(n\)&lt;/span>阶实方阵&lt;span class="math">\(A\)&lt;/span>正交相似于一个&lt;span class="math">\(n\)&lt;/span>阶&lt;strong>拟上三角&lt;/strong>矩阵&lt;span class="math">\(T\)&lt;/span>。&lt;/p>
&lt;/blockquote>
&lt;p>对于对称矩阵而言，由于&lt;span class="math">\(A^T=A\)&lt;/span>，所以矩阵&lt;span class="math">\(A\)&lt;/span>和其转置&lt;span class="math">\(A^T\)&lt;/span>写成舒尔分解形式有： &lt;span class="math">\[\left . \begin{aligned}A=QTQ^T\\A^T=QT^TQ^T\\A=A^T\end{aligned}\right\}\Rightarrow QT^TQ^T=QTQ^T\Rightarrow T^T=T\]&lt;/span> 由于&lt;span class="math">\(T\)&lt;/span>是拟三角矩阵，当其也为对称矩阵的时候，&lt;span class="math">\(T\)&lt;/span>必然是一个对角矩阵。我们用&lt;span class="math">\(\Lambda\)&lt;/span>表示。这个证明用转置相等可以证明，在此就不详细写了。所以，对称矩阵&lt;span class="math">\(A\)&lt;/span>一定可以分解成正交矩阵和对角阵的组合，即&lt;span class="math">\(A=Q\Lambda Q^T\)&lt;/span>。&lt;/p>
&lt;p>以上说明，对称矩阵&lt;span class="math">\(A\)&lt;/span>是一定可以对角化的，而构建对角化的方法，就是笔记&lt;a href="线性代数与矩阵之特征值与特征向量.md">线性代数与矩阵之特征值与特征向量&lt;/a>中提到的特征分解方法。&lt;/p>
&lt;p>最后，加一个注：&lt;strong>对称矩阵的SVD分解等于谱分解&lt;/strong>。&lt;/p>
&lt;h3 id="cholesky分解">Cholesky分解&lt;/h3>
&lt;p>Cholesky分解是正定埃尔米特矩阵的LU分解。&lt;/p>
&lt;p>Cholesky分解是指将一个&lt;strong>正定的埃尔米特矩阵&lt;/strong>分解成一个&lt;strong>下三角矩阵与其共轭转置之乘积&lt;/strong>。 &lt;span class="math">\[\mathbf A=\mathbf L\mathbf L^\ast\]&lt;/span> 当矩阵&lt;span class="math">\(\mathbf{A}\)&lt;/span>是一个&lt;strong>半正定&lt;/strong>的埃尔米特矩阵，若允许&lt;span class="math">\(\mathbf {L}\)&lt;/span>的对角线元素为&lt;strong>零&lt;/strong>，则&lt;span class="math">\(\mathbf{A}\)&lt;/span>也存在上述形式的分解。&lt;/p>
&lt;p>当&lt;span class="math">\(\mathbf{A}\)&lt;/span>为实数矩阵，则&lt;span class="math">\(\mathbf {L}\)&lt;/span>也为实数矩阵且Cholesky分解可改写成 &lt;span class="math">\[\mathbf {A} =\mathbf {LL} ^{\mathbf {T} }\]&lt;/span>&lt;/p>
&lt;h4 id="分解唯一性">分解唯一性&lt;/h4>
&lt;p>当&lt;span class="math">\(\mathbf{A}\)&lt;/span>是&lt;strong>正定&lt;/strong>矩阵时，Cholesky分解是&lt;strong>唯一&lt;/strong>的，即只存在一个对角元素均严格大于零的下三角矩阵，使&lt;span class="math">\(\mathbf {A} =\mathbf {LL} ^{*}\)&lt;/span>成立。然而，当&lt;span class="math">\(\mathbf{A}\)&lt;/span>是&lt;strong>半正定&lt;/strong>时，分解则&lt;strong>不一定&lt;/strong>是唯一的。&lt;/p>
&lt;p>定理的逆命题自然成立：对于某些可逆矩阵&lt;span class="math">\(\mathbf {L}\)&lt;/span>（下三角矩阵或其他矩阵），如果&lt;span class="math">\(\mathbf{A}\)&lt;/span>可被写成&lt;span class="math">\(\mathbf {LL} ^{*}\)&lt;/span>，则&lt;span class="math">\(\mathbf{A}\)&lt;/span>是一个正定的埃尔米特矩阵。&lt;/p>
&lt;h4 id="分解方法">分解方法&lt;/h4>
&lt;p>Cholesky分解是LU分解的高斯消元法改进。&lt;/p>
&lt;p>这种分解方式在提高代数运算效率、蒙特卡罗方法等场合中十分有用。实数矩阵的Cholesky分解由安德烈·路易·科列斯基（英语：André-Louis Cholesky）最先发明。实际应用中，Cholesky分解在求解线性方程组中的效率约两倍于LU分解。&lt;/p>
&lt;h3 id="cholesky分解变形ldl分解">Cholesky分解变形——LDL分解&lt;/h3>
&lt;p>经典Cholesky分解的一个变形是LDL分解，即 &lt;span class="math">\[\mathbf {A} =\mathbf {LDL} ^{*}\]&lt;/span> 其中，&lt;span class="math">\(\mathbf {L}\)&lt;/span>是一个单位下三角矩阵，&lt;span class="math">\(\mathbf {D}\)&lt;/span>是一个对角矩阵。&lt;/p>
&lt;p>该分解与经典Cholesky分解犹有关系，如下：&lt;/p>
&lt;p>&lt;span class="math">\[\mathbf {A} =\mathbf {LDL} ^{*}=\mathbf {LD} ^{\frac {1}{2}}(\mathbf {D} ^{\frac {1}{2}})^{*}\mathbf {L} ^{*}=\mathbf {LD} ^{\frac {1}{2}}(\mathbf {LD} ^{\frac {1}{2}})^{*}\]&lt;/span>&lt;/p>
&lt;p>LDL变形如果得以有效运行，构造及使用时所需求的空间及计算的复杂性与经典Cholesky分解是相同的，但是可避免提取平方根。某些不存在Cholesky分解的不定矩阵，也可以运行LDL分解，&lt;span class="math">\(\mathbf {D}\)&lt;/span>中会出现负数元素。因此人们更倾向于使用LDL分解。对于实数矩阵，该种分解的形式可被改写成 &lt;span class="math">\[\mathbf {A} =\mathbf {LDL} ^{\mathbf {T} }\]&lt;/span> 此形式通常称为LDLT分解（或LDLT分解）。它与实对称矩阵的特征分解密切相关，因为对于实对称矩阵，存在特征分解&lt;span class="math">\(\mathbf {A} =\mathbf {Q\Lambda Q}^T\)&lt;/span>。&lt;/p>
&lt;h2 id="拓展埃米特矩阵">拓展：埃米特矩阵&lt;/h2>
&lt;p>埃米特矩阵是对称矩阵在复数域的推广，将实对称矩阵的转置&lt;span class="math">\(A=A^T\)&lt;/span>升级为共轭转置&lt;span class="math">\(A=A^H\)&lt;/span>，其中字母“H”来自埃米特的英文“Hermite”。&lt;/p>
&lt;p>对称矩阵的性质在复数空间中由埃米特矩阵继承。&lt;/p>
&lt;p>埃尔米特矩阵主对角线上的元素都是实数的，其特征值也是实数。埃尔米特矩阵是正规矩阵，因此埃尔米特矩阵可被酉对角化，而且得到的对角阵的元素都是实数。这意味着埃尔米特矩阵的特征值都是实的，而且不同的特征值所对应的特征向量相互正交，因此可以在这些特征向量中找出一组&lt;span class="math">\(C^n\)&lt;/span>的正交基。&lt;/p></description></item><item><title>线性代数与矩阵之度量矩阵与广义内积</title><link>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%BA%A6%E9%87%8F%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%B9%BF%E4%B9%89%E5%86%85%E7%A7%AF/</link><pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/studynotes/%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0%E4%B8%8E%E7%9F%A9%E9%98%B5%E4%B9%8B%E5%BA%A6%E9%87%8F%E7%9F%A9%E9%98%B5%E4%B8%8E%E5%B9%BF%E4%B9%89%E5%86%85%E7%A7%AF/</guid><description>
&lt;h2 id="度量矩阵与广义内积">度量矩阵与广义内积&lt;!-- omit in toc -->&lt;/h2>
&lt;h2 id="度量矩阵">度量矩阵&lt;/h2>
&lt;h3 id="gram矩阵">Gram矩阵&lt;/h3>
&lt;p>设&lt;span class="math">\(A\)&lt;/span>为一个&lt;span class="math">\(m\times n\)&lt;/span>阶实矩阵，&lt;span class="math">\(n\)&lt;/span>阶方阵&lt;span class="math">\(G=[g_{ij}]=A^TA\)&lt;/span>称为Gramian或Gram矩阵，也有人称之为交互乘积(cross-product)矩阵。考虑&lt;span class="math">\(A\)&lt;/span>的行向量表达式&lt;span class="math">\(A=\begin{bmatrix} \mathbf{a}_1&amp;amp;\mathbf{a}_2&amp;amp;\cdots&amp;amp;\mathbf{a}_n \end{bmatrix}，\mathbf{a}_i\in\mathbb{R}^m\)&lt;/span>，则 &lt;span class="math">\[G=A^TA=\begin{bmatrix} \mathbf{a}_1^T\\ \mathbf{a}_2^T\\ \vdots\\ \mathbf{a}_n^T \end{bmatrix}\begin {bmatrix} \mathbf{a}_1&amp;amp;\mathbf{a}_2&amp;amp;\cdots&amp;amp;\mathbf{a}_n \end{bmatrix}=\begin{bmatrix} \mathbf{a}_1^T\mathbf{a}_1&amp;amp;\mathbf {a}_1^T\mathbf{a}_2&amp;amp;\cdots&amp;amp;\mathbf{a}_1^T\mathbf{a}_n\\ \mathbf{a}_2^T\mathbf{a}_1&amp;amp;\mathbf{a}_2 ^T\mathbf{a}_2&amp;amp;\cdots&amp;amp;\mathbf{a}_2^T\mathbf{a}_n\\ ~&amp;amp;~&amp;amp;~&amp;amp;~\\ \mathbf{a}_n^T\mathbf{a}_1&amp;amp;\mathbf{a}_n^T\mathbf{a}_2&amp;amp;\cdots&amp;amp;\mathbf{a}_n^T\mathbf{a}_n \end{bmatrix}\]&lt;/span> 这指出&lt;span class="math">\(g_{ij}=\mathbf{a}_i^T\mathbf{a}_j\)&lt;/span>。推广至一般情况，设向量集&lt;span class="math">\(\mathbf{v}_1,\mathbf{v}_2,\ldots,\mathbf{v}_n\)&lt;/span>属于内积空间&lt;span class="math">\(\mathcal{V}，n\times n\)&lt;/span>阶Gramian矩阵&lt;span class="math">\(G\)&lt;/span>的&lt;span class="math">\((i,j)\)&lt;/span>元定义为&lt;span class="math">\(\mathbf{v}_i和\mathbf{v}_j\)&lt;/span>的内积，以&lt;span class="math">\(g_{ij}=\left\langle\mathbf{v}_i,\mathbf{v}_j\right\rangle\)&lt;/span>表示。&lt;/p>
&lt;p>本文仅讨论广泛应用于统计学与控制系统的实Gramian矩阵，以下列举几个实Gramian矩阵&lt;span class="math">\(G=A^TA\)&lt;/span>的基本性质。&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>&lt;span class="math">\(A^TA\)&lt;/span>是对称矩阵。&lt;/li>
&lt;/ol>
&lt;p>明显地，&lt;span class="math">\(g_{ij}=\mathbf{a}_i^T\mathbf{a}_j=\mathbf{a}_j^T\mathbf{a}_i=g_{ji}\)&lt;/span>。&lt;/p>
&lt;p>(2)对任一实矩阵&lt;span class="math">\(A，\mathrm{rank}(A^TA)=\mathrm{rank}A\)&lt;/span>。&lt;/p>
&lt;p>(3)若&lt;span class="math">\(A^TA=0，则A=0\)&lt;/span>。&lt;/p>
&lt;p>性质(3)是性质(2)的必然结果。若&lt;span class="math">\(A^TA=0\)&lt;/span>，则&lt;span class="math">\(\mathrm{rank}A=\mathrm{rank}A^TA=\mathrm{rank}0=0\)&lt;/span>，惟有零矩阵其矩阵秩为零，推得&lt;span class="math">\(A=0\)&lt;/span>。&lt;/p>
&lt;p>Gramian矩阵和正定矩阵有密切的关系，归结为以下三个性质。&lt;/p>
&lt;p>(4)对任一实矩阵&lt;span class="math">\(A，A^TA\)&lt;/span>是半正定矩阵。设&lt;span class="math">\(\mathbf{x}\in\mathbb{R}^n且\mathbf{x}\neq\mathbf{0}\)&lt;/span>，则&lt;span class="math">\(\mathbf{x}^TA^TA\mathbf{x}=(A\mathbf{x})^T(A\mathbf{x})=\Vert A\mathbf{x}\Vert^2\ge 0\)&lt;/span>。&lt;/p>
&lt;p>(5)任一实对称半正定矩阵&lt;span class="math">\(M\)&lt;/span>皆可表示为Grammin矩阵，亦即存在一矩阵&lt;span class="math">\(A\)&lt;/span>使得&lt;span class="math">\(M=A^TA\)&lt;/span>。&lt;/p>
&lt;p>实对称矩阵&lt;span class="math">\(M\)&lt;/span>可正交对角化为&lt;span class="math">\(M=Q\Lambda Q^{T}\)&lt;/span>，其中&lt;span class="math">\(Q^TQ=I，\Lambda=\mathrm{diag}(\lambda_1,\ldots,\lambda_n)\)&lt;/span>。又&lt;span class="math">\(M\)&lt;/span>为半正定，这意味对所有&lt;span class="math">\(i，\lambda_i\ge 0\)&lt;/span>，故可令&lt;span class="math">\(\Lambda^{1/2}=\mathrm{diag}(\sqrt{\lambda_1},\ldots,\sqrt{\lambda_n})\)&lt;/span>且&lt;span class="math">\(A=\Lambda^{1/2}Q^T\)&lt;/span>，立得&lt;span class="math">\(M=Q\Lambda Q^{T}=(Q\Lambda^{1/2})(\Lambda^{1/2}Q^T)=(\Lambda^{1/2}Q^T)^ T(\Lambda^{1/2}Q^T)=A^TA\)&lt;/span>。&lt;/p>
&lt;p>(6)唯当&lt;span class="math">\(A\)&lt;/span>的列向量&lt;span class="math">\(\mathbf{a}_1,\ldots,\mathbf{a}_n\)&lt;/span>是线性独立时，&lt;span class="math">\(A^TA\)&lt;/span>可逆，故为正定矩阵。因为&lt;span class="math">\(A\)&lt;/span>有线性独立的列向量意味&lt;span class="math">\(\mathrm{rank}A=n\)&lt;/span>，由性质(2)可知&lt;span class="math">\(\mathrm{rank}(A^TA)=n\)&lt;/span>，反向陈述显然成立。另外也可以考虑&lt;span class="math">\(A\mathbf{x}=\mathbf{0}\)&lt;/span>，当A有线性独立行向量时，零空间&lt;span class="math">\(N(A)=\{\mathbf{0}\}\)&lt;/span>，性质(4)的等号仅发生于&lt;span class="math">\(\mathbf{x}=\mathbf{0}\)&lt;/span>，故&lt;span class="math">\(A\)&lt;/span>为正定矩阵。&lt;/p>
&lt;h2 id="广义内积">广义内积&lt;/h2>
&lt;p>有复空间&lt;span class="math">\(C^n\)&lt;/span>，有一组基&lt;span class="math">\(bases_1=\{\varepsilon_1,\varepsilon_2,\dotsb,\varepsilon_n\}\)&lt;/span>，&lt;span class="math">\(\alpha,\beta\)&lt;/span>用&lt;span class="math">\(base_1\)&lt;/span>表示的向量，那么&lt;span class="math">\(\alpha,\beta\)&lt;/span>在&lt;span class="math">\(base_1\)&lt;/span>下的内积可以定义为 &lt;span class="math">\[\langle\alpha,\beta\rangle=\sum_{i=1}^n\sum_{j=1}^n x_i\bar y_i\langle\varepsilon_i,\varepsilon_j\rangle\\=x^TA\bar y\]&lt;/span> 其中，&lt;span class="math">\(A=(\langle\varepsilon_i,\varepsilon_j\rangle)_{n*n}\)&lt;/span>，称&lt;span class="math">\(A\)&lt;/span>是空间&lt;span class="math">\(C^n\)&lt;/span>在基&lt;span class="math">\(\{\varepsilon_1,\varepsilon_2,\dotsb,\varepsilon_n\}\)&lt;/span>下的度量矩阵，这种带有度量矩阵的内积称为广义内积。&lt;/p>
&lt;p>对于欧几里得空间&lt;span class="math">\(R^n\)&lt;/span>，度量矩阵是对称矩阵&lt;span class="math">\(A^T=A\)&lt;/span>；对于酉空间&lt;span class="math">\(C^n\)&lt;/span>，度量矩阵是Hermite矩阵&lt;span class="math">\(A^H=A\)&lt;/span>。对于一般内积，可以看成度量矩阵是n阶单位矩阵&lt;span class="math">\(I_{n*n}\)&lt;/span>。&lt;/p>
&lt;p>可以看出定义内积的方式是多种多样的，因此我们能够指出只要满足哪些问题就可以算是内积。&lt;/p>
&lt;h2 id="内积空间">内积空间&lt;/h2>
&lt;p>标量域&lt;span class="math">\({\displaystyle F}\)&lt;/span>是指实数域&lt;span class="math">\(\mathbb {R}\)&lt;/span>或复数域&lt;span class="math">\(\mathbb {C}\)&lt;/span>。&lt;/p>
&lt;p>正式地，一个内积空间是域&lt;span class="math">\(F\)&lt;/span>上的向量空间&lt;span class="math">\(V\)&lt;/span>与一个内积(即一个映射)构成的。&lt;span class="math">\(V\)&lt;/span>上的一个内积定义为正定、非退化的共轭双线性形式（&lt;span class="math">\(F = \mathbb{R}\)&lt;/span>时，内积是一个正定、对称、非退化的双线性形式），记为&lt;span class="math">\(\langle \cdot, \cdot \rangle : V \times V \rightarrow F\)&lt;/span>。&lt;/p>
&lt;p>它满足以下设定：&lt;/p>
&lt;ol style="list-style-type: decimal">
&lt;li>共轭对称；&lt;span class="math">\(\forall x,y\in V, \; \; \langle x,y\rangle =\overline{\langle y,x\rangle}\)&lt;/span>，这个设定蕴含了：&lt;span class="math">\(\forall x \in V, \; \; \langle x,x\rangle \in \mathbb{R}\)&lt;/span>，因为&lt;span class="math">\(\langle x,x\rangle = \overline{\langle x,x\rangle}\)&lt;/span>.&lt;/li>
&lt;li>对第一个元素线性； &lt;span class="math">\[\forall a\in F,\ \forall x,y\in V,\ \langle ax,y\rangle= a \langle x,y\rangle, \\ \forall x,y,z\in V,\ \langle x+y,z\rangle= \langle x,z\rangle+ \langle y,z\rangle.\]&lt;/span> 前两条可以推断出： &lt;span class="math">\[\forall b\in F,\ \forall x,y\in V,\ \langle x,by \rangle= \overline{b} \langle x,y\rangle,\\ \forall x,y,z\in V,\ \langle x,y+z\rangle= \langle x,y\rangle+ \langle x,z\rangle.\]&lt;/span> 因此&lt;span class="math">\(\langle \cdot , \cdot \rangle\)&lt;/span>实际上是一个半双线性形式。&lt;/li>
&lt;li>非负性：&lt;span class="math">\(\forall x \in V,\ \langle x,x\rangle \ge 0.\)&lt;/span>&lt;/li>
&lt;li>非退化：从&lt;span class="math">\(V\)&lt;/span>到对偶空间&lt;span class="math">\(V^\ast\)&lt;/span>的映射：&lt;span class="math">\(x\mapsto \langle x,\cdot\rangle\)&lt;/span>是同构映射。在有限维的向量空间中，只需要验证它是单射：&lt;span class="math">\(\langle x,y\rangle = 0 \; \forall y \in V\)&lt;/span>,当且仅当&lt;span class="math">\(x = 0\)&lt;/span>。&lt;/li>
&lt;/ol>
&lt;p>拥有以上性质的共轭双线性形式被称为&lt;strong>埃尔米特形式&lt;/strong>。&lt;strong>内积是一个埃尔米特形式&lt;/strong>。如果&lt;span class="math">\(F\)&lt;/span>是实数域&lt;span class="math">\(\mathbb {R}\)&lt;/span>那么共轭对称性质就等价于对称性：&lt;span class="math">\(\langle x,y\rangle=\langle y,x\rangle\)&lt;/span>，也就是说，共轭双线性变成了一般的双线性。&lt;/p></description></item></channel></rss>