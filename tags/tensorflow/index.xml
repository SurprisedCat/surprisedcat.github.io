<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>tensorflow on SurprisedCat</title><link>https://surprisedcat.github.io/tags/tensorflow/</link><description>Recent content in tensorflow on SurprisedCat</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><copyright>Copyright © 2020–2021, SurprisedCat; all rights reserved.</copyright><lastBuildDate>Sat, 04 Jul 2020 00:00:00 +0000</lastBuildDate><atom:link href="https://surprisedcat.github.io/tags/tensorflow/index.xml" rel="self" type="application/rss+xml"/><item><title>tensorflow-保存和载入模型</title><link>https://surprisedcat.github.io/projectnotes/tensorflow-%E4%BF%9D%E5%AD%98%E5%92%8C%E8%BD%BD%E5%85%A5%E6%A8%A1%E5%9E%8B/</link><pubDate>Sat, 04 Jul 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/projectnotes/tensorflow-%E4%BF%9D%E5%AD%98%E5%92%8C%E8%BD%BD%E5%85%A5%E6%A8%A1%E5%9E%8B/</guid><description>
&lt;h2 id="tensorflow-中模型的保证与载入---omit-in-toc---">Tensorflow 中模型的保证与载入&lt;!-- omit in toc -->&lt;/h2>
&lt;p>Tensorflow中模型保存有着关键作用，无论是隔段时间保存以防止突发状况，还是保存训练完毕的模型以供使用，都需要使用tensorflow中的模型保存功能。有时候，可能也需要用到训练好的模型（迁移学习，预学习），并在这个基础上再次训练（fine tuning）。这时候我们需要掌握如何操作这些模型数据。&lt;/p>
&lt;h2 id="模型文件">模型文件&lt;/h2>
&lt;p>目前使用tensorflow 1.X版本，指定的模型保存目录下有4个，3类。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>&lt;span class="p">|&lt;/span>--checkpoint_dir
&lt;span class="ln">2&lt;/span>&lt;span class="p">|&lt;/span> &lt;span class="p">|&lt;/span>--checkpoint
&lt;span class="ln">3&lt;/span>&lt;span class="p">|&lt;/span> &lt;span class="p">|&lt;/span>--MyModel.meta
&lt;span class="ln">4&lt;/span>&lt;span class="p">|&lt;/span> &lt;span class="p">|&lt;/span>--MyModel.data-00000-of-00001
&lt;span class="ln">5&lt;/span>&lt;span class="p">|&lt;/span> &lt;span class="p">|&lt;/span>--MyModel.index
&lt;span class="ln">6&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;ul>
&lt;li>checkpoint：该文件是文本文件，里面记录了保存的最新的checkpoint文件以及其它checkpoint文件列表。例如最近保存的默认5个文件名称。&lt;/li>
&lt;li>meta文件：保存的是图结构，meta文件是pb（protocol buffer）格式文件，包含变量、op、集合等。&lt;/li>
&lt;li>ckpt文件：包含name-global_step.data-xxxx-of-xxxx和.index文件，都是二进制文件，保存了所有的weights、biases、gradients等变量。.index是索引，.data文件保存具体数值，一般参数很多时很大。&lt;/li>
&lt;/ul>
&lt;h2 id="保存tensorflow模型">保存Tensorflow模型&lt;/h2>
&lt;p>Tensorflow使用tf.train.Saver类来保存模型，值得注意的是，在tensorflow中，变量是存在于Session环境中，也就是说，只有在Session环境下才会存有变量值，因此，保存模型时需要传入session：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="n">saver&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Saver&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">2&lt;/span>&lt;span class="n">saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="s2">&amp;#34;Mypath/checkpoint_dir/MyModel&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>以下Copy from &lt;a href="https://blog.csdn.net/huachao1001/article/details/78501928">https://blog.csdn.net/huachao1001/article/details/78501928&lt;/a>&lt;/p>
&lt;p>如果想要在1000次迭代后，再保存模型，只需设置global_step参数即可：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="n">saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Mypath/checkpoint_dir/MyModel&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">global_step&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1000&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>保存的模型文件名称会在后面加-1000,如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="ln">1&lt;/span>checkpoint
&lt;span class="ln">2&lt;/span>MyModel-1000.data-00000-of-00001
&lt;span class="ln">3&lt;/span>MyModel-1000.index
&lt;span class="ln">4&lt;/span>MyModel-1000.meta
&lt;/code>&lt;/pre>&lt;/div>&lt;p>在实际训练中，我们可能会在每1000次迭代中保存一次模型数据，但是由于图是不变的，没必要每次都去保存，可以通过如下方式指定不保存图：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="n">saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Mypath/checkpoint_dir/MyModel&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">global_step&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">step&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">write_meta_graph&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="kc">False&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>另一种比较实用的是，如果你希望每2小时保存一次模型，并且只保存最近的5个模型文件：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Saver&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">max_to_keep&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">keep_checkpoint_every_n_hours&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>注意：tensorflow默认只会保存最近的5个模型文件，如果你希望保存更多，可以通过max_to_keep来指定&lt;/p>
&lt;/blockquote>
&lt;p>如果我们不对tf.train.Saver指定任何参数，默认会保存所有变量。如果你不想保存所有变量，而只保存一部分变量，可以通过指定variables/collections。在创建tf.train.Saver实例时，通过将需要保存的变量构造list或者dictionary，传入到Saver中&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;span class="ln">2&lt;/span>&lt;span class="n">w1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random_normal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;w1&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="n">w2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">random_normal&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;w2&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">4&lt;/span>&lt;span class="n">saver&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Saver&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">w1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">w2&lt;/span>&lt;span class="p">])&lt;/span> &lt;span class="c1"># 只保存w1 , w2&lt;/span>
&lt;span class="ln">5&lt;/span>&lt;span class="n">sess&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">6&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">global_variables_initializer&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="ln">7&lt;/span>&lt;span class="n">saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;Mypath/checkpoint_dir/MyModel&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">global_step&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1000&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">8&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="导入tensorflow已有模型">导入Tensorflow已有模型&lt;/h2>
&lt;p>Tensorflow将图和变量数据分开保存为不同的文件。因此，在导入模型时，也要分为2步：构造网络图和加载参数。&lt;/p>
&lt;h3 id="导入网络图">导入网络图&lt;/h3>
&lt;p>一个比较笨的方法是，手敲代码，实现跟模型一模一样的图结构。其实，我们既然已经保存了图，那就没必要在去手写一次图结构代码。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="n">saver&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">import_meta_graph&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Mypath/checkpoint_dir/MyModel-1000.meta&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h3 id="加载参数">加载参数&lt;/h3>
&lt;p>仅仅有图并没有用，更重要的是，我们需要前面训练好的模型参数（即weights、biases等），本文第2节提到过，变量值需要依赖于Session，因此在加载参数时，先要构造好Session：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;span class="ln">2&lt;/span>&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="n">new_saver&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">import_meta_graph&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Mypath/checkpoint_dir/MyModel-1000.meta&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="n">new_saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">restore&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">latest_checkpoint&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;Mypath/checkpoint_dir&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="c1"># 选取最新的check point&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>此时，W1和W2加载进了图，并且可以被访问。&lt;/p>
&lt;p>还有一种导入模型的方式如下：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="n">ckpt&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_checkpoint_state&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">MODEL_SAVE_PATH&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">2&lt;/span>&lt;span class="c1"># 若模型存在，则加载出模型到当前对话，在测试数据集上进行准确率验证，并打印出当前轮数下的准确率&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="k">if&lt;/span> &lt;span class="n">ckpt&lt;/span> &lt;span class="ow">and&lt;/span> &lt;span class="n">ckpt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">model_checkpoint_path&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="c1"># 默认恢复最新的模型&lt;/span>
&lt;span class="ln">5&lt;/span> &lt;span class="n">saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">restore&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">ckpt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">model_checkpoint_path&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">6&lt;/span> &lt;span class="c1"># 根据模型名称获取global_step&lt;/span>
&lt;span class="ln">7&lt;/span> &lt;span class="n">global_step&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ckpt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">model_checkpoint_path&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;/&amp;#39;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">split&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;-&amp;#39;&lt;/span>&lt;span class="p">)[&lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>还可以遍历所有保存的模型：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="k">for&lt;/span> &lt;span class="n">i&lt;/span> &lt;span class="ow">in&lt;/span> &lt;span class="nb">range&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">len&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ckpt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">all_model_checkpoint_paths&lt;/span>&lt;span class="p">)):&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="n">p&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">ckpt&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">all_model_checkpoint_paths&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">i&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;h2 id="使用恢复的模型">使用恢复的模型&lt;/h2>
&lt;p>前面我们理解了如何保存和恢复模型，很多时候，我们希望使用一些已经训练好的模型，如prediction、fine-tuning以及进一步训练等。这时候，我们可能需要获取训练好的模型中的一些中间结果值，可以通过&lt;code>graph.get_tensor_by_name('w1:0')&lt;/code>来获取，注意&lt;code>w1:0&lt;/code>是tensor的name。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;span class="ln"> 2&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="n">w1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">placeholder&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;float&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;w1&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="n">w2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">placeholder&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;float&amp;#34;&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;w2&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="n">b1&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">2.0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;bias&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 6&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="c1">#定义一个op，用于后面恢复&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="n">w3&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">add&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">w2&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="n">w4&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">multiply&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">b1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s2">&amp;#34;op_to_restore&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="n">sess&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">global_variables_initializer&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="ln">12&lt;/span>
&lt;span class="ln">13&lt;/span>&lt;span class="c1">#创建一个Saver对象，用于保存所有变量&lt;/span>
&lt;span class="ln">14&lt;/span>&lt;span class="n">saver&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Saver&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">15&lt;/span>
&lt;span class="ln">16&lt;/span>&lt;span class="c1">#通过传入数据，执行op&lt;/span>
&lt;span class="ln">17&lt;/span>&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">w4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">feed_dict&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">w1&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">w2&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mi">8&lt;/span>&lt;span class="p">}))&lt;/span>
&lt;span class="ln">18&lt;/span>&lt;span class="c1">#打印 24.0 ==&amp;gt;(w1+w2)*b1&lt;/span>
&lt;span class="ln">19&lt;/span>
&lt;span class="ln">20&lt;/span>&lt;span class="c1">#现在保存模型&lt;/span>
&lt;span class="ln">21&lt;/span>&lt;span class="n">saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">save&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="s1">&amp;#39;./checkpoint_dir/MyModel&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">global_step&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">1000&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>接下来我们使用&lt;code>graph.get_tensor_by_name()&lt;/code>方法来操纵这个保存的模型。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;span class="ln"> 2&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="c1">#先加载图和参数变量&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="n">saver&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">import_meta_graph&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;./checkpoint_dir/MyModel-1000.meta&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 6&lt;/span>&lt;span class="n">saver&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">restore&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">latest_checkpoint&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;./checkpoint_dir&amp;#39;&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln"> 7&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="c1"># 访问placeholders变量，并且创建feed-dict来作为placeholders的新值&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="n">graph&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_default_graph&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="n">w1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">graph&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_tensor_by_name&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;w1:0&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="n">w2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">graph&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_tensor_by_name&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;w2:0&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="n">feed_dict&lt;/span> &lt;span class="o">=&lt;/span>&lt;span class="p">{&lt;/span>&lt;span class="n">w1&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">13.0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">w2&lt;/span>&lt;span class="p">:&lt;/span>&lt;span class="mf">17.0&lt;/span>&lt;span class="p">}&lt;/span>
&lt;span class="ln">13&lt;/span>
&lt;span class="ln">14&lt;/span>&lt;span class="c1">#接下来，访问你想要执行的op&lt;/span>
&lt;span class="ln">15&lt;/span>&lt;span class="n">op_to_restore&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">graph&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_tensor_by_name&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s2">&amp;#34;op_to_restore:0&amp;#34;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">16&lt;/span>
&lt;span class="ln">17&lt;/span>&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">op_to_restore&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="n">feed_dict&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">18&lt;/span>&lt;span class="c1">#打印结果为60.0==&amp;gt;(13+17)*2&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果只想恢复图的一部分，并且再加入其它的op用于fine-tuning。只需通过&lt;code>graph.get_tensor_by_name()&lt;/code>方法获取需要的op，并且在此基础上建立图，看一个简单例子，假设我们需要在训练好的VGG网络使用图，并且修改最后一层，将输出改为2，用于fine-tuning新数据：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="o">......&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="o">......&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="n">saver&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">train&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">import_meta_graph&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;vgg.meta&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="c1"># 访问图&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="n">graph&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_default_graph&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln"> 6&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="c1">#访问用于fine-tuning的output&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="n">fc7&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="n">graph&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_tensor_by_name&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="s1">&amp;#39;fc7:0&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 9&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="c1">#如果你想修改最后一层梯度，需要如下&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="n">fc7&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">stop_gradient&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fc7&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># It&amp;#39;s an identity function&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="n">fc7_shape&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="n">fc7&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_shape&lt;/span>&lt;span class="p">()&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">as_list&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">13&lt;/span>
&lt;span class="ln">14&lt;/span>&lt;span class="n">new_outputs&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mi">2&lt;/span>
&lt;span class="ln">15&lt;/span>&lt;span class="n">weights&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">truncated_normal&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">fc7_shape&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">num_outputs&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">stddev&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="mf">0.05&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">16&lt;/span>&lt;span class="n">biases&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">constant&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">0.05&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">num_outputs&lt;/span>&lt;span class="p">]))&lt;/span>
&lt;span class="ln">17&lt;/span>&lt;span class="n">output&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">fc7&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">weights&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="o">+&lt;/span> &lt;span class="n">biases&lt;/span>
&lt;span class="ln">18&lt;/span>&lt;span class="n">pred&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">nn&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">softmax&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">output&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">19&lt;/span>
&lt;span class="ln">20&lt;/span>&lt;span class="c1"># Now, you run this with fine-tuning data in sess.run()&lt;/span>
&lt;span class="ln">21&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>tensorflow-tf.shape(x)、x.shape和x.get_shape()的区别</title><link>https://surprisedcat.github.io/projectnotes/tensorflow-tf.shapexx.shape%E5%92%8Cx.get_shape%E7%9A%84%E5%8C%BA%E5%88%AB/</link><pubDate>Fri, 03 Jul 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/projectnotes/tensorflow-tf.shapexx.shape%E5%92%8Cx.get_shape%E7%9A%84%E5%8C%BA%E5%88%AB/</guid><description>
&lt;h2 id="tfshapexxshape和xget_shape的区别---omit-in-toc---">tf.shape(x)、x.shape和x.get_shape()的区别&lt;!-- omit in toc -->&lt;/h2>
&lt;h2 id="对于tensor来说">对于Tensor来说&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="kn">import&lt;/span> &lt;span class="nn">tensorflow&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="nn">tf&lt;/span>
&lt;span class="ln"> 2&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="nb">input&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">constant&lt;/span>&lt;span class="p">([[&lt;/span>&lt;span class="mi">0&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">],[&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">]])&lt;/span>
&lt;span class="ln"> 4&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln"> 6&lt;/span>&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_shape&lt;/span>&lt;span class="p">()))&lt;/span>
&lt;span class="ln"> 7&lt;/span>&lt;span class="nb">print&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">type&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="nb">input&lt;/span>&lt;span class="p">)))&lt;/span>
&lt;span class="ln"> 8&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="n">Out&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="k">class&lt;/span> &lt;span class="err">&amp;#39;&lt;/span>&lt;span class="nc">tensorflow&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">python&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">framework&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor_shape&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TensorShape&lt;/span>&lt;span class="s1">&amp;#39;&amp;gt;&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="k">class&lt;/span> &lt;span class="err">&amp;#39;&lt;/span>&lt;span class="nc">tensorflow&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">python&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">framework&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">tensor_shape&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">TensorShape&lt;/span>&lt;span class="s1">&amp;#39;&amp;gt;&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="k">class&lt;/span> &lt;span class="err">&amp;#39;&lt;/span>&lt;span class="nc">tensorflow&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">python&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">framework&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">ops&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Tensor&lt;/span>&lt;span class="s1">&amp;#39;&amp;gt;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以看到&lt;code>x.shape&lt;/code>和&lt;code>x.get_shape()&lt;/code>都是返回TensorShape类型对象，而&lt;code>tf.shape(x)&lt;/code>返回的是Tensor类型对象。&lt;/p>
&lt;p>具体来说&lt;code>tf.shape()&lt;/code>返回的是tensor，想要获取tensor具体的shape结果需要&lt;code>sess.run&lt;/code>才行。而&lt;code>tf.get_shape&lt;/code>和&lt;code>x.shape&lt;/code>返回的是一个元组，因此要想操作维度信息，则需要调用TensorShape的&lt;code>tf.as_list()&lt;/code>方法，返回的是Python的list。&lt;/p>
&lt;p>需要注意的是&lt;code>tf.get_shape()&lt;/code>返回的是元组，不能放到&lt;code>sess.run()&lt;/code>里面，这个里面只能放operation和tensor&lt;/p>
&lt;h2 id="对于placeholder来说">对于placeholder来说&lt;/h2>
&lt;p>对&lt;code>tf.placeholder&lt;/code>占位符来说，如果shape设置的其中某一个是None，那么对于&lt;code>tf.shape，sess.run&lt;/code>会报错，而&lt;code>tf.get_shape&lt;/code>不会，它会在None位置显示“?”表示此位置的shape暂时未知。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="n">a&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Variable&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">constant&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mf">1.5&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">float32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="mi">1&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">2&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">4&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">5&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">6&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="mi">7&lt;/span>&lt;span class="p">]),&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;a&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="n">b&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">placeholder&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">dtype&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">int32&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">shape&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="kc">None&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="mi">3&lt;/span>&lt;span class="p">],&lt;/span> &lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;b&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 3&lt;/span>&lt;span class="n">s1&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 4&lt;/span>&lt;span class="n">s2&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">a&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_shape&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln"> 5&lt;/span>&lt;span class="nb">print&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">s1&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># Tensor(&amp;#34;Shape:0&amp;#34;, shape=(7,), dtype=int32)&lt;/span>
&lt;span class="ln"> 6&lt;/span>&lt;span class="nb">print&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">s2&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 元组 (1, 2, 3, 4, 5, 6, 7)&lt;/span>
&lt;span class="ln"> 7&lt;/span>
&lt;span class="ln"> 8&lt;/span>&lt;span class="n">s11&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">shape&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">b&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="n">s21&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">get_shape&lt;/span>&lt;span class="p">()&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="nb">print&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">s11&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># Tensor(&amp;#34;Shape_1:0&amp;#34;, shape=(2,), dtype=int32)&lt;/span>
&lt;span class="ln">11&lt;/span>&lt;span class="nb">print&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">s21&lt;/span>&lt;span class="p">)&lt;/span> &lt;span class="c1"># 因为第一位设置的是None，所以这里的第一位显示问号表示暂时不确认 (?, 3)&lt;/span>
&lt;span class="ln">12&lt;/span>&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">Session&lt;/span>&lt;span class="p">()&lt;/span> &lt;span class="k">as&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="p">:&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">global_variables_initializer&lt;/span>&lt;span class="p">())&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="nb">print&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s1&lt;/span>&lt;span class="p">))&lt;/span> &lt;span class="c1"># [1 2 3 4 5 6 7]&lt;/span>
&lt;span class="ln">15&lt;/span> &lt;span class="nb">print&lt;/span> &lt;span class="p">(&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">s11&lt;/span>&lt;span class="p">))&lt;/span>
&lt;span class="ln">16&lt;/span> &lt;span class="c1"># InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor &amp;#39;b&amp;#39; with dtype int32&lt;/span>
&lt;span class="ln">17&lt;/span> &lt;span class="c1"># [[Node: b = Placeholder[dtype=DT_INT32, shape=[], _device=&amp;#34;/job:localhost/replica:0/task:0/cpu:0&amp;#34;]()]]&lt;/span>
&lt;/code>&lt;/pre>&lt;/div></description></item><item><title>tensorflow-tf.control_dependencies()作用及用法</title><link>https://surprisedcat.github.io/projectnotes/tensorflow-tf.control_dependencies%E4%BD%9C%E7%94%A8%E5%8F%8A%E7%94%A8%E6%B3%95/</link><pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/projectnotes/tensorflow-tf.control_dependencies%E4%BD%9C%E7%94%A8%E5%8F%8A%E7%94%A8%E6%B3%95/</guid><description>
&lt;h2 id="tensorflow-tfcontrol_dependencies作用及用法---omit-in-toc---">tensorflow tf.control_dependencies()作用及用法&lt;!-- omit in toc -->&lt;/h2>
&lt;p>在有些机器学习程序中我们想要指定某些操作执行的依赖关系，这时我们可以使用&lt;code>tf.control_dependencies()&lt;/code>来实现。
&lt;code>control_dependencies(control_inputs)&lt;/code>返回一个控制依赖的上下文管理器，使用&lt;code>with关&lt;/code>键字可以让在这个上下文环境中的操作都在&lt;code>control_inputs&lt;/code> 执行。&lt;/p>
&lt;h2 id="原型分析">原型分析&lt;/h2>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="bp">self&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">control_inputs&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;blockquote>
&lt;p>arguments：control_inputs: A list of &lt;code>Operation&lt;/code> or &lt;code>Tensor&lt;/code> objects
which must be executed or computed before running the operations
defined in the context. （注意这里control_inputs是list）
return： A context manager that specifies control dependencies
for all operations constructed within the context.&lt;/p>
&lt;/blockquote>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="k">with&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="c1"># `d` and `e` will only run after `a`, `b`, and `c` have executed.&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="n">d&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="n">e&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="o">...&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以嵌套&lt;code>control_dependencies&lt;/code> 使用&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="k">with&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="c1"># Ops constructed here run after `a` and `b`.&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="k">with&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="c1"># Ops constructed here run after `a`, `b`, `c`, and `d`.&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>可以传入&lt;code>None&lt;/code> 来消除依赖：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="k">with&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="c1"># Ops constructed here run after `a` and `b`.&lt;/span>
&lt;span class="ln">3&lt;/span> &lt;span class="k">with&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="kc">None&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln">4&lt;/span> &lt;span class="c1"># Ops constructed here run normally, not waiting for either `a` or `b`.&lt;/span>
&lt;span class="ln">5&lt;/span> &lt;span class="k">with&lt;/span> &lt;span class="n">g&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">d&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln">6&lt;/span> &lt;span class="c1"># Ops constructed here run after `c` and `d`, also not waiting&lt;/span>
&lt;span class="ln">7&lt;/span> &lt;span class="c1"># for either `a` or `b`.&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意：控制依赖只对那些在上下文环境中建立的操作有效，仅仅在context中使用一个操作或张量是没用的&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln"> 1&lt;/span>&lt;span class="c1"># WRONG&lt;/span>
&lt;span class="ln"> 2&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">my_func&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln"> 3&lt;/span> &lt;span class="n">t&lt;/span> &lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln"> 4&lt;/span> &lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">pred&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln"> 5&lt;/span> &lt;span class="c1"># The matmul op is created outside the context, so no control&lt;/span>
&lt;span class="ln"> 6&lt;/span> &lt;span class="c1"># dependency will be added.&lt;/span>
&lt;span class="ln"> 7&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">t&lt;/span>
&lt;span class="ln"> 8&lt;/span>
&lt;span class="ln"> 9&lt;/span>&lt;span class="c1"># RIGHT&lt;/span>
&lt;span class="ln">10&lt;/span>&lt;span class="k">def&lt;/span> &lt;span class="nf">my_func&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">pred&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor&lt;/span>&lt;span class="p">):&lt;/span>
&lt;span class="ln">11&lt;/span> &lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">pred&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln">12&lt;/span> &lt;span class="c1"># The matmul op is created in the context, so a control dependency&lt;/span>
&lt;span class="ln">13&lt;/span> &lt;span class="c1"># will be added.&lt;/span>
&lt;span class="ln">14&lt;/span> &lt;span class="k">return&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">matmul&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">tensor&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">tensor&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>例子：在训练模型时我们每步训练可能要执行两种操作，op a, b 这时我们就可以使用如下代码：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="ln">1&lt;/span>&lt;span class="k">with&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">control_dependencies&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">]):&lt;/span>
&lt;span class="ln">2&lt;/span> &lt;span class="n">c&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">no_op&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;train&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="c1">#tf.no_op；什么也不做&lt;/span>
&lt;span class="ln">3&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span>
&lt;span class="ln">4&lt;/span>
&lt;span class="ln">5&lt;/span>&lt;span class="c1"># 在这样简单的要求下，可以将上面代码替换为：&lt;/span>
&lt;span class="ln">6&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="o">=&lt;/span> &lt;span class="n">tf&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">group&lt;/span>&lt;span class="p">([&lt;/span>&lt;span class="n">a&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">b&lt;/span>&lt;span class="p">])&lt;/span>
&lt;span class="ln">7&lt;/span>&lt;span class="n">sess&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="n">run&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">c&lt;/span>&lt;span class="p">)&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>其他关于&lt;code>tf.identity()&lt;/code>的奇怪操作可见&lt;a href="https://blog.csdn.net/u012436149/article/details/72084744">https://blog.csdn.net/u012436149/article/details/72084744&lt;/a>&lt;/p>
&lt;p>使用&lt;code>tf.no_op()&lt;/code>是一个占位符，表示什么都不做，但是会返回一个operation，用以保证&lt;code>tf.control_dependencies()&lt;/code>被执行，和&lt;code>tf.group&lt;/code>操作类似。&lt;/p>
&lt;p>版权声明：本文为CSDN博主「PKU_Jade」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：&lt;a href="https://blog.csdn.net/PKU_Jade/article/details/73498753">https://blog.csdn.net/PKU_Jade/article/details/73498753&lt;/a>&lt;/p></description></item><item><title>tensorflow-1和2的区别直观理解</title><link>https://surprisedcat.github.io/projectnotes/tensorflow-1%E5%92%8C2%E7%9A%84%E5%8C%BA%E5%88%AB%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/</link><pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><guid>https://surprisedcat.github.io/projectnotes/tensorflow-1%E5%92%8C2%E7%9A%84%E5%8C%BA%E5%88%AB%E7%9B%B4%E8%A7%82%E7%90%86%E8%A7%A3/</guid><description>
&lt;h2 id="tensorflow-1-和-2-区别直观理解---omit-in-toc---">Tensorflow 1 和 2 区别直观理解&lt;!-- omit in toc -->&lt;/h2>
&lt;ol>
&lt;li>1.X的感觉和过去用的ns3很像，默认方式是先要定义一个静态结构，然后训练操作流程时独立的。这样运行效率比较高，但是调试起来费劲。最直观的一点，就是一些在函数中预先定义静态结构“彷佛”是不执行的，这造成有些写在后面的语句彷佛先执行了一样。2.X默认采用动态图处理的方式，和python风格更接近（Eager execution）。&lt;/li>
&lt;li>1.X版本有很多额外的概念比如，graph，session，run，placeholder，feed_dict这些，这些其实和静态模型构建息息相关，在2.X版本中不再使用了。&lt;/li>
&lt;li>1.X的tensorflow像一个平台工具，只是借用了python语言，tensorflow 1.X本身更像是一种描述神经网络模型的语言，2.X版本更像python的一个包。&lt;/li>
&lt;li>1.X中的变量空间和命名空间使得变量管理比较复杂，并大量依赖隐式全局名称空间（这点类似c++），还有一些必须的初始化比如&lt;code>tf.global_variables_initializer()&lt;/code>， 2.X消除了所有这些机制，支持跟踪变量。（根据这第1点和第4点我特别怀疑1.X的设计者C++用的很6）&lt;/li>
&lt;li>2.X版本中默认使用keras作为高级API， 1.X中需要自己装。在1.X中使用keras反而更容易移植到2.X。&lt;/li>
&lt;li>1.X中一些API很难找，而且位置分类有很多争议，2.X版本重新归纳整理了API。&lt;/li>
&lt;/ol></description></item></channel></rss>